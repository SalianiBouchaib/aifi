import streamlit as st

# This MUST be the first Streamlit command
st.set_page_config(
    page_title="Advanced Financial Planning Suite", 
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üíº"
)

# Enhanced imports
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import os
import warnings
from datetime import datetime, timedelta
import base64
from io import BytesIO
import time
from scipy import stats
from scipy.interpolate import interp1d
from scipy.signal import savgol_filter

# Handle optional dependencies with try/except
try:
    from sklearn.ensemble import RandomForestRegressor, VotingRegressor
    from sklearn.linear_model import LinearRegression, Ridge
    from sklearn.preprocessing import StandardScaler, PolynomialFeatures
    from sklearn.model_selection import cross_val_score, GridSearchCV, TimeSeriesSplit
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.pipeline import Pipeline
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    class MLFallback:
        def __init__(self, *args, **kwargs):
            pass
        def fit(self, X, y):
            return self
        def predict(self, X):
            return np.zeros(len(X)) if hasattr(X, '__len__') else [0]
        def fit_transform(self, X):
            return X
        def transform(self, X):
            return X
        def score(self, X, y):
            return 0.0
    RandomForestRegressor = MLFallback
    LinearRegression = MLFallback
    StandardScaler = MLFallback
    VotingRegressor = MLFallback
    Ridge = MLFallback
    PolynomialFeatures = MLFallback
    Pipeline = MLFallback

warnings.filterwarnings('ignore')

# ========== ENHANCED DATA VALIDATION AND CORRECTION SYSTEM ==========
class AdvancedDataValidator:
    """Classe pour validation avanc√©e et diagnostic d'incoh√©rences avec corrections automatiques"""
    
    def __init__(self):
        self.validation_results = {}
        self.correction_log = []
        self.outlier_threshold = 3
        self.variation_threshold = 1.0
        
    def validate_accounting_equation(self, df, mappings):
        """Validation √©quation comptable : Assets = Liabilities + Equity - VERSION CORRIG√âE"""
        issues = []
        
        try:
            if all(col in mappings for col in ['assets', 'liabilities', 'equity']):
                assets_col = mappings['assets']
                liabilities_col = mappings['liabilities']
                equity_col = mappings['equity']
                
                if all(col in df.columns for col in [assets_col, liabilities_col, equity_col]):
                    assets = self.clean_numeric_column(df[assets_col])
                    liabilities = self.clean_numeric_column(df[liabilities_col])
                    equity = self.clean_numeric_column(df[equity_col])
                    
                    # FIX: Gestion s√©curis√©e des comparaisons numpy
                    if len(assets) > 0 and len(liabilities) > 0 and len(equity) > 0:
                        calculated_assets = liabilities + equity
                        differences = np.abs(assets - calculated_assets)
                        tolerance = assets * 0.05
                        
                        # FIX: Conversion s√©curis√©e pour √©viter l'erreur numpy
                        violations = np.array(differences > tolerance, dtype=bool)
                        violation_count = int(np.sum(violations)) if len(violations) > 0 else 0
                        
                        if violation_count > 0:
                            max_diff = float(np.max(differences)) if len(differences) > 0 else 0
                            max_diff_pct = (max_diff / float(np.max(assets))) * 100 if float(np.max(assets)) > 0 else 0
                            
                            issues.append({
                                'type': '√âquation Comptable',
                                'severity': '√âlev√©e' if violation_count > len(df) * 0.3 else 'Moyenne',
                                'count': violation_count,
                                'message': f"{violation_count} violations d√©tect√©es (max: {max_diff_pct:.1f}%)",
                                'violations': violations.tolist(),
                                'differences': differences.tolist()
                            })
                        else:
                            issues.append({
                                'type': '√âquation Comptable',
                                'severity': 'OK',
                                'message': "√âquation comptable respect√©e"
                            })
        except Exception as e:
            issues.append({
                'type': '√âquation Comptable',
                'severity': 'Erreur',
                'message': f"Erreur validation: {str(e)}"
            })
        
        return issues
    
    def validate_profit_logic(self, df, mappings):
        """Contr√¥le logique : Profit = Revenue - Costs - VERSION CORRIG√âE"""
        issues = []
        
        try:
            if all(col in mappings for col in ['revenue', 'costs', 'profit']):
                revenue_col = mappings['revenue']
                costs_col = mappings['costs']
                profit_col = mappings['profit']
                
                if all(col in df.columns for col in [revenue_col, costs_col, profit_col]):
                    revenue = self.clean_numeric_column(df[revenue_col])
                    costs = self.clean_numeric_column(df[costs_col])
                    profit = self.clean_numeric_column(df[profit_col])
                    
                    if len(revenue) > 0 and len(costs) > 0 and len(profit) > 0:
                        calculated_profit = revenue - costs
                        differences = np.abs(profit - calculated_profit)
                        tolerance = revenue * 0.02
                        
                        # FIX: Conversion s√©curis√©e
                        violations = np.array(differences > tolerance, dtype=bool)
                        violation_count = int(np.sum(violations)) if len(violations) > 0 else 0
                        
                        if violation_count > 0:
                            issues.append({
                                'type': 'Logique Profit',
                                'severity': '√âlev√©e' if violation_count > len(df) * 0.2 else 'Moyenne',
                                'count': violation_count,
                                'message': f"{violation_count} incoh√©rences profit d√©tect√©es",
                                'violations': violations.tolist(),
                                'differences': differences.tolist(),
                                'calculated_profit': calculated_profit.tolist()
                            })
                        else:
                            issues.append({
                                'type': 'Logique Profit',
                                'severity': 'OK',
                                'message': "Logique profit respect√©e"
                            })
        except Exception as e:
            issues.append({
                'type': 'Logique Profit',
                'severity': 'Erreur',
                'message': f"Erreur validation: {str(e)}"
            })
        
        return issues
    
    def detect_extreme_variations(self, df, mappings):
        """V√©rification plausibilit√© : variations >100% p√©riode √† p√©riode"""
        issues = []
        
        key_metrics = ['revenue', 'costs', 'profit', 'assets']
        
        for metric in key_metrics:
            try:
                if metric in mappings:
                    col = mappings[metric]
                    if col in df.columns:
                        data = self.clean_numeric_column(df[col]).dropna()
                        
                        if len(data) > 1:
                            variations = data.pct_change().abs()
                            # FIX: Gestion s√©curis√©e des variations extr√™mes
                            extreme_variations = np.array(variations > self.variation_threshold, dtype=bool)
                            extreme_count = int(np.sum(extreme_variations)) if len(extreme_variations) > 0 else 0
                            
                            if extreme_count > 0:
                                max_variation = float(np.max(variations.dropna())) if len(variations.dropna()) > 0 else 0
                                
                                issues.append({
                                    'type': f'Variations Extr√™mes - {metric.title()}',
                                    'severity': '√âlev√©e' if max_variation > 2.0 else 'Moyenne',
                                    'count': extreme_count,
                                    'message': f"{extreme_count} variations >100% d√©tect√©es (max: {max_variation:.1%})",
                                    'extreme_indices': variations[extreme_variations].index.tolist(),
                                    'variations': variations.tolist()
                                })
            except Exception as e:
                issues.append({
                    'type': f'Variations Extr√™mes - {metric.title()}',
                    'severity': 'Erreur',
                    'message': f"Erreur validation: {str(e)}"
                })
        
        return issues
    
    def detect_outliers(self, df, mappings):
        """D√©tection outliers : valeurs >3 √©carts-types de la moyenne"""
        issues = []
        
        for metric, col in mappings.items():
            try:
                if col in df.columns:
                    data = self.clean_numeric_column(df[col]).dropna()
                    
                    if len(data) > 3:
                        mean_val = float(data.mean())
                        std_val = float(data.std())
                        
                        if std_val > 0:
                            z_scores = np.abs((data - mean_val) / std_val)
                            # FIX: Gestion s√©curis√©e des outliers
                            outliers = np.array(z_scores > self.outlier_threshold, dtype=bool)
                            outlier_count = int(np.sum(outliers)) if len(outliers) > 0 else 0
                            
                            if outlier_count > 0:
                                max_z_score = float(np.max(z_scores)) if len(z_scores) > 0 else 0
                                
                                issues.append({
                                    'type': f'Outliers - {metric.title()}',
                                    'severity': '√âlev√©e' if max_z_score > 5 else 'Moyenne',
                                    'count': outlier_count,
                                    'message': f"{outlier_count} valeurs aberrantes (max Z-score: {max_z_score:.1f})",
                                    'outlier_indices': data[outliers].index.tolist(),
                                    'outlier_values': data[outliers].tolist(),
                                    'z_scores': z_scores.tolist()
                                })
            except Exception as e:
                issues.append({
                    'type': f'Outliers - {metric.title()}',
                    'severity': 'Erreur',
                    'message': f"Erreur validation: {str(e)}"
                })
        
        return issues
    
    def clean_numeric_column(self, series):
        """Nettoyer les colonnes num√©riques avec gestion d'erreurs renforc√©e"""
        try:
            # Si d√©j√† num√©rique
            if pd.api.types.is_numeric_dtype(series):
                return pd.to_numeric(series, errors='coerce').fillna(0)
            
            # Nettoyer les strings
            cleaned = series.astype(str)
            cleaned = cleaned.str.replace(r'[$‚Ç¨¬£¬•‚Çπ‚ÇΩ]', '', regex=True)
            cleaned = cleaned.str.replace(',', '')
            cleaned = cleaned.str.replace(' ', '')
            cleaned = cleaned.str.replace(r'[^\d.-]', '', regex=True)
            
            # Convertir en num√©rique
            cleaned = pd.to_numeric(cleaned, errors='coerce').fillna(0)
            return cleaned
        except Exception:
            # En cas d'erreur, retourner une s√©rie de z√©ros
            return pd.Series([0] * len(series))
    
    def apply_outlier_correction(self, data, method='iqr'):
        """Corriger les valeurs aberrantes"""
        try:
            if len(data) < 4:
                return data, []
            
            corrected_data = data.copy()
            corrections = []
            
            if method == 'iqr':
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = (data < lower_bound) | (data > upper_bound)
                outlier_count = outliers.sum()
                
                if outlier_count > 0:
                    # Remplacer par la m√©diane
                    median_val = data.median()
                    corrected_data.loc[outliers] = median_val
                    
                    corrections.append({
                        'method': 'IQR Outlier Correction',
                        'outliers_found': int(outlier_count),
                        'replacement_value': float(median_val),
                        'basis': f'Q1={Q1:.2f}, Q3={Q3:.2f}, IQR={IQR:.2f}'
                    })
            
            elif method == 'zscore':
                z_scores = np.abs(stats.zscore(data))
                outliers = z_scores > 3
                outlier_count = outliers.sum()
                
                if outlier_count > 0:
                    mean_val = data.mean()
                    corrected_data.loc[outliers] = mean_val
                    
                    corrections.append({
                        'method': 'Z-Score Outlier Correction',
                        'outliers_found': int(outlier_count),
                        'replacement_value': float(mean_val),
                        'threshold_used': 3.0,
                        'basis': f'Mean={mean_val:.2f}, Std={data.std():.2f}'
                    })
            
            return corrected_data, corrections
        except Exception as e:
            return data, [{'method': 'Outlier Correction Failed', 'error': str(e)}]
    
    def apply_missing_value_interpolation(self, data, method='linear'):
        """Interpoler les valeurs manquantes"""
        try:
            if data.isnull().sum() == 0:
                return data, []
            
            corrected_data = data.copy()
            missing_count = data.isnull().sum()
            corrections = []
            
            if method == 'linear' and len(data.dropna()) >= 2:
                corrected_data = data.interpolate(method='linear')
                corrections.append({
                    'method': 'Linear Interpolation',
                    'missing_values_filled': int(missing_count),
                    'interpolation_method': 'linear'
                })
            
            elif method == 'forward_fill':
                corrected_data = data.fillna(method='ffill').fillna(method='bfill')
                corrections.append({
                    'method': 'Forward/Backward Fill',
                    'missing_values_filled': int(missing_count),
                    'interpolation_method': 'forward_fill'
                })
            
            else:
                # Fallback: remplir par la moyenne
                mean_val = data.mean()
                corrected_data = data.fillna(mean_val)
                corrections.append({
                    'method': 'Mean Imputation',
                    'missing_values_filled': int(missing_count),
                    'replacement_value': float(mean_val)
                })
            
            return corrected_data, corrections
        except Exception as e:
            return data, [{'method': 'Interpolation Failed', 'error': str(e)}]
    
    def apply_extreme_variation_smoothing(self, data, threshold=1.0):
        """Lisser les variations extr√™mes"""
        try:
            if len(data) < 3:
                return data, []
            
            corrected_data = data.copy()
            variations = data.pct_change().abs()
            extreme_mask = variations > threshold
            extreme_count = extreme_mask.sum()
            corrections = []
            
            if extreme_count > 0:
                # Appliquer un filtre Savitzky-Golay pour lisser
                window_length = min(5, len(data) if len(data) % 2 == 1 else len(data) - 1)
                if window_length >= 3:
                    smoothed = savgol_filter(data, window_length, 2)
                    
                    # Remplacer seulement les points avec variations extr√™mes
                    corrected_data.loc[extreme_mask] = smoothed[extreme_mask]
                    
                    corrections.append({
                        'method': 'Savitzky-Golay Smoothing',
                        'extreme_variations_smoothed': int(extreme_count),
                        'threshold_used': threshold,
                        'window_length': window_length
                    })
            
            return corrected_data, corrections
        except Exception as e:
            return data, [{'method': 'Smoothing Failed', 'error': str(e)}]
    
    def comprehensive_validation(self, df, mappings):
        """Validation compl√®te des donn√©es avec corrections automatiques"""
        all_issues = []
        all_corrections = []
        
        try:
            # Validation √©quation comptable
            accounting_issues = self.validate_accounting_equation(df, mappings)
            all_issues.extend(accounting_issues)
            
            # Validation logique profit
            profit_issues = self.validate_profit_logic(df, mappings)
            all_issues.extend(profit_issues)
            
            # D√©tection variations extr√™mes
            variation_issues = self.detect_extreme_variations(df, mappings)
            all_issues.extend(variation_issues)
            
            # D√©tection outliers
            outlier_issues = self.detect_outliers(df, mappings)
            all_issues.extend(outlier_issues)
            
            # Calculer score de qualit√© global
            quality_score = self.calculate_quality_score(all_issues, len(df))
            
            return {
                'issues': all_issues,
                'quality_score': quality_score,
                'total_issues': len(all_issues),
                'critical_issues': len([i for i in all_issues if i.get('severity') == '√âlev√©e']),
                'corrections_applied': all_corrections
            }
        except Exception as e:
            return {
                'issues': [{'type': 'Erreur G√©n√©rale', 'severity': 'Critique', 'message': f"Erreur validation: {str(e)}"}],
                'quality_score': 50,
                'total_issues': 1,
                'critical_issues': 1,
                'corrections_applied': []
            }

    def calculate_quality_score(self, issues, data_length):
        """Calculer score de qualit√© des donn√©es (0-100)"""
        if not issues:
            return 100
        
        penalty = 0
        for issue in issues:
            severity = issue.get('severity', 'Moyenne')
            if severity == '√âlev√©e' or severity == 'Critique':
                penalty += 20
            elif severity == 'Moyenne':
                penalty += 10
            elif severity == 'OK':
                penalty -= 5
        
        score = max(0, 100 - penalty)
        return min(100, score)

# ========== ENHANCED ML FORECASTING ENGINE ==========
class EnhancedMLForecastingEngine:
    """Moteur de pr√©vision ML avanc√© avec ensemble methods et validation crois√©e"""
    
    def __init__(self):
        self.models = {}
        self.best_model = None
        self.feature_importance = {}
        self.validation_scores = {}
        
    def prepare_features(self, data, include_seasonality=True, include_trend=True):
        """Pr√©parer les features pour l'entra√Ænement ML"""
        try:
            if len(data) < 3:
                return None, None
            
            features = []
            targets = []
            
            # Cr√©er des features temporelles
            for i in range(2, len(data)):
                feature_row = []
                
                # Features de base (lag features)
                feature_row.extend([
                    data[i-1],  # Valeur pr√©c√©dente
                    data[i-2],  # Valeur t-2
                ])
                
                # Tendance
                if include_trend and i >= 3:
                    trend = (data[i-1] - data[i-3]) / 2
                    feature_row.append(trend)
                
                # Saisonnalit√© simple
                if include_seasonality and len(data) >= 12:
                    seasonal_index = i % 12
                    feature_row.append(seasonal_index)
                
                # Moyenne mobile
                if i >= 3:
                    ma_3 = np.mean(data[i-3:i])
                    feature_row.append(ma_3)
                
                # Volatilit√© r√©cente
                if i >= 4:
                    recent_vol = np.std(data[i-4:i])
                    feature_row.append(recent_vol)
                
                features.append(feature_row)
                targets.append(data[i])
            
            return np.array(features), np.array(targets)
        except Exception as e:
            print(f"Erreur pr√©paration features: {e}")
            return None, None
    
    def create_ensemble_models(self):
        """Cr√©er un ensemble de mod√®les ML"""
        models = {}
        
        if ML_AVAILABLE:
            # Random Forest
            models['random_forest'] = Pipeline([
                ('scaler', StandardScaler()),
                ('rf', RandomForestRegressor(
                    n_estimators=100,
                    max_depth=10,
                    min_samples_split=5,
                    random_state=42
                ))
            ])
            
            # Linear Regression with Polynomial Features
            models['polynomial'] = Pipeline([
                ('poly', PolynomialFeatures(degree=2)),
                ('scaler', StandardScaler()),
                ('linear', LinearRegression())
            ])
            
            # Ridge Regression
            models['ridge'] = Pipeline([
                ('scaler', StandardScaler()),
                ('ridge', Ridge(alpha=1.0))
            ])
            
            # Ensemble Voting
            models['ensemble'] = VotingRegressor([
                ('rf', models['random_forest']),
                ('poly', models['polynomial']),
                ('ridge', models['ridge'])
            ])
        else:
            # Fallback simple models
            models['simple_linear'] = LinearRegression()
        
        return models
    
    def validate_models(self, X, y, cv_folds=3):
        """Validation crois√©e des mod√®les"""
        if X is None or y is None or len(X) < cv_folds:
            return {}
        
        models = self.create_ensemble_models()
        scores = {}
        
        try:
            # TimeSeriesSplit pour les donn√©es temporelles
            if ML_AVAILABLE and len(X) >= 6:
                tscv = TimeSeriesSplit(n_splits=min(cv_folds, len(X)//3))
            else:
                tscv = None
            
            for name, model in models.items():
                try:
                    if tscv and ML_AVAILABLE:
                        cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='r2')
                        scores[name] = {
                            'mean_score': np.mean(cv_scores),
                            'std_score': np.std(cv_scores),
                            'cv_scores': cv_scores.tolist()
                        }
                    else:
                        # Fallback simple validation
                        split_point = int(len(X) * 0.7)
                        X_train, X_test = X[:split_point], X[split_point:]
                        y_train, y_test = y[:split_point], y[split_point:]
                        
                        model.fit(X_train, y_train)
                        predictions = model.predict(X_test)
                        score = r2_score(y_test, predictions) if ML_AVAILABLE else 0.5
                        
                        scores[name] = {
                            'mean_score': score,
                            'std_score': 0.1,
                            'cv_scores': [score]
                        }
                except Exception as e:
                    scores[name] = {
                        'mean_score': 0.0,
                        'std_score': 1.0,
                        'cv_scores': [0.0],
                        'error': str(e)
                    }
            
            return scores
        except Exception as e:
            return {'error': f"Validation failed: {str(e)}"}
    
    def enhanced_forecast(self, data, periods, confidence_level=95, 
                         external_factors=None, business_constraints=None):
        """G√©n√©ration de pr√©visions avec mod√®les ensemble - VERSION CORRIG√âE"""
        try:
            if len(data) < 3:
                return None
            
            # Pr√©parer les donn√©es
            X, y = self.prepare_features(data)
            if X is None or y is None:
                return self.fallback_forecast(data, periods, confidence_level)
            
            # Valider les mod√®les
            model_scores = self.validate_models(X, y)
            
            # S√©lectionner le meilleur mod√®le
            best_model_name = self.select_best_model(model_scores)
            
            # Entra√Æner le meilleur mod√®le
            models = self.create_ensemble_models()
            best_model = models.get(best_model_name, models['random_forest'] if 'random_forest' in models else list(models.values())[0])
            
            try:
                best_model.fit(X, y)
                self.best_model = best_model
            except Exception as e:
                return self.fallback_forecast(data, periods, confidence_level)
            
            # G√©n√©rer les pr√©visions
            forecasts = []
            current_data = list(data)
            
            for period in range(periods):
                try:
                    # Pr√©parer les features pour cette pr√©diction
                    if len(current_data) >= 2:
                        feature_row = [
                            current_data[-1],
                            current_data[-2]
                        ]
                        
                        # Ajouter trend si disponible
                        if len(current_data) >= 3:
                            trend = (current_data[-1] - current_data[-3]) / 2
                            feature_row.append(trend)
                        
                        # Ajouter features suppl√©mentaires pour matcher X
                        while len(feature_row) < X.shape[1]:
                            feature_row.append(np.mean(current_data[-3:]) if len(current_data) >= 3 else current_data[-1])
                        
                        # Pr√©diction
                        prediction = best_model.predict([feature_row[:X.shape[1]]])[0]
                        
                        # Appliquer facteurs externes
                        if external_factors:
                            market_factor = external_factors.get('market_growth', 0)
                            economic_factor = external_factors.get('economic_impact', 1.0)
                            prediction = prediction * (1 + market_factor) * economic_factor
                        
                        # Appliquer contraintes business
                        if business_constraints:
                            max_growth = business_constraints.get('max_growth', 0.25)
                            min_growth = business_constraints.get('min_growth', -0.20)
                            
                            if len(current_data) > 0:
                                growth_rate = (prediction - current_data[-1]) / current_data[-1]
                                growth_rate = max(min_growth, min(max_growth, growth_rate))
                                prediction = current_data[-1] * (1 + growth_rate)
                        
                        # √âviter les valeurs n√©gatives
                        prediction = max(0, prediction)
                        
                        forecasts.append(float(prediction))
                        current_data.append(prediction)
                    else:
                        # Fallback si pas assez de donn√©es
                        last_value = current_data[-1] if current_data else 0
                        forecasts.append(float(last_value * 1.02))  # Croissance 2%
                        current_data.append(last_value * 1.02)
                        
                except Exception as e:
                    # Fallback pour cette pr√©diction
                    last_value = current_data[-1] if current_data else 0
                    forecasts.append(float(last_value))
                    current_data.append(last_value)
            
            # Calculer intervalles de confiance
            std_error = np.std(y - best_model.predict(X)) if len(y) > 1 else np.std(data) * 0.1
            confidence_multiplier = 1.96 if confidence_level == 95 else 2.58
            
            upper_bounds = [f + confidence_multiplier * std_error for f in forecasts]
            lower_bounds = [max(0, f - confidence_multiplier * std_error) for f in forecasts]
            
            # Calculer m√©triques de performance
            train_predictions = best_model.predict(X)
            performance_metrics = {
                'rmse': float(np.sqrt(mean_squared_error(y, train_predictions))) if ML_AVAILABLE else 0.0,
                'mae': float(mean_absolute_error(y, train_predictions)) if ML_AVAILABLE else 0.0,
                'r2_score': float(r2_score(y, train_predictions)) if ML_AVAILABLE else 0.7,
                'cv_score': model_scores.get(best_model_name, {}).get('mean_score', 0.0)
            }
            
            # Feature importance si disponible
            feature_importance = {}
            if hasattr(best_model, 'feature_importances_'):
                importance_values = best_model.feature_importances_
                feature_names = ['lag_1', 'lag_2', 'trend', 'seasonal', 'ma_3', 'volatility']
                for i, importance in enumerate(importance_values[:len(feature_names)]):
                    feature_importance[feature_names[i]] = float(importance)
            
            # FIX: S'assurer que tous les r√©sultats contiennent 'forecasts'
            results = {
                'forecasts': forecasts,
                'upper_bounds': upper_bounds,
                'lower_bounds': lower_bounds,
                'confidence_level': confidence_level,
                'periods': periods,
                'best_model': best_model_name,
                'model_performance': performance_metrics,
                'feature_importance': feature_importance,
                'model_scores': model_scores
            }
            
            return results
            
        except Exception as e:
            print(f"Erreur ML forecast: {e}")
            return self.fallback_forecast(data, periods, confidence_level)
    
    def fallback_forecast(self, data, periods, confidence_level):
        """M√©thode de pr√©vision de secours simple mais robuste"""
        try:
            if len(data) < 2:
                base_value = data[0] if data else 1000
                forecasts = [base_value] * periods
            else:
                # Calcul de tendance simple
                recent_data = data[-6:] if len(data) >= 6 else data
                if len(recent_data) >= 2:
                    trend = (recent_data[-1] - recent_data[0]) / (len(recent_data) - 1)
                else:
                    trend = 0
                
                forecasts = []
                last_value = data[-1]
                
                for i in range(periods):
                    forecast = last_value + trend * (i + 1)
                    forecast = max(0, forecast)  # √âviter valeurs n√©gatives
                    forecasts.append(float(forecast))
            
            # Intervalles de confiance simples
            std_error = np.std(data) * 0.1 if len(data) > 1 else np.mean(data) * 0.1
            confidence_multiplier = 1.96 if confidence_level == 95 else 2.58
            
            upper_bounds = [f + confidence_multiplier * std_error for f in forecasts]
            lower_bounds = [max(0, f - confidence_multiplier * std_error) for f in forecasts]
            
            # FIX: S'assurer que le fallback contient aussi 'forecasts'
            return {
                'forecasts': forecasts,
                'upper_bounds': upper_bounds,
                'lower_bounds': lower_bounds,
                'confidence_level': confidence_level,
                'periods': periods,
                'best_model': 'Simple Trend',
                'model_performance': {
                    'rmse': std_error,
                    'mae': std_error * 0.8,
                    'r2_score': 0.5,
                    'cv_score': 0.5
                },
                'feature_importance': {},
                'model_scores': {}
            }
        except Exception as e:
            # Derni√®re ligne de d√©fense
            fallback_value = 1000
            forecasts = [fallback_value] * periods
            return {
                'forecasts': forecasts,
                'upper_bounds': [f * 1.2 for f in forecasts],
                'lower_bounds': [f * 0.8 for f in forecasts],
                'confidence_level': confidence_level,
                'periods': periods,
                'best_model': 'Emergency Fallback',
                'model_performance': {'rmse': 0, 'mae': 0, 'r2_score': 0, 'cv_score': 0},
                'feature_importance': {},
                'model_scores': {}
            }
    
    def select_best_model(self, model_scores):
        """S√©lectionner le meilleur mod√®le bas√© sur les scores"""
        if not model_scores:
            return 'random_forest'
        
        best_model = None
        best_score = -float('inf')
        
        for model_name, scores in model_scores.items():
            if isinstance(scores, dict) and 'mean_score' in scores:
                score = scores['mean_score']
                if score > best_score:
                    best_score = score
                    best_model = model_name
        
        return best_model if best_model else list(model_scores.keys())[0]

# ========== ENHANCED SCENARIO CALIBRATOR ==========
class EnhancedScenarioCalibrator:
    """Calibrateur avanc√© pour planification de sc√©narios bas√© sur l'historique"""
    
    def __init__(self):
        self.historical_patterns = {}
        self.volatility_metrics = {}
        self.seasonal_patterns = {}
    
    def analyze_historical_volatility(self, data):
        """Analyser la volatilit√© historique pour calibrer les sc√©narios"""
        try:
            if len(data) < 3:
                return {
                    'volatility': 0.2,
                    'trend': 0.0,
                    'seasonality': False,
                    'coefficient_variation': 0.2
                }
            
            data_array = np.array(data)
            
            # Calculer volatilit√©
            returns = np.diff(data_array) / data_array[:-1]
            volatility = np.std(returns) if len(returns) > 0 else 0.2
            
            # Calculer tendance
            if len(data) >= 2:
                x = np.arange(len(data))
                slope, _ = np.polyfit(x, data_array, 1)
                trend = slope / np.mean(data_array) if np.mean(data_array) != 0 else 0
            else:
                trend = 0
            
            # D√©tecter saisonnalit√© simple
            seasonality = False
            if len(data) >= 12:
                monthly_means = []
                for month in range(12):
                    month_data = [data[i] for i in range(month, len(data), 12)]
                    if month_data:
                        monthly_means.append(np.mean(month_data))
                
                if len(monthly_means) == 12:
                    seasonal_cv = np.std(monthly_means) / np.mean(monthly_means)
                    seasonality = seasonal_cv > 0.1
            
            # Coefficient de variation
            coeff_var = np.std(data_array) / np.mean(data_array) if np.mean(data_array) != 0 else 0
            
            return {
                'volatility': float(volatility),
                'trend': float(trend),
                'seasonality': seasonality,
                'coefficient_variation': float(coeff_var),
                'mean_value': float(np.mean(data_array)),
                'data_points': len(data)
            }
        except Exception as e:
            return {
                'volatility': 0.2,
                'trend': 0.0,
                'seasonality': False,
                'coefficient_variation': 0.2,
                'error': str(e)
            }
    
    def calibrate_scenario_parameters(self, historical_analysis, industry='general'):
        """Calibrer les param√®tres de sc√©narios bas√©s sur l'analyse historique"""
        
        volatility = historical_analysis.get('volatility', 0.2)
        trend = historical_analysis.get('trend', 0.0)
        
        # Ajustements sp√©cifiques par industrie
        industry_adjustments = {
            'saas': {'volatility_multiplier': 0.8, 'growth_boost': 1.5},
            'retail': {'volatility_multiplier': 1.2, 'growth_boost': 0.8},
            'technology': {'volatility_multiplier': 1.0, 'growth_boost': 1.3},
            'manufacturing': {'volatility_multiplier': 0.9, 'growth_boost': 0.9}
        }
        
        adjustments = industry_adjustments.get(industry, {'volatility_multiplier': 1.0, 'growth_boost': 1.0})
        
        # Calibrer sc√©narios
        base_volatility = volatility * adjustments['volatility_multiplier']
        base_trend = trend * adjustments['growth_boost']
        
        scenarios = {
            'pessimistic': {
                'revenue_change': max(-0.30, base_trend - 2 * base_volatility),
                'cost_change': min(0.25, 0.15 + base_volatility),
                'probability': 0.20
            },
            'realistic': {
                'revenue_change': base_trend,
                'cost_change': 0.08 + base_volatility * 0.5,
                'probability': 0.60
            },
            'optimistic': {
                'revenue_change': min(0.50, base_trend + 1.5 * base_volatility),
                'cost_change': max(0.03, 0.05 - base_volatility * 0.3),
                'probability': 0.20
            }
        }
        
        return scenarios
    
    def apply_operational_constraints(self, scenarios, constraints):
        """Appliquer des contraintes op√©rationnelles aux sc√©narios"""
        
        max_revenue_decline = constraints.get('max_revenue_decline', -0.3)
        max_cost_increase = constraints.get('max_cost_increase', 0.25)
        min_margin = constraints.get('min_margin', -0.1)
        
        for scenario_name, params in scenarios.items():
            # Contraindre les changements de revenus
            params['revenue_change'] = max(max_revenue_decline, params['revenue_change'])
            
            # Contraindre les changements de co√ªts
            params['cost_change'] = min(max_cost_increase, params['cost_change'])
            
            # S'assurer qu'on respecte la marge minimale
            implied_margin = params['revenue_change'] - params['cost_change']
            if implied_margin < min_margin:
                # Ajuster les co√ªts pour respecter la marge minimale
                params['cost_change'] = params['revenue_change'] - min_margin
                params['cost_change'] = min(max_cost_increase, params['cost_change'])
        
        return scenarios
    
    def generate_monte_carlo_scenarios(self, base_data, n_simulations=1000, periods=12):
        """G√©n√©rer des sc√©narios Monte Carlo bas√©s sur l'historique"""
        
        if len(base_data) < 2:
            base_value = base_data[0] if base_data else 1000
            return [{'total_value': base_value * periods} for _ in range(n_simulations)]
        
        # Analyser patterns historiques
        returns = np.diff(base_data) / np.array(base_data[:-1])
        mean_return = np.mean(returns)
        std_return = np.std(returns)
        
        simulations = []
        
        for _ in range(n_simulations):
            path = [base_data[-1]]  # Commencer par la derni√®re valeur
            
            for period in range(periods):
                # G√©n√©rer un rendement al√©atoire
                random_return = np.random.normal(mean_return, std_return)
                
                # Appliquer des contraintes de r√©alisme
                random_return = max(-0.5, min(1.0, random_return))
                
                next_value = path[-1] * (1 + random_return)
                next_value = max(0, next_value)  # √âviter valeurs n√©gatives
                
                path.append(next_value)
            
            simulations.append({
                'path': path[1:],  # Exclure la valeur initiale
                'total_value': sum(path[1:]),
                'final_value': path[-1],
                'max_value': max(path[1:]),
                'min_value': min(path[1:])
            })
        
        return simulations

# ========== ADVANCED CSV PROCESSOR (Enhanced with Validation) ==========
class AdvancedCSVProcessor:
    """Processeur CSV avanc√© avec validation et correction automatique"""
    
    def __init__(self):
        self.column_mappings = {
            'revenue': ['revenue', 'sales', 'income', 'turnover', 'ca', 'chiffre_affaires'],
            'costs': ['costs', 'expenses', 'expenditure', 'charges', 'depenses'],
            'date': ['date', 'month', 'period', 'time', 'mois', 'periode'],
            'profit': ['profit', 'earnings', 'net_income', 'benefice', 'resultat'],
            'cash_flow': ['cash_flow', 'cash flow', 'cashflow', 'flux_tresorerie'],
            'assets': ['assets', 'total_assets', 'actifs', 'actif_total'],
            'current_assets': ['current_assets', 'actifs_courants', 'actif_circulant'],
            'fixed_assets': ['fixed_assets', 'actifs_fixes', 'immobilisations'],
            'liabilities': ['liabilities', 'total_liabilities', 'passifs', 'passif_total'],
            'current_liabilities': ['current_liabilities', 'passifs_courants', 'dettes_court_terme'],
            'equity': ['equity', 'shareholders_equity', 'capitaux_propres'],
            'inventory': ['inventory', 'stock', 'stocks'],
            'accounts_receivable': ['accounts_receivable', 'creances_clients', 'clients'],
            'accounts_payable': ['accounts_payable', 'dettes_fournisseurs', 'fournisseurs'],
            'customer_metrics': ['customer_count', 'customers', 'clients', 'nombre_clients'],
            'unit_metrics': ['units_sold', 'quantity', 'quantite', 'unites_vendues'],
            'pricing_metrics': ['average_price', 'price', 'prix_moyen', 'prix'],
            'saas_metrics': ['mrr', 'arr', 'monthly_recurring_revenue', 'annual_recurring_revenue']
        }
        
        self.validator = AdvancedDataValidator()
    
    def detect_columns(self, df):
        """D√©tection automatique am√©lior√©e des colonnes"""
        detected = {}
        
        for target, keywords in self.column_mappings.items():
            for col in df.columns:
                col_lower = col.lower().replace('_', ' ').replace('-', ' ').strip()
                for keyword in keywords:
                    if keyword.lower() in col_lower or col_lower in keyword.lower():
                        detected[target] = col
                        break
                if target in detected:
                    break
        
        return detected
    
    def clean_numeric_column(self, series):
        """Nettoyage avanc√© des colonnes num√©riques"""
        try:
            # Si d√©j√† num√©rique, v√©rifier les NaN
            if pd.api.types.is_numeric_dtype(series):
                return pd.to_numeric(series, errors='coerce').fillna(0)
            
            # Nettoyer les cha√Ænes
            cleaned = series.astype(str)
            
            # Supprimer symboles mon√©taires et espaces
            cleaned = cleaned.str.replace(r'[$‚Ç¨¬£¬•‚Çπ‚ÇΩ]', '', regex=True)
            cleaned = cleaned.str.replace(',', '')
            cleaned = cleaned.str.replace(' ', '')
            cleaned = cleaned.str.replace('%', '')
            
            # Garder seulement chiffres, points et tirets
            cleaned = cleaned.str.replace(r'[^\d.-]', '', regex=True)
            
            # Convertir en num√©rique
            cleaned = pd.to_numeric(cleaned, errors='coerce').fillna(0)
            
            return cleaned
        except Exception as e:
            # Fallback: retourner une s√©rie de z√©ros
            return pd.Series([0] * len(series))
    
    def calculate_comprehensive_metrics(self, df, mappings):
        """Calcul de m√©triques compl√®tes avec validation"""
        metrics = {}
        
        # M√©triques financi√®res de base
        for metric_type in ['revenue', 'costs', 'profit', 'cash_flow']:
            if metric_type in mappings and mappings[metric_type] in df.columns:
                col = mappings[metric_type]
                data = self.clean_numeric_column(df[col]).dropna()
                
                if len(data) > 0:
                    metrics[metric_type] = {
                        'total': float(data.sum()),
                        'average': float(data.mean()),
                        'median': float(data.median()),
                        'std': float(data.std()),
                        'min': float(data.min()),
                        'max': float(data.max()),
                        'growth_rate': 0.0,
                        'volatility': float(data.std() / data.mean()) if data.mean() != 0 else 0,
                        'data': data.tolist(),
                        'trend': 'stable'
                    }
                    
                    # Calculer taux de croissance
                    if len(data) > 1:
                        growth_rate = ((data.iloc[-1] / data.iloc[0]) - 1) * 100 if data.iloc[0] != 0 else 0
                        metrics[metric_type]['growth_rate'] = float(growth_rate)
                        
                        # D√©terminer tendance
                        if growth_rate > 5:
                            metrics[metric_type]['trend'] = 'croissance'
                        elif growth_rate < -5:
                            metrics[metric_type]['trend'] = 'declin'
        
        # Calculer m√©triques d√©riv√©es si revenus et co√ªts disponibles
        if 'revenue' in metrics and 'costs' in metrics:
            revenue_data = np.array(metrics['revenue']['data'])
            costs_data = np.array(metrics['costs']['data'])
            
            # S'assurer que les arrays ont la m√™me longueur
            min_length = min(len(revenue_data), len(costs_data))
            revenue_data = revenue_data[:min_length]
            costs_data = costs_data[:min_length]
            
            profit_data = revenue_data - costs_data
            
            metrics['profit'] = {
                'total': float(profit_data.sum()),
                'average': float(profit_data.mean()),
                'median': float(np.median(profit_data)),
                'std': float(np.std(profit_data)),
                'min': float(profit_data.min()),
                'max': float(profit_data.max()),
                'margin_average': float((profit_data.mean() / revenue_data.mean() * 100)) if revenue_data.mean() != 0 else 0,
                'data': profit_data.tolist(),
                'growth_rate': 0.0,
                'volatility': float(np.std(profit_data) / np.mean(profit_data)) if np.mean(profit_data) != 0 else 0
            }
            
            if len(profit_data) > 1:
                profit_growth = ((profit_data[-1] / profit_data[0]) - 1) * 100 if profit_data[0] != 0 else 0
                metrics['profit']['growth_rate'] = float(profit_growth)
        
        # M√©triques de bilan si disponibles
        balance_sheet_metrics = ['assets', 'liabilities', 'equity', 'current_assets', 'current_liabilities']
        for metric in balance_sheet_metrics:
            if metric in mappings and mappings[metric] in df.columns:
                col = mappings[metric]
                data = self.clean_numeric_column(df[col]).dropna()
                
                if len(data) > 0:
                    metrics[metric] = {
                        'average': float(data.mean()),
                        'latest': float(data.iloc[-1]) if len(data) > 0 else 0,
                        'data': data.tolist()
                    }
        
        # M√©triques business si disponibles
        business_metrics = ['customer_metrics', 'unit_metrics', 'pricing_metrics']
        for metric in business_metrics:
            if metric in mappings and mappings[metric] in df.columns:
                col = mappings[metric]
                data = self.clean_numeric_column(df[col]).dropna()
                
                if len(data) > 0:
                    metrics[metric] = {
                        'average': float(data.mean()),
                        'growth_rate': 0.0,
                        'data': data.tolist()
                    }
                    
                    if len(data) > 1:
                        growth = ((data.iloc[-1] / data.iloc[0]) - 1) * 100 if data.iloc[0] != 0 else 0
                        metrics[metric]['growth_rate'] = float(growth)
        
        return metrics
    
    def generate_enhanced_insights(self, metrics, validation_results=None):
        """G√©n√©ration d'insights am√©lior√©s avec contexte de validation"""
        insights = []
        recommendations = []
        alerts = []
        
        # Insights bas√©s sur les m√©triques
        if 'revenue' in metrics:
            revenue_growth = metrics['revenue'].get('growth_rate', 0)
            revenue_volatility = metrics['revenue'].get('volatility', 0)
            
            if revenue_growth > 20:
                insights.append(f"üöÄ **Forte croissance** : {revenue_growth:.1f}% d'augmentation du CA")
            elif revenue_growth > 5:
                insights.append(f"üìà **Croissance positive** : {revenue_growth:.1f}% sur la p√©riode")
            elif revenue_growth > -5:
                insights.append(f"üìä **Revenus stables** : {revenue_growth:.1f}% de variation")
            else:
                alerts.append(f"üìâ **D√©clin significatif** : {abs(revenue_growth):.1f}% de baisse du CA")
            
            if revenue_volatility < 0.1:
                insights.append("üéØ **Revenus tr√®s pr√©visibles** : Faible volatilit√©")
            elif revenue_volatility > 0.3:
                alerts.append("‚ö†Ô∏è **Revenus volatils** : Forte variabilit√© d√©tect√©e")
        
        if 'profit' in metrics:
            profit_margin = metrics['profit'].get('margin_average', 0)
            profit_growth = metrics['profit'].get('growth_rate', 0)
            
            if profit_margin > 20:
                insights.append(f"üí∞ **Excellentes marges** : {profit_margin:.1f}% de marge b√©n√©ficiaire")
            elif profit_margin > 10:
                insights.append(f"üíµ **Bonnes marges** : {profit_margin:.1f}% de rentabilit√©")
            elif profit_margin > 0:
                insights.append(f"üìà **Marges positives** : {profit_margin:.1f}% de marge")
            else:
                alerts.append(f"üî¥ **Marges n√©gatives** : {profit_margin:.1f}% - Entreprise d√©ficitaire")
            
            if profit_growth > 15:
                insights.append(f"üéâ **Croissance rentabilit√©** : {profit_growth:.1f}% d'am√©lioration")
            elif profit_growth < -15:
                alerts.append(f"üìâ **D√©t√©rioration profits** : {abs(profit_growth):.1f}% de baisse")
        
        # Recommandations bas√©es sur l'analyse
        if 'revenue' in metrics and 'costs' in metrics:
            revenue_trend = metrics['revenue'].get('trend', 'stable')
            
            if revenue_trend == 'declin':
                recommendations.append("üéØ **Strat√©gie CA** : Analyser causes du d√©clin et revoir strat√©gie commerciale")
            elif revenue_trend == 'stable':
                recommendations.append("üìà **Acc√©l√©ration croissance** : Identifier opportunit√©s d'expansion")
            
            avg_revenue = metrics['revenue'].get('average', 0)
            avg_costs = metrics['costs'].get('average', 0)
            
            if avg_costs > avg_revenue * 0.8:
                recommendations.append("‚úÇÔ∏è **Optimisation co√ªts** : Structure de co√ªts √©lev√©e - opportunit√©s d'√©conomies")
        
        # Insights sp√©cifiques validation des donn√©es
        if validation_results:
            quality_score = validation_results.get('quality_score', 100)
            
            if quality_score >= 90:
                insights.append("‚úÖ **Donn√©es de haute qualit√©** : Analyses tr√®s fiables")
            elif quality_score >= 70:
                insights.append("üìä **Donn√©es de qualit√© correcte** : Analyses globalement fiables")
            else:
                alerts.append("‚ö†Ô∏è **Qualit√© donn√©es limit√©e** : Interpr√©ter r√©sultats avec prudence")
            
            critical_issues = validation_results.get('critical_issues', 0)
            if critical_issues > 0:
                alerts.append(f"üî¥ **{critical_issues} incoh√©rence(s) critique(s)** d√©tect√©e(s)")
        
        return {
            'insights': insights,
            'recommendations': recommendations,
            'alerts': alerts
        }
    
    def create_enhanced_visualizations(self, df, mappings, metrics):
        """Cr√©ation de visualisations avanc√©es avec contexte m√©tier"""
        figures = {}
        
        try:
            # Graphique principal des tendances financi√®res
            fig = go.Figure()
            
            # Pr√©parer l'axe X
            if 'date' in mappings and mappings['date'] in df.columns:
                x_axis = pd.to_datetime(df[mappings['date']], errors='coerce')
                if x_axis.isnull().all():
                    x_axis = range(len(df))
                x_title = "Date"
            else:
                x_axis = range(len(df))
                x_title = "P√©riode"
            
            # Ajouter les courbes principales
            colors = {'revenue': '#2E8B57', 'costs': '#DC143C', 'profit': '#4169E1', 'cash_flow': '#FF8C00'}
            
            for metric in ['revenue', 'costs', 'profit', 'cash_flow']:
                if metric in mappings and mappings[metric] in df.columns:
                    data = self.clean_numeric_column(df[mappings[metric]])
                    
                    fig.add_trace(go.Scatter(
                        x=x_axis,
                        y=data,
                        mode='lines+markers',
                        name=metric.title().replace('_', ' '),
                        line=dict(color=colors.get(metric, '#666666'), width=3),
                        marker=dict(size=6),
                        hovertemplate=f"<b>{metric.title()}</b><br>" +
                                    f"{x_title}: %{{x}}<br>" +
                                    "Valeur: %{y:,.0f} DHS<extra></extra>"
                    ))
            
            # Configuration du graphique
            fig.update_layout(
                title="Performance Financi√®re - Tendances Temporelles",
                xaxis_title=x_title,
                yaxis_title="Montant (DHS)",
                height=600,
                hovermode='x unified',
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                )
            )
            
            # Ajouter ligne de r√©f√©rence z√©ro pour le profit
            fig.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
            
            figures['financial_trend'] = fig
            
            # Graphique de r√©partition si donn√©es disponibles
            if 'revenue' in metrics and 'costs' in metrics:
                avg_revenue = metrics['revenue']['average']
                avg_costs = metrics['costs']['average']
                avg_profit = avg_revenue - avg_costs
                
                fig_pie = go.Figure(data=[go.Pie(
                    labels=['Co√ªts', 'Profit'],
                    values=[avg_costs, max(0, avg_profit)],
                    hole=0.3,
                    marker_colors=['#DC143C', '#2E8B57']
                )])
                
                fig_pie.update_layout(
                    title="R√©partition Moyenne : Co√ªts vs Profit",
                    annotations=[dict(text=f'{(avg_profit/avg_revenue*100):.1f}%<br>Marge', 
                                    x=0.5, y=0.5, font_size=16, showarrow=False)]
                )
                
                figures['cost_profit_breakdown'] = fig_pie
            
            # Graphique de volatilit√© si plusieurs m√©triques
            volatility_data = []
            volatility_labels = []
            
            for metric in ['revenue', 'costs', 'profit']:
                if metric in metrics and 'volatility' in metrics[metric]:
                    volatility_data.append(metrics[metric]['volatility'] * 100)
                    volatility_labels.append(metric.title())
            
            if len(volatility_data) >= 2:
                fig_vol = go.Figure(data=[
                    go.Bar(x=volatility_labels, y=volatility_data, 
                          marker_color=['#2E8B57', '#DC143C', '#4169E1'][:len(volatility_data)])
                ])
                
                fig_vol.update_layout(
                    title="Analyse de Volatilit√© par M√©trique",
                    xaxis_title="M√©triques",
                    yaxis_title="Coefficient de Variation (%)",
                    height=400
                )
                
                figures['volatility_analysis'] = fig_vol
            
        except Exception as e:
            # En cas d'erreur, cr√©er un graphique de base
            st.warning(f"Erreur cr√©ation visualisations avanc√©es: {str(e)}")
            
            # Graphique de secours
            fig_basic = go.Figure()
            if 'revenue' in mappings and mappings['revenue'] in df.columns:
                revenue_data = self.clean_numeric_column(df[mappings['revenue']])
                fig_basic.add_trace(go.Scatter(
                    x=list(range(len(revenue_data))),
                    y=revenue_data,
                    mode='lines+markers',
                    name='Revenue'
                ))
            
            fig_basic.update_layout(title="Donn√©es Financi√®res (Vue Simplifi√©e)")
            figures['financial_trend'] = fig_basic
        
        return figures
    
    def process_csv(self, df):
        """Traitement complet du CSV avec validation et correction automatiques"""
        try:
            # √âtape 1: D√©tection des colonnes
            mappings = self.detect_columns(df)
            
            # √âtape 2: Validation avanc√©e avec le nouveau syst√®me
            validation_results = self.validator.comprehensive_validation(df, mappings)
            
            # √âtape 3: Application des corrections si n√©cessaire
            corrections_applied = False
            correction_log = []
            
            # Corriger les outliers si d√©tect√©s
            for issue in validation_results.get('issues', []):
                if 'Outliers' in issue.get('type', '') and issue.get('severity') == '√âlev√©e':
                    metric = issue['type'].split(' - ')[1].lower()
                    if metric in mappings and mappings[metric] in df.columns:
                        col = mappings[metric]
                        original_data = self.clean_numeric_column(df[col])
                        corrected_data, corrections = self.validator.apply_outlier_correction(original_data)
                        
                        if corrections:
                            df[col] = corrected_data
                            correction_log.extend(corrections)
                            corrections_applied = True
            
            # √âtape 4: Calcul des m√©triques sur les donn√©es corrig√©es
            metrics = self.calculate_comprehensive_metrics(df, mappings)
            
            # √âtape 5: G√©n√©ration d'insights avec contexte de validation
            insights_data = self.generate_enhanced_insights(metrics, validation_results)
            
            # √âtape 6: Cr√©ation des visualisations
            figures = self.create_enhanced_visualizations(df, mappings, metrics)
            
            # √âtape 7: G√©n√©rer suggestions d'am√©lioration
            suggestions = self.generate_improvement_suggestions(metrics, validation_results)
            
            # √âtape 8: Identifier probl√®mes potentiels
            issues = self.identify_potential_issues(metrics, validation_results)
            
            return {
                'mappings': mappings,
                'metrics': metrics,
                'insights': insights_data,
                'figures': figures,
                'issues': issues,
                'suggestions': suggestions,
                'processed_df': df,
                'validation_results': validation_results,
                'corrections_applied': corrections_applied,
                'correction_log': correction_log
            }
            
        except Exception as e:
            return {
                'mappings': {},
                'metrics': {},
                'insights': {'insights': [], 'recommendations': [], 'alerts': []},
                'figures': {},
                'issues': [f"Erreur traitement CSV: {str(e)}"],
                'suggestions': ["V√©rifier format du fichier CSV"],
                'processed_df': df,
                'validation_results': {'quality_score': 50, 'total_issues': 1, 'critical_issues': 1, 'issues': []},
                'corrections_applied': False,
                'correction_log': []
            }
    
    def generate_improvement_suggestions(self, metrics, validation_results):
        """G√©n√©rer des suggestions d'am√©lioration bas√©es sur l'analyse"""
        suggestions = []
        
        try:
            # Suggestions bas√©es sur la qualit√© des donn√©es
            if validation_results:
                quality_score = validation_results.get('quality_score', 100)
                
                if quality_score < 70:
                    suggestions.append("üîß **Am√©lioration qualit√©** : Revoir processus de collecte des donn√©es")
                
                if validation_results.get('critical_issues', 0) > 0:
                    suggestions.append("‚ö†Ô∏è **Correction urgente** : R√©soudre incoh√©rences critiques d√©tect√©es")
            
            # Suggestions bas√©es sur les m√©triques business
            if 'revenue' in metrics:
                revenue_volatility = metrics['revenue'].get('volatility', 0)
                revenue_growth = metrics['revenue'].get('growth_rate', 0)
                
                if revenue_volatility > 0.3:
                    suggestions.append("üìä **Stabilisation CA** : Diversifier sources de revenus pour r√©duire volatilit√©")
                
                if revenue_growth < 0:
                    suggestions.append("üìà **Relance croissance** : D√©velopper strat√©gies d'acquisition clients")
                elif revenue_growth < 5:
                    suggestions.append("üöÄ **Acc√©l√©ration** : Identifier leviers de croissance suppl√©mentaires")
            
            if 'profit' in metrics:
                margin = metrics['profit'].get('margin_average', 0)
                
                if margin < 5:
                    suggestions.append("üí∞ **Optimisation marges** : Revoir structure de co√ªts et pricing")
                elif margin < 15:
                    suggestions.append("üíé **Am√©lioration rentabilit√©** : Opportunit√©s d'optimisation identifi√©es")
            
            # Suggestions sp√©cifiques selon type de business d√©tect√©
            if self.detect_business_type(metrics) == 'saas':
                suggestions.append("‚òÅÔ∏è **M√©triques SaaS** : Tracker MRR, churn rate et LTV/CAC")
            elif self.detect_business_type(metrics) == 'retail':
                suggestions.append("üõçÔ∏è **Optimisation retail** : Focus sur rotation stocks et saisonnalit√©")
            
        except Exception as e:
            suggestions.append(f"Erreur g√©n√©ration suggestions: {str(e)}")
        
        return suggestions
    
    def identify_potential_issues(self, metrics, validation_results):
        """Identifier les probl√®mes potentiels dans les donn√©es"""
        issues = []
        
        try:
            # Issues li√©s √† la validation
            if validation_results:
                for issue in validation_results.get('issues', []):
                    if issue.get('severity') in ['√âlev√©e', 'Critique']:
                        issues.append(f"‚ùå {issue.get('type', 'Probl√®me')}: {issue.get('message', '')}")
            
            # Issues business
            if 'profit' in metrics:
                margin = metrics['profit'].get('margin_average', 0)
                if margin < 0:
                    issues.append("üî¥ **Rentabilit√© critique** : Entreprise en perte")
                elif margin < 2:
                    issues.append("‚ö†Ô∏è **Marges faibles** : Risque de rentabilit√©")
            
            if 'revenue' in metrics:
                growth = metrics['revenue'].get('growth_rate', 0)
                if growth < -20:
                    issues.append("üìâ **D√©clin s√©v√®re** : Chute importante du chiffre d'affaires")
                elif growth < -10:
                    issues.append("üìâ **D√©clin** : Baisse significative des revenus")
            
            # Issues de coh√©rence
            if 'revenue' in metrics and 'costs' in metrics:
                avg_costs = metrics['costs'].get('average', 0)
                avg_revenue = metrics['revenue'].get('average', 1)
                
                if avg_costs > avg_revenue:
                    issues.append("‚ö†Ô∏è **Structure co√ªts** : Co√ªts sup√©rieurs aux revenus en moyenne")
        
        except Exception as e:
            issues.append(f"Erreur identification issues: {str(e)}")
        
        return issues
    
    def detect_business_type(self, metrics):
        """D√©tecter le type de business bas√© sur les m√©triques"""
        try:
            if 'profit' in metrics:
                margin = metrics['profit'].get('margin_average', 0)
                
                # Marges √©lev√©es sugg√®rent SaaS/Software
                if margin > 20:
                    return 'saas'
                # Marges faibles sugg√®rent retail
                elif margin < 8:
                    return 'retail'
                # Marges moyennes sugg√®rent services/tech
                else:
                    return 'services'
            
            return 'general'
        except:
            return 'general'

# ========== CSV TEMPLATE GENERATOR ==========
class CSVTemplateGenerator:
    """G√©n√©rateur de templates CSV pour diff√©rents types d'entreprises"""
    
    def __init__(self):
        self.templates = {
            'complete_financial': {
                'name': 'Complete Financial Data Template',
                'description': 'Template complet avec toutes les m√©triques financi√®res pour analyse maximale',
                'columns': {
                    'Date': 'Format YYYY-MM-DD (ex: 2024-01-01)',
                    'Revenue': 'Chiffre d\'affaires mensuel en devise locale (chiffres uniquement)',
                    'Sales': 'Colonne alternative revenus (utiliser si pr√©f√©r√©)',
                    'Costs': 'Total co√ªts/charges mensuels',
                    'Variable_Costs': 'Co√ªts variables (√©voluent avec les ventes)',
                    'Fixed_Costs': 'Co√ªts fixes (constants)',
                    'Profit': 'B√©n√©fice net (Revenus - Co√ªts)',
                    'Cash_Flow': 'Flux de tr√©sorerie net du mois',
                    'Assets': 'Total actifs en fin de mois',
                    'Current_Assets': 'Actifs court terme (tr√©sorerie, stocks, etc.)',
                    'Fixed_Assets': 'Actifs long terme (√©quipements, immobilier)',
                    'Liabilities': 'Total passifs',
                    'Current_Liabilities': 'Dettes et obligations court terme',
                    'Equity': 'Capitaux propres/fonds propres',
                    'Inventory': 'Valeur des stocks/inventaire',
                    'Accounts_Receivable': 'Cr√©ances clients',
                    'Accounts_Payable': 'Dettes fournisseurs',
                    'Customer_Count': 'Nombre de clients actifs',
                    'Units_Sold': 'Quantit√© produits/services vendus',
                    'Average_Price': 'Prix moyen par unit√©/service'
                },
                'sample_data': [
                    ['2025-01-01', 15000, 15000, 12000, 8000, 4000, 3000, 2500, 50000, 20000, 30000, 20000, 8000, 30000, 5000, 8000, 6000, 150, 300, 50],
                    ['2025-02-01', 16500, 16500, 13100, 8800, 4300, 3400, 3200, 52000, 21000, 31000, 21000, 8500, 31000, 5200, 8500, 6200, 165, 330, 50],
                    ['2025-03-01', 14200, 14200, 11800, 7600, 4200, 2400, 2100, 51500, 20500, 31000, 20800, 8300, 30700, 5100, 8200, 6100, 158, 284, 50]
                ]
            },
            'saas_template': {
                'name': 'SaaS Business Template',
                'description': 'Template sp√©cialis√© pour entreprises Software as a Service',
                'columns': {
                    'Date': 'Format YYYY-MM-DD',
                    'Monthly_Recurring_Revenue': 'MRR - revenus r√©currents mensuels pr√©visibles',
                    'Customer_Count': 'Total abonn√©s actifs',
                    'Churn_Rate': 'Taux de churn mensuel (pourcentage en d√©cimal)',
                    'Customer_Acquisition_Cost': 'CAC - co√ªt d\'acquisition d\'un client',
                    'Lifetime_Value': 'LTV - valeur vie moyenne d\'un client',
                    'Costs': 'Total co√ªts op√©rationnels mensuels'
                },
                'sample_data': [
                    ['2025-01-01', 12000, 400, 0.05, 150, 1800, 9000],
                    ['2025-02-01', 13200, 440, 0.05, 140, 1850, 9900],
                    ['2025-03-01', 14100, 470, 0.053, 160, 1820, 10500]
                ]
            }
        }
    
    def generate_template_csv(self, template_type):
        """G√©n√©rer un template CSV avec formatage appropri√©"""
        template = self.templates.get(template_type)
        if not template:
            return None
        
        columns = list(template['columns'].keys())
        df = pd.DataFrame(template['sample_data'], columns=columns)
        
        csv_buffer = BytesIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8')
        csv_buffer.seek(0)
        
        return csv_buffer.getvalue()

# ========== ENHANCED ANALYTICS ENGINE ==========
class AdvancedAnalytics:
    """Moteur d'analytics avanc√© avec calculs de ratios et recommandations IA"""
    
    def __init__(self):
        self.ratios_weights = {
            'liquidity': 0.3,
            'profitability': 0.4,
            'efficiency': 0.2,
            'leverage': 0.1
        }
        self.ml_engine = EnhancedMLForecastingEngine()
        self.scenario_calibrator = EnhancedScenarioCalibrator()
    
    @staticmethod
    def monte_carlo_simulation(base_revenue, base_costs, volatility=0.2, simulations=1000, periods=12):
        """Simulation Monte Carlo avanc√©e avec corr√©lation et contraintes business"""
        results = []
        correlation = 0.6
        
        for _ in range(simulations):
            revenue_path = []
            cost_path = []
            
            z1 = np.random.normal(0, 1, periods)
            z2 = np.random.normal(0, 1, periods)
            
            for period in range(periods):
                revenue_shock = z1[period] * volatility
                cost_shock = (correlation * z1[period] + 
                             np.sqrt(1 - correlation**2) * z2[period]) * volatility * 0.8
                
                # Appliquer contraintes business
                revenue_shock = max(-0.5, min(1.0, revenue_shock))
                cost_shock = max(-0.3, min(0.5, cost_shock))
                
                if period == 0:
                    revenue = base_revenue * (1 + revenue_shock)
                    cost = base_costs * (1 + cost_shock)
                else:
                    revenue = revenue_path[-1] * (1 + revenue_shock)
                    cost = cost_path[-1] * (1 + cost_shock)
                
                revenue_path.append(max(revenue, 0))
                cost_path.append(max(cost, 0))
            
            total_revenue = sum(revenue_path)
            total_cost = sum(cost_path)
            net_profit = total_revenue - total_cost
            
            results.append({
                'total_revenue': total_revenue,
                'total_cost': total_cost,
                'net_profit': net_profit,
                'revenue_path': revenue_path,
                'cost_path': cost_path,
                'max_drawdown': min(np.cumsum([r-c for r,c in zip(revenue_path, cost_path)])),
                'profit_margin': (net_profit / total_revenue * 100) if total_revenue > 0 else -100
            })
        
        return pd.DataFrame(results)
    
    def calculate_comprehensive_ratios(self, financial_data):
        """Calculer ratios financiers complets avec validation renforc√©e"""
        ratios = {}
        
        # Ratios de liquidit√© avec validation
        current_assets = float(financial_data.get('current_assets', 0))
        current_liabilities = max(float(financial_data.get('current_liabilities', 1)), 1)
        inventory = float(financial_data.get('inventory', 0))
        cash = float(financial_data.get('cash', 0))
        
        ratios['current_ratio'] = current_assets / current_liabilities
        ratios['quick_ratio'] = (current_assets - inventory) / current_liabilities
        ratios['cash_ratio'] = cash / current_liabilities
        
        # Ratios de rentabilit√© avec calculs avanc√©s
        revenue = max(float(financial_data.get('revenue', 1)), 1)
        gross_profit = float(financial_data.get('gross_profit', 0))
        operating_profit = float(financial_data.get('operating_profit', 0))
        net_profit = float(financial_data.get('net_profit', 0))
        total_assets = max(float(financial_data.get('total_assets', 1)), 1)
        equity = max(float(financial_data.get('equity', 1)), 1)
        
        ratios['gross_margin'] = gross_profit / revenue
        ratios['operating_margin'] = operating_profit / revenue
        ratios['net_margin'] = net_profit / revenue
        ratios['roa'] = net_profit / total_assets
        ratios['roe'] = net_profit / equity
        
        # Ratios d'efficacit√©
        ratios['asset_turnover'] = revenue / total_assets
        ratios['equity_turnover'] = revenue / equity
        
        # Ratios de levier avec validation renforc√©e
        total_debt = float(financial_data.get('total_debt', 0))
        ratios['debt_to_equity'] = total_debt / equity
        ratios['debt_to_assets'] = total_debt / total_assets
        ratios['equity_multiplier'] = total_assets / equity
        
        # Ratios de couverture
        interest_expense = max(float(financial_data.get('interest_expense', 1)), 1)
        ratios['interest_coverage'] = operating_profit / interest_expense
        
        # Valider ratios pour outliers
        for ratio_name, ratio_value in ratios.items():
            if np.isnan(ratio_value) or np.isinf(ratio_value):
                ratios[ratio_name] = 0
            elif ratio_value > 1000:
                ratios[ratio_name] = 1000
            elif ratio_value < -1000:
                ratios[ratio_name] = -1000
        
        return ratios
    
    def calculate_financial_health_score(self, ratios, industry='general', validation_results=None):
        """Calculer score sant√© financi√®re avanc√© avec ajustements validation"""
        industry_benchmarks = self.get_industry_benchmarks(industry)
        
        scores = {}
        
        # Score liquidit√© (0-25) avec pond√©ration avanc√©e
        current_ratio_score = min(25, (ratios.get('current_ratio', 0) / industry_benchmarks['current_ratio']) * 15)
        quick_ratio_score = min(10, (ratios.get('quick_ratio', 0) / industry_benchmarks.get('quick_ratio', 1.0)) * 10)
        scores['liquidity'] = current_ratio_score + quick_ratio_score
        
        # Score rentabilit√© (0-40) avec m√©triques avanc√©es
        net_margin_score = min(20, max(0, (ratios.get('net_margin', 0) / industry_benchmarks['net_margin']) * 20))
        roa_score = min(10, max(0, (ratios.get('roa', 0) / industry_benchmarks['roa']) * 10))
        roe_score = min(10, max(0, (ratios.get('roe', 0) / industry_benchmarks['roe']) * 10))
        scores['profitability'] = net_margin_score + roa_score + roe_score
        
        # Score efficacit√© (0-20)
        asset_turnover_score = min(20, max(0, (ratios.get('asset_turnover', 0) / industry_benchmarks['asset_turnover']) * 20))
        scores['efficiency'] = asset_turnover_score
        
        # Score levier (0-15) avec logique avanc√©e
        debt_ratio = ratios.get('debt_to_equity', 0)
        if debt_ratio <= industry_benchmarks['debt_to_equity']:
            leverage_score = 15
        else:
            leverage_score = max(0, 15 - (debt_ratio - industry_benchmarks['debt_to_equity']) * 30)
        scores['leverage'] = leverage_score
        
        # Appliquer ajustement qualit√© donn√©es
        quality_adjustment = 1.0
        if validation_results:
            quality_score = validation_results.get('quality_score', 100)
            if quality_score < 70:
                quality_adjustment = quality_score / 100
                scores['data_quality_penalty'] = (100 - quality_score) * 0.2
        
        total_score = sum(scores.values()) * quality_adjustment
        return min(100, max(0, total_score)), scores
    
    def get_industry_benchmarks(self, industry):
        """Obtenir benchmarks sp√©cifiques par industrie avanc√©s"""
        benchmarks = {
            'general': {
                'current_ratio': 1.5, 'quick_ratio': 1.0, 'net_margin': 0.08,
                'roa': 0.06, 'roe': 0.12, 'asset_turnover': 1.2, 'debt_to_equity': 0.4
            },
            'retail': {
                'current_ratio': 1.2, 'quick_ratio': 0.8, 'net_margin': 0.05,
                'roa': 0.04, 'roe': 0.15, 'asset_turnover': 2.5, 'debt_to_equity': 0.6
            },
            'technology': {
                'current_ratio': 2.0, 'quick_ratio': 1.8, 'net_margin': 0.15,
                'roa': 0.12, 'roe': 0.18, 'asset_turnover': 0.8, 'debt_to_equity': 0.2
            },
            'saas': {
                'current_ratio': 1.8, 'quick_ratio': 1.6, 'net_margin': 0.20,
                'roa': 0.15, 'roe': 0.25, 'asset_turnover': 0.6, 'debt_to_equity': 0.1
            },
            'manufacturing': {
                'current_ratio': 1.4, 'quick_ratio': 0.9, 'net_margin': 0.08,
                'roa': 0.06, 'roe': 0.14, 'asset_turnover': 1.5, 'debt_to_equity': 0.8
            }
        }
        return benchmarks.get(industry, benchmarks['general'])
    
    def generate_ai_recommendations(self, financial_data, ratios, health_score, validation_results=None):
        """G√©n√©rer recommandations IA avanc√©es avec insights validation - VERSION CORRIG√âE"""
        recommendations = []
        
        try:
            # Syst√®me de recommandations par priorit√©
            high_priority = []
            medium_priority = []
            low_priority = []
            
            # Recommandations qualit√© donn√©es
            if validation_results:
                quality_score = validation_results.get('quality_score', 100)
                if quality_score < 50:
                    high_priority.append({
                        'category': 'Qualit√© des donn√©es',
                        'priority': 'Critique',
                        'recommendation': 'Am√©lioration urgente de la qualit√© des donn√©es requise. V√©rifier et corriger les incoh√©rences d√©tect√©es.',
                        'impact': 'Tr√®s √âlev√©',
                        'timeframe': 'Imm√©diat',
                        'estimated_benefit': 10000  # FIX: Valeur num√©rique fixe
                    })
                elif quality_score < 80:
                    medium_priority.append({
                        'category': 'Validation des donn√©es',
                        'priority': 'Moyenne',
                        'recommendation': 'R√©viser les processus de saisie des donn√©es pour am√©liorer la coh√©rence.',
                        'impact': 'Moyen',
                        'timeframe': '1-2 semaines',
                        'estimated_benefit': 5000  # FIX: Valeur num√©rique fixe
                    })
            
            # Recommandations cash flow
            cash_flow = financial_data.get('cash_flow', 0)
            if isinstance(cash_flow, (int, float)) and cash_flow < 0:
                high_priority.append({
                    'category': 'Gestion de tr√©sorerie',
                    'priority': 'Critique',
                    'recommendation': 'Am√©lioration imm√©diate du cash-flow n√©cessaire. Actions : 1) Acc√©l√©rer l\'encaissement clients, 2) √âtendre les d√©lais fournisseurs, 3) R√©duire les d√©penses non essentielles, 4) Financement d\'urgence.',
                    'impact': 'Tr√®s √âlev√©',
                    'timeframe': 'Imm√©diat',
                    'estimated_benefit': abs(float(cash_flow)) * 0.5 if isinstance(cash_flow, (int, float)) else 5000
                })
            
            # Recommandations liquidit√© avec logique avanc√©e
            current_ratio = ratios.get('current_ratio', 0)
            if isinstance(current_ratio, (int, float)):
                if current_ratio < 1.0:
                    high_priority.append({
                        'category': 'Liquidit√© critique',
                        'priority': 'Critique',
                        'recommendation': 'Liquidit√© insuffisante pour couvrir les obligations √† court terme. Actions imm√©diates requises.',
                        'impact': 'Tr√®s √âlev√©',
                        'timeframe': 'Imm√©diat',
                        'estimated_benefit': float(financial_data.get('current_liabilities', 10000)) * 0.2
                    })
                elif current_ratio < 1.2:
                    high_priority.append({
                        'category': 'Am√©lioration de la liquidit√©',
                        'priority': '√âlev√©e',
                        'recommendation': 'Am√©liorer la gestion du fonds de roulement. Actions : 1) Optimisation des stocks, 2) R√©vision des conditions de cr√©dit, 3) Options de financement court terme.',
                        'impact': '√âlev√©',
                        'timeframe': '1-3 mois',
                        'estimated_benefit': float(financial_data.get('current_assets', 10000)) * 0.1
                    })
            
            # Recommandations rentabilit√© avec contexte industrie
            net_margin = ratios.get('net_margin', 0)
            if isinstance(net_margin, (int, float)):
                if net_margin < 0:
                    high_priority.append({
                        'category': 'Rentabilit√© critique',
                        'priority': 'Critique',
                        'recommendation': 'Entreprise en perte. Plan de redressement urgent : 1) Analyse d√©taill√©e des co√ªts, 2) R√©vision de la strat√©gie tarifaire, 3) Restructuration op√©rationnelle, 4) Recherche de financements.',
                        'impact': 'Tr√®s √âlev√©',
                        'timeframe': 'Imm√©diat',
                        'estimated_benefit': float(financial_data.get('revenue', 100000)) * 0.1
                    })
                elif net_margin < 0.05:
                    medium_priority.append({
                        'category': 'Am√©lioration de la rentabilit√©',
                        'priority': '√âlev√©e',
                        'recommendation': 'Marges faibles n√©cessitant am√©lioration. Actions : 1) Optimisation de la structure de co√ªts, 2) R√©vision de la strat√©gie tarifaire, 3) Am√©lioration de l\'efficacit√© op√©rationnelle, 4) Optimisation du mix produits.',
                        'impact': '√âlev√©',
                        'timeframe': '3-6 mois',
                        'estimated_benefit': float(financial_data.get('revenue', 100000)) * 0.05
                    })
            
            # Recommandations levier
            debt_to_equity = ratios.get('debt_to_equity', 0)
            if isinstance(debt_to_equity, (int, float)) and debt_to_equity > 2.0:
                medium_priority.append({
                    'category': 'Gestion de l\'endettement',
                    'priority': 'Moyenne',
                    'recommendation': 'Niveau d\'endettement √©lev√©. Actions : 1) Plan de d√©sendettement, 2) Am√©lioration de la couverture du service de la dette, 3) Consid√©rer un financement par capitaux propres.',
                    'impact': 'Moyen',
                    'timeframe': '6-12 mois',
                    'estimated_benefit': float(financial_data.get('total_debt', 10000)) * 0.1
                })
            
            # Recommandations croissance et efficacit√©
            revenue_growth = financial_data.get('revenue_growth', 0)
            if isinstance(revenue_growth, (int, float)) and revenue_growth < 0:
                high_priority.append({
                    'category': 'Croissance du chiffre d\'affaires',
                    'priority': '√âlev√©e',
                    'recommendation': 'D√©clin du CA d√©tect√©. Actions : 1) Analyse march√© et concurrence, 2) Programmes de fid√©lisation clients, 3) Innovation produits/services, 4) R√©vision strat√©gie marketing.',
                    'impact': '√âlev√©',
                    'timeframe': '3-6 mois',
                    'estimated_benefit': float(financial_data.get('revenue', 100000)) * 0.1
                })
            elif isinstance(revenue_growth, (int, float)) and revenue_growth < 5:
                low_priority.append({
                    'category': 'Acc√©l√©ration de la croissance',
                    'priority': 'Faible',
                    'recommendation': 'Croissance lente. Consid√©rer : 1) Expansion g√©ographique, 2) D√©veloppement nouveaux segments, 3) Partenariats strat√©giques.',
                    'impact': 'Moyen',
                    'timeframe': '6-12 mois',
                    'estimated_benefit': float(financial_data.get('revenue', 100000)) * 0.05
                })
            
            # Combiner toutes les recommandations
            all_recommendations = high_priority + medium_priority + low_priority
            
            # FIX: S'assurer que toutes les valeurs estimated_benefit sont num√©riques
            for rec in all_recommendations:
                if not isinstance(rec.get('estimated_benefit'), (int, float)):
                    rec['estimated_benefit'] = 5000  # Valeur par d√©faut
                else:
                    rec['estimated_benefit'] = float(rec['estimated_benefit'])
            
            # Limiter aux 5 recommandations les plus impactantes
            sorted_recommendations = sorted(all_recommendations, 
                                          key=lambda x: float(x.get('estimated_benefit', 0)), 
                                          reverse=True)
            
            return sorted_recommendations[:5]
            
        except Exception as e:
            # Retourner une recommandation de secours en cas d'erreur
            return [{
                'category': 'Erreur syst√®me',
                'priority': 'Moyenne',
                'recommendation': f'Erreur dans la g√©n√©ration des recommandations: {str(e)}',
                'impact': 'Moyen',
                'timeframe': '√Ä d√©terminer',
                'estimated_benefit': 1000
            }]

# ========== INDUSTRY TEMPLATES MANAGER (Enhanced) ==========
class IndustryTemplateManager:
    """Gestionnaire de templates sectoriels avanc√© avec benchmarking complet"""
    
    def __init__(self):
        self.templates = {
            'retail': {
                'name': 'Retail & E-commerce',
                'icon': 'üõçÔ∏è',
                'revenue_model': 'Units Sold √ó Average Selling Price √ó Store Count',
                'key_metrics': [
                    'Same-Store Sales Growth', 'Inventory Turnover', 'Gross Margin',
                    'Sales per Square Foot', 'Customer Traffic', 'Average Transaction Value'
                ],
                'typical_ratios': {
                    'gross_margin': 0.35, 'net_margin': 0.04, 'current_ratio': 1.2,
                    'inventory_turnover': 6, 'asset_turnover': 2.5, 'debt_to_equity': 0.6
                },
                'seasonal_factors': [0.85, 0.9, 1.0, 1.05, 1.0, 0.95, 0.9, 0.95, 1.0, 1.1, 1.25, 1.4],
                'cost_structure': {
                    'cost_of_goods_sold': 0.65, 'labor': 0.15, 'rent': 0.08,
                    'marketing': 0.03, 'other_operating': 0.05
                },
                'working_capital': {
                    'days_sales_outstanding': 5, 'days_inventory_outstanding': 60,
                    'days_payable_outstanding': 30
                },
                'benchmarks': {
                    'revenue_growth': 0.05, 'profit_margin': 0.04, 'inventory_turns': 6,
                    'customer_retention': 0.75, 'market_share': 0.10
                },
                'validation_rules': {
                    'max_inventory_ratio': 0.4,
                    'min_inventory_turnover': 2,
                    'max_seasonal_variation': 0.5
                }
            },
            'saas': {
                'name': 'Software as a Service',
                'icon': '‚òÅÔ∏è',
                'revenue_model': 'Monthly Recurring Revenue √ó 12 + One-time Setup Fees',
                'key_metrics': [
                    'Monthly Recurring Revenue (MRR)', 'Annual Recurring Revenue (ARR)',
                    'Customer Lifetime Value (LTV)', 'Customer Acquisition Cost (CAC)',
                    'Churn Rate', 'Net Revenue Retention'
                ],
                'typical_ratios': {
                    'gross_margin': 0.8, 'net_margin': 0.15, 'current_ratio': 2.0,
                    'ltv_cac_ratio': 3.0, 'asset_turnover': 0.6, 'debt_to_equity': 0.2
                },
                'seasonal_factors': [1.0] * 12,  # Faible saisonnalit√©
                'cost_structure': {
                    'hosting_infrastructure': 0.1, 'customer_support': 0.08, 'sales_marketing': 0.4,
                    'research_development': 0.25, 'general_administrative': 0.12
                },
                'working_capital': {
                    'days_sales_outstanding': 30, 'days_inventory_outstanding': 0,
                    'days_payable_outstanding': 45
                },
                'benchmarks': {
                    'revenue_growth': 0.30, 'profit_margin': 0.15, 'churn_rate': 0.05,
                    'ltv_cac_ratio': 3.0, 'gross_margin': 0.80
                },
                'validation_rules': {
                    'max_churn_rate': 0.15,
                    'min_ltv_cac': 1.5,
                    'min_gross_margin': 0.6
                }
            },
            'technology': {
                'name': 'Technology Services',
                'icon': 'üíª',
                'revenue_model': 'Product Sales + Service Revenue + Licensing',
                'key_metrics': [
                    'Research & Development Ratio', 'Time to Market', 'Product Margins',
                    'Customer Acquisition Cost', 'Revenue per Employee'
                ],
                'typical_ratios': {
                    'gross_margin': 0.6, 'net_margin': 0.12, 'current_ratio': 2.0,
                    'asset_turnover': 0.8, 'debt_to_equity': 0.3
                },
                'seasonal_factors': [0.95, 0.9, 1.0, 1.05, 1.0, 0.95, 0.85, 0.9, 1.05, 1.1, 1.15, 1.2],
                'cost_structure': {
                    'research_development': 0.25, 'sales_marketing': 0.2, 'cost_of_sales': 0.4,
                    'general_administrative': 0.15
                },
                'working_capital': {
                    'days_sales_outstanding': 45, 'days_inventory_outstanding': 30,
                    'days_payable_outstanding': 35
                },
                'benchmarks': {
                    'revenue_growth': 0.15, 'profit_margin': 0.12, 'rd_ratio': 0.25,
                    'customer_satisfaction': 0.85, 'employee_productivity': 150000
                },
                'validation_rules': {
                    'min_rd_ratio': 0.05,
                    'max_rd_ratio': 0.40,
                    'min_gross_margin': 0.3
                }
            },
            'manufacturing': {
                'name': 'Manufacturing',
                'icon': 'üè≠',
                'revenue_model': 'Units Produced √ó Selling Price - Production Costs',
                'key_metrics': [
                    'Capacity Utilization', 'Overall Equipment Effectiveness (OEE)',
                    'Inventory Turnover', 'Quality Defect Rate', 'Labor Productivity'
                ],
                'typical_ratios': {
                    'gross_margin': 0.25, 'net_margin': 0.08, 'current_ratio': 1.5,
                    'inventory_turnover': 8, 'asset_turnover': 1.2, 'debt_to_equity': 0.8
                },
                'seasonal_factors': [0.9, 0.95, 1.1, 1.05, 1.0, 0.95, 0.85, 0.9, 1.05, 1.1, 1.0, 0.95],
                'cost_structure': {
                    'raw_materials': 0.45, 'direct_labor': 0.20, 'manufacturing_overhead': 0.15,
                    'general_administrative': 0.12, 'sales_marketing': 0.08
                },
                'working_capital': {
                    'days_sales_outstanding': 45, 'days_inventory_outstanding': 90,
                    'days_payable_outstanding': 30
                },
                'benchmarks': {
                    'revenue_growth': 0.08, 'profit_margin': 0.08, 'capacity_utilization': 0.85,
                    'oee': 0.75, 'defect_rate': 0.02
                },
                'validation_rules': {
                    'max_inventory_days': 120,
                    'min_capacity_utilization': 0.5,
                    'max_defect_rate': 0.05
                }
            }
        }
    
    def get_template(self, industry):
        """Obtenir template complet industrie avec r√®gles validation"""
        return self.templates.get(industry, self.templates['technology'])
    
    def validate_industry_data(self, csv_data, industry):
        """Valider donn√©es contre r√®gles sp√©cifiques industrie"""
        template = self.get_template(industry)
        validation_rules = template.get('validation_rules', {})
        issues = []
        
        # Validations sp√©cifiques par industrie
        if industry == 'saas':
            # V√©rifier taux de churn si disponible
            churn_rate = csv_data.get('churn_rate', 0)
            if churn_rate > validation_rules.get('max_churn_rate', 0.15):
                issues.append(f"Taux de churn √©lev√© ({churn_rate:.1%}) pour une entreprise SaaS")
            
            # V√©rifier marge brute
            gross_margin = csv_data.get('gross_margin', 0)
            if gross_margin < validation_rules.get('min_gross_margin', 0.6):
                issues.append(f"Marge brute faible ({gross_margin:.1%}) pour le secteur SaaS")
        
        elif industry == 'retail':
            # V√©rifier niveaux de stock
            inventory_ratio = csv_data.get('inventory_ratio', 0)
            if inventory_ratio > validation_rules.get('max_inventory_ratio', 0.4):
                issues.append(f"Niveau de stock √©lev√© ({inventory_ratio:.1%}) pour le retail")
            
            # V√©rifier patterns saisonniers
            revenue_volatility = csv_data.get('revenue_volatility', 0)
            if revenue_volatility > validation_rules.get('max_seasonal_variation', 0.5):
                issues.append(f"Forte variabilit√© saisonni√®re d√©tect√©e ({revenue_volatility:.1%})")
        
        elif industry == 'technology':
            # V√©rifier investissement R&D
            rd_ratio = csv_data.get('rd_ratio', 0)
            min_rd = validation_rules.get('min_rd_ratio', 0.05)
            max_rd = validation_rules.get('max_rd_ratio', 0.40)
            
            if rd_ratio < min_rd:
                issues.append(f"Investissement R&D faible ({rd_ratio:.1%}) pour le secteur tech")
            elif rd_ratio > max_rd:
                issues.append(f"Investissement R&D tr√®s √©lev√© ({rd_ratio:.1%}) - v√©rifier la viabilit√©")
        
        elif industry == 'manufacturing':
            # V√©rifier dur√©e de stock
            inventory_days = csv_data.get('inventory_days', 0)
            if inventory_days > validation_rules.get('max_inventory_days', 120):
                issues.append(f"Dur√©e de stock excessive ({inventory_days:.0f} jours) pour le manufacturing")
        
        return issues
    
    def detect_industry_from_csv(self, csv_data):
        """D√©tecter industrie probable bas√©e sur patterns donn√©es CSV avec logique avanc√©e"""
        if not csv_data:
            return 'technology'
        
        scores = {}
        
        # Initialiser scores
        for industry in self.templates.keys():
            scores[industry] = 0
        
        # Analyser patterns revenus
        revenue_data = csv_data.get('revenue_data', [])
        if len(revenue_data) >= 12:
            # Calculer saisonnalit√©
            monthly_avg = []
            for month in range(12):
                month_values = [revenue_data[i] for i in range(month, len(revenue_data), 12)]
                if month_values:
                    monthly_avg.append(np.mean(month_values))
            
            if len(monthly_avg) == 12:
                seasonality_score = np.std(monthly_avg) / np.mean(monthly_avg) if np.mean(monthly_avg) > 0 else 0
                
                # Forte saisonnalit√© sugg√®re retail
                if seasonality_score > 0.2:
                    scores['retail'] += 30
                # Faible saisonnalit√© sugg√®re SaaS
                elif seasonality_score < 0.05:
                    scores['saas'] += 20
        
        # Analyser marges profit
        profit_margin = csv_data.get('profit_margin', 0)
        
        # Marges √©lev√©es sugg√®rent SaaS ou technology
        if profit_margin > 20:
            scores['saas'] += 25
            scores['technology'] += 15
        # Marges faibles sugg√®rent manufacturing ou retail
        elif profit_margin < 10:
            scores['manufacturing'] += 20
            scores['retail'] += 15
        
        # Analyser volatilit√© revenus
        revenue_volatility = csv_data.get('revenue_volatility', 0)
        
        # Forte volatilit√© sugg√®re retail ou manufacturing
        if revenue_volatility > 0.3:
            scores['retail'] += 15
            scores['manufacturing'] += 10
        # Faible volatilit√© sugg√®re SaaS
        elif revenue_volatility < 0.1:
            scores['saas'] += 15
        
        # Analyser taux de croissance
        revenue_growth = csv_data.get('revenue_growth', 0)
        
        # Forte croissance sugg√®re SaaS ou technology
        if revenue_growth > 20:
            scores['saas'] += 20
            scores['technology'] += 15
        # Croissance mod√©r√©e sugg√®re technology
        elif revenue_growth > 10:
            scores['technology'] += 10
        
        # Retourner industrie avec score le plus √©lev√©
        best_industry = max(scores, key=scores.get)
        
        # Fallback vers technology si pas de gagnant clair
        if scores[best_industry] < 10:
            return 'technology'
        
        return best_industry
    
    def benchmark_against_industry(self, csv_data, industry):
        """Comparaison benchmark avanc√©e avec validation industrie"""
        template = self.get_template(industry)
        benchmarks = template['benchmarks']
        
        comparison = {}
        
        # Comparaison croissance revenus avec validation
        company_growth = csv_data.get('revenue_growth', 0) / 100
        industry_growth = benchmarks.get('revenue_growth', 0.1)
        
        comparison['revenue_growth'] = {
            'company_value': company_growth,
            'industry_benchmark': industry_growth,
            'difference': company_growth - industry_growth,
            'percentage_difference': ((company_growth - industry_growth) / industry_growth * 100) if industry_growth != 0 else 0,
            'performance': self.categorize_performance(company_growth, industry_growth),
            'validation_status': self.validate_metric_range('revenue_growth', company_growth, industry)
        }
        
        # Comparaison marge profit avec validation
        company_margin = csv_data.get('profit_margin', 0) / 100
        industry_margin = benchmarks.get('profit_margin', 0.1)
        
        comparison['profit_margin'] = {
            'company_value': company_margin,
            'industry_benchmark': industry_margin,
            'difference': company_margin - industry_margin,
            'percentage_difference': ((company_margin - industry_margin) / industry_margin * 100) if industry_margin != 0 else 0,
            'performance': self.categorize_performance(company_margin, industry_margin),
            'validation_status': self.validate_metric_range('profit_margin', company_margin, industry)
        }
        
        # M√©triques sp√©cifiques par industrie
        if industry == 'saas':
            churn_rate = csv_data.get('estimated_churn', 0.05)
            industry_churn = benchmarks.get('churn_rate', 0.05)
            
            comparison['churn_rate'] = {
                'company_value': churn_rate,
                'industry_benchmark': industry_churn,
                'difference': churn_rate - industry_churn,
                'performance': self.categorize_performance(industry_churn, churn_rate),  # Plus bas est meilleur pour churn
                'validation_status': 'Normal' if churn_rate <= 0.15 else 'Attention Required'
            }
        
        elif industry == 'retail':
            inventory_turns = csv_data.get('estimated_inventory_turns', 6)
            industry_turns = benchmarks.get('inventory_turns', 6)
            
            comparison['inventory_turnover'] = {
                'company_value': inventory_turns,
                'industry_benchmark': industry_turns,
                'difference': inventory_turns - industry_turns,
                'performance': self.categorize_performance(inventory_turns, industry_turns),
                'validation_status': 'Normal' if inventory_turns >= 2 else 'Low Efficiency'
            }
        
        return comparison
    
    def categorize_performance(self, company_value, benchmark_value):
        """Cat√©goriser performance relative au benchmark"""
        if benchmark_value == 0:
            return 'Cannot Compare'
        
        ratio = company_value / benchmark_value
        
        if ratio >= 1.2:
            return 'Excellent'
        elif ratio >= 1.1:
            return 'Above Average'
        elif ratio >= 0.9:
            return 'Average'
        elif ratio >= 0.8:
            return 'Below Average'
        else:
            return 'Poor'
    
    def validate_metric_range(self, metric, value, industry):
        """Valider si m√©trique est dans fourchette raisonnable pour industrie"""
        validation_ranges = {
            'saas': {
                'revenue_growth': (-0.3, 3.0),  # -30% √† 300%
                'profit_margin': (-0.5, 0.8),  # -50% √† 80%
                'churn_rate': (0, 0.3)          # 0% √† 30%
            },
            'retail': {
                'revenue_growth': (-0.5, 1.0),  # -50% √† 100%
                'profit_margin': (-0.2, 0.3),  # -20% √† 30%
                'inventory_turnover': (1, 20)   # 1 √† 20 rotations
            },
            'technology': {
                'revenue_growth': (-0.4, 2.0),  # -40% √† 200%
                'profit_margin': (-0.3, 0.6),  # -30% √† 60%
            },
            'manufacturing': {
                'revenue_growth': (-0.3, 0.8),  # -30% √† 80%
                'profit_margin': (-0.2, 0.4),  # -20% √† 40%
            }
        }
        
        ranges = validation_ranges.get(industry, validation_ranges['technology'])
        metric_range = ranges.get(metric, (-1, 10))  # Fourchette large par d√©faut
        
        if metric_range[0] <= value <= metric_range[1]:
            return 'Normal'
        elif value < metric_range[0]:
            return 'Below Normal Range'
        else:
            return 'Above Normal Range'
    
    def generate_industry_insights(self, csv_data, industry):
        """G√©n√©rer insights sp√©cifiques industrie avanc√©s avec validation"""
        template = self.get_template(industry)
        insights = []
        recommendations = []
        
        # Valider donn√©es contre r√®gles industrie
        validation_issues = self.validate_industry_data(csv_data, industry)
        
        profit_margin = csv_data.get('profit_margin', 0)
        revenue_growth = csv_data.get('revenue_growth', 0)
        revenue_volatility = csv_data.get('revenue_volatility', 0)
        
        # Ajouter insights validation
        for issue in validation_issues:
            recommendations.append(f"‚ö†Ô∏è **Validation** : {issue}")
        
        # Analyse sp√©cifique par industrie avec logique avanc√©e
        if industry == 'saas':
            if profit_margin > 15:
                insights.append(f"üí∞ **Marges SaaS solides** : {profit_margin:.1f}% d√©passe les benchmarks SaaS typiques")
            else:
                recommendations.append("üéØ **Optimisation SaaS** : Se concentrer sur les revenus r√©currents et r√©duire les co√ªts d'acquisition client")
            
            if revenue_volatility < 0.1:
                insights.append("üìä **Excellente pr√©dictibilit√© des revenus** : Faible volatilit√© align√©e avec les forces du mod√®le SaaS")
            else:
                recommendations.append("üîÑ **Am√©liorer les revenus r√©currents** : R√©duire le churn et augmenter la valeur vie client")
            
            # Recommandations sp√©cifiques SaaS
            if revenue_growth > 30:
                insights.append("üöÄ **Croissance SaaS exceptionnelle** : Maintenir le momentum avec scaling intelligent")
            elif revenue_growth < 10:
                recommendations.append("üìà **Acc√©l√©ration SaaS** : Focus sur l'expansion des comptes existants et nouveaux segments")
        
        elif industry == 'retail':
            if revenue_volatility > 0.2:
                insights.append("üõçÔ∏è **Mod√®le saisonnier retail** : Forte volatilit√© typique des op√©rations retail")
                recommendations.append("üìà **Planification saisonni√®re** : Optimiser stocks et personnel pour les pics d'activit√©")
            
            if profit_margin < 5:
                recommendations.append("üí° **Efficacit√© retail** : Focus sur la rotation des stocks et l'optimisation supply chain")
            
            # Insights sp√©cifiques retail
            inventory_efficiency = csv_data.get('estimated_inventory_turns', 6)
            if inventory_efficiency > 8:
                insights.append("‚ö° **Gestion de stock efficace** : Rotation rapide des stocks optimise la rentabilit√©")
            elif inventory_efficiency < 4:
                recommendations.append("üì¶ **Optimisation stocks** : Am√©liorer la rotation pour lib√©rer du cash-flow")
        
        elif industry == 'technology':
            if revenue_growth > 15:
                insights.append(f"üöÄ **Forte croissance tech** : {revenue_growth:.1f}% de croissance excellente pour le secteur technologique")
            
            if profit_margin > 12:
                insights.append("üíé **Prime innovation tech** : Marges √©lev√©es indiquent une forte position march√©")
            else:
                recommendations.append("üî¨ **Investissement R&D** : Augmenter les d√©penses d'innovation pour am√©liorer la position concurrentielle")
            
            # Recommandations sp√©cifiques technology
            if revenue_volatility > 0.25:
                recommendations.append("üéØ **Stabilisation tech** : Diversifier le portefeuille produits pour r√©duire la volatilit√©")
        
        elif industry == 'manufacturing':
            if profit_margin > 8:
                insights.append("üè≠ **Manufacturing efficace** : Marges sup√©rieures √† la moyenne du secteur manufacturier")
            
            if revenue_volatility < 0.15:
                insights.append("‚öôÔ∏è **Op√©rations manufacturing stables** : Patterns coh√©rents de production et demande")
            else:
                recommendations.append("üìä **Planification demande** : Impl√©menter de meilleures pr√©visions pour r√©duire la volatilit√©")
            
            # Insights sp√©cifiques manufacturing
            if revenue_growth > 10:
                insights.append("üìà **Expansion manufacturing** : Croissance solide sugg√®re une demande soutenue")
                recommendations.append("üèóÔ∏è **Scalabilit√©** : √âvaluer la capacit√© de production pour soutenir la croissance")
        
        return insights, recommendations

# ========== CSV DATA MANAGER ==========
class CSVDataManager:
    """Gestionnaire de donn√©es CSV am√©lior√© avec validation"""
    
    @staticmethod
    def get_csv_financial_data():
        """Obtenir les donn√©es financi√®res du CSV avec validation"""
        if not st.session_state.imported_metrics:
            return None
        
        metrics = st.session_state.imported_metrics
        
        # Extraire les m√©triques financi√®res cl√©s
        financial_data = {}
        
        if 'revenue' in metrics:
            financial_data['revenue'] = metrics['revenue']['average'] * 12
            financial_data['monthly_revenue'] = metrics['revenue']['average']
            financial_data['revenue_data'] = metrics['revenue']['data']
            financial_data['revenue_growth'] = metrics['revenue'].get('growth_rate', 0)
            financial_data['revenue_volatility'] = metrics['revenue'].get('volatility', 0)
        
        if 'costs' in metrics:
            financial_data['total_costs'] = metrics['costs']['average'] * 12
            financial_data['monthly_costs'] = metrics['costs']['average']
            financial_data['costs_data'] = metrics['costs']['data']
            financial_data['costs_growth'] = metrics['costs'].get('growth_rate', 0)
        
        if 'profit' in metrics:
            financial_data['net_profit'] = metrics['profit']['average'] * 12
            financial_data['monthly_profit'] = metrics['profit']['average']
            financial_data['profit_data'] = metrics['profit']['data']
            financial_data['profit_margin'] = metrics['profit'].get('margin_average', 0)
        
        # Calculer les m√©triques d√©riv√©es avec validation
        if 'revenue' in financial_data and 'total_costs' in financial_data:
            financial_data['gross_profit'] = financial_data['revenue'] - financial_data['total_costs']
            financial_data['operating_profit'] = financial_data['gross_profit'] * 0.8
            financial_data['net_margin'] = financial_data['net_profit'] / financial_data['revenue'] if financial_data['revenue'] > 0 else 0
        
        # Ajouter des estimations de bilan valid√©es
        if 'revenue' in financial_data:
            revenue = financial_data['revenue']
            financial_data['current_assets'] = revenue * 0.3
            financial_data['current_liabilities'] = revenue * 0.15
            financial_data['total_assets'] = revenue * 0.8
            financial_data['total_debt'] = revenue * 0.2
            financial_data['equity'] = revenue * 0.4
            financial_data['cash'] = revenue * 0.1
            financial_data['inventory'] = revenue * 0.08
            financial_data['interest_expense'] = revenue * 0.02
            financial_data['cash_flow'] = financial_data.get('monthly_profit', revenue * 0.02)
            
            # Ratios financiers
            financial_data['current_ratio'] = financial_data['current_assets'] / financial_data['current_liabilities']
            financial_data['debt_to_equity'] = financial_data['total_debt'] / financial_data['equity']
            financial_data['interest_coverage'] = financial_data['operating_profit'] / financial_data['interest_expense']
        
        return financial_data
    
    @staticmethod
    def has_csv_data():
        """V√©rifier si les donn√©es CSV sont disponibles"""
        return bool(st.session_state.imported_metrics)
    
    @staticmethod
    def get_csv_insights():
        """Obtenir les insights IA des donn√©es CSV"""
        if 'csv_data' in st.session_state and 'insights' in st.session_state.csv_data:
            return st.session_state.csv_data['insights']
        return None
    
    @staticmethod
    def get_csv_visualizations():
        """Obtenir les visualisations des donn√©es CSV"""
        if 'csv_data' in st.session_state and 'figures' in st.session_state.csv_data:
            return st.session_state.csv_data['figures']
        return None

# ========== SESSION STATE INITIALIZATION ==========
def init_session_state():
    """Initialiser toutes les variables d'√©tat de session y compris nouveaux composants validation"""
    
    # Donn√©es sp√©cifiques import CSV
    if 'csv_data' not in st.session_state:
        st.session_state.csv_data = {}
    
    if 'csv_processor' not in st.session_state:
        st.session_state.csv_processor = AdvancedCSVProcessor()
    
    if 'imported_metrics' not in st.session_state:
        st.session_state.imported_metrics = {}
    
    # R√©sultats validation avanc√©s
    if 'validation_results' not in st.session_state:
        st.session_state.validation_results = {}
    
    if 'correction_log' not in st.session_state:
        st.session_state.correction_log = []
    
    # G√©n√©rateur de templates
    if 'template_generator' not in st.session_state:
        st.session_state.template_generator = CSVTemplateGenerator()
    
    # Composants analytics avanc√©s
    if 'scenario_results' not in st.session_state:
        st.session_state.scenario_results = {}
    
    if 'ml_forecasts' not in st.session_state:
        st.session_state.ml_forecasts = {}
    
    if 'enhanced_ml_results' not in st.session_state:
        st.session_state.enhanced_ml_results = {}
    
    # Analytics avanc√©s et risk management
    if 'risk_analysis' not in st.session_state:
        st.session_state.risk_analysis = {}
    
    if 'industry_analysis' not in st.session_state:
        st.session_state.industry_analysis = {}
    
    # Historique des analyses
    if 'analysis_history' not in st.session_state:
        st.session_state.analysis_history = []
    
    # Param√®tres utilisateur
    if 'user_preferences' not in st.session_state:
        st.session_state.user_preferences = {
            'currency': 'DHS',
            'date_format': 'YYYY-MM-DD',
            'decimal_places': 2,
            'theme': 'light'
        }
    
    # Cache des calculs avanc√©s
    if 'cached_calculations' not in st.session_state:
        st.session_state.cached_calculations = {}

# ========== ENHANCED CSV IMPORT INTERFACE ==========
def show_enhanced_csv_import():
    """Interface d'import CSV am√©lior√©e avec validation et correction automatiques"""
    st.header("üì§ Import CSV Intelligent avec Validation Avanc√©e")
    
    # Introduction avec nouvelles capacit√©s
    st.markdown("""
    üöÄ **Nouveau Syst√®me de Validation & Correction Automatique** 
    - ‚úÖ **Diagnostic d'incoh√©rences** : D√©tection automatique des probl√®mes comptables
    - üîß **Corrections automatiques** : IA corrige les valeurs aberrantes et incoh√©rences
    - üìä **Score qualit√©** : √âvaluation en temps r√©el de la fiabilit√© de vos donn√©es
    - ‚ö†Ô∏è **Alertes intelligentes** : Identification des risques et probl√®mes potentiels
    """)
    
    # Section de t√©l√©chargement des templates am√©lior√©e
    st.subheader("üì• Templates CSV Avanc√©s")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üìä Template Complet")
        st.write("Toutes m√©triques financi√®res pour analyse maximale")
        
        if st.button("üì• T√©l√©charger Template Complet", type="primary", use_container_width=True):
            template_gen = st.session_state.template_generator
            csv_data = template_gen.generate_template_csv('complete_financial')
            
            if csv_data:
                st.download_button(
                    label="üíæ T√©l√©charger complete_financial_template.csv",
                    data=csv_data,
                    file_name="complete_financial_template.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                st.success("‚úÖ Template pr√™t au t√©l√©chargement !")
    
    with col2:
        st.markdown("#### ‚òÅÔ∏è Template SaaS")
        st.write("Sp√©cialis√© entreprises Software as a Service")
        
        if st.button("‚òÅÔ∏è T√©l√©charger Template SaaS", use_container_width=True):
            template_gen = st.session_state.template_generator
            csv_data = template_gen.generate_template_csv('saas_template')
            
            if csv_data:
                st.download_button(
                    label="üíæ T√©l√©charger saas_template.csv",
                    data=csv_data,
                    file_name="saas_template.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                st.success("‚úÖ Template SaaS pr√™t !")
    
    with col3:
        st.markdown("#### üéØ Templates Futurs")
        st.write("Templates sectoriels additionnels")
        st.info("üîú Retail, Manufacturing, Consulting...")
        st.caption("Prochaines versions")
    
    # Zone d'upload avec instructions am√©lior√©es
    st.subheader("üìÅ Upload & Analyse de Vos Donn√©es")
    
    uploaded_file = st.file_uploader(
        "üìÇ S√©lectionnez votre fichier CSV financier",
        type=['csv'],
        help="Formats support√©s: CSV avec s√©parateur virgule. Encodage: UTF-8 recommand√©."
    )
    
    if uploaded_file is not None:
        try:
            # Lecture et analyse du fichier
            df = pd.read_csv(uploaded_file)
            st.success(f"‚úÖ **Fichier lu avec succ√®s** : {len(df)} lignes, {len(df.columns)} colonnes")
            
            # Affichage aper√ßu des donn√©es
            with st.expander("üëÄ Aper√ßu des Donn√©es Brutes", expanded=False):
                st.dataframe(df.head(10), use_container_width=True)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Lignes", len(df))
                with col2:
                    st.metric("Colonnes", len(df.columns))
                with col3:
                    missing_data = df.isnull().sum().sum()
                    st.metric("Donn√©es Manquantes", missing_data)
            
            # Traitement avec le processeur CSV avanc√©
            with st.spinner("üîç Analyse et validation des donn√©es en cours..."):
                processor = st.session_state.csv_processor
                results = processor.process_csv(df)
                
                # Sauvegarder les r√©sultats dans l'√©tat de session
                st.session_state.csv_data = results
                st.session_state.imported_metrics = results['metrics']
                st.session_state.validation_results = results['validation_results']
                st.session_state.correction_log = results['correction_log']
            
            # ========== R√âSULTATS DE L'ANALYSE ==========
            st.subheader("üìä R√©sultats de l'Analyse Avanc√©e")
            
            # Score de qualit√© global avec nouvelle logique
            validation_results = results['validation_results']
            quality_score = validation_results.get('quality_score', 100)
            total_issues = validation_results.get('total_issues', 0)
            critical_issues = validation_results.get('critical_issues', 0)
            corrections_applied = results.get('corrections_applied', False)
            
            # Affichage du score de qualit√© avec contexte
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Score Qualit√© Global", f"{quality_score:.0f}/100")
                if quality_score >= 90:
                    st.success("üü¢ Excellente qualit√©")
                elif quality_score >= 70:
                    st.info("üîµ Qualit√© correcte")
                elif quality_score >= 50:
                    st.warning("üü° Qualit√© mod√©r√©e")
                else:
                    st.error("üî¥ Qualit√© faible")
            
            with col2:
                st.metric("Anomalies D√©tect√©es", total_issues)
                if total_issues == 0:
                    st.success("‚úÖ Aucune anomalie")
                elif total_issues <= 3:
                    st.info("üîµ Mineures")
                else:
                    st.warning("üü° Attention requise")
            
            with col3:
                st.metric("Probl√®mes Critiques", critical_issues)
                if critical_issues == 0:
                    st.success("‚úÖ Aucun")
                else:
                    st.error(f"üî¥ {critical_issues} critique(s)")
            
            with col4:
                corrections_count = len(results.get('correction_log', []))
                st.metric("Corrections Appliqu√©es", corrections_count)
                if corrections_count == 0:
                    st.success("‚úÖ Aucune correction n√©cessaire")
                else:
                    st.info(f"üîß {corrections_count} correction(s) auto")
            
            # D√©tails des colonnes d√©tect√©es avec mapping avanc√©
            mappings = results['mappings']
            if mappings:
                st.markdown("#### üéØ Mapping des Colonnes D√©tect√©es")
                
                # Organiser par cat√©gories
                categories = {
                    'üí∞ Revenus & Profits': ['revenue', 'sales', 'profit'],
                    'üí∏ Co√ªts & Charges': ['costs', 'variable_costs', 'fixed_costs'],
                    'üè¶ Bilan': ['assets', 'liabilities', 'equity', 'current_assets', 'current_liabilities'],
                    'üì¶ Op√©rations': ['inventory', 'accounts_receivable', 'accounts_payable', 'cash_flow'],
                    'üìÖ Temporel': ['date'],
                    'üë• Business': ['customer_metrics', 'unit_metrics', 'pricing_metrics']
                }
                
                cols_per_row = 2
                for i in range(0, len(categories), cols_per_row):
                    cols = st.columns(cols_per_row)
                    
                    for j, (category, fields) in enumerate(list(categories.items())[i:i+cols_per_row]):
                        with cols[j]:
                            st.markdown(f"**{category}**")
                            detected_in_category = False
                            
                            for field in fields:
                                if field in mappings:
                                    st.write(f"‚úÖ `{field}` ‚Üê `{mappings[field]}`")
                                    detected_in_category = True
                            
                            if not detected_in_category:
                                st.caption("üîç Aucune colonne d√©tect√©e")
            
            # Insights de validation avanc√©s
            if validation_results.get('issues'):
                st.markdown("#### ‚ö†Ô∏è D√©tails des Validations")
                
                issues = validation_results['issues']
                
                # Grouper par s√©v√©rit√©
                critical_group = [i for i in issues if i.get('severity') == '√âlev√©e']
                medium_group = [i for i in issues if i.get('severity') == 'Moyenne']
                ok_group = [i for i in issues if i.get('severity') == 'OK']
                
                # Afficher issues critiques
                if critical_group:
                    st.error("üö® **Probl√®mes Critiques D√©tect√©s**")
                    for issue in critical_group:
                        st.error(f"‚Ä¢ **{issue.get('type', 'Probl√®me')}** : {issue.get('message', 'D√©tails non disponibles')}")
                
                # Afficher issues moyennes
                if medium_group:
                    st.warning("‚ö†Ô∏è **Probl√®mes Mod√©r√©s**")
                    for issue in medium_group:
                        st.warning(f"‚Ä¢ **{issue.get('type', 'Probl√®me')}** : {issue.get('message', 'D√©tails non disponibles')}")
                
                # Afficher validations OK
                if ok_group:
                    with st.expander("‚úÖ Validations R√©ussies", expanded=False):
                        for issue in ok_group:
                            st.success(f"‚Ä¢ **{issue.get('type', 'Validation')}** : {issue.get('message', 'Validation pass√©e')}")
            
            # Log des corrections automatiques
            if corrections_applied and results.get('correction_log'):
                st.markdown("#### üîß Journal des Corrections Automatiques")
                
                correction_log = results['correction_log']
                
                with st.expander(f"üìã D√©tails des {len(correction_log)} Correction(s)", expanded=False):
                    for i, correction in enumerate(correction_log):
                        st.info(f"**Correction {i+1}** : {correction.get('method', 'M√©thode inconnue')}")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if 'outliers_found' in correction:
                                st.write(f"‚Ä¢ Outliers d√©tect√©s : {correction['outliers_found']}")
                            if 'missing_values_filled' in correction:
                                st.write(f"‚Ä¢ Valeurs manquantes combl√©es : {correction['missing_values_filled']}")
                            if 'extreme_variations_smoothed' in correction:
                                st.write(f"‚Ä¢ Variations extr√™mes liss√©es : {correction['extreme_variations_smoothed']}")
                        
                        with col2:
                            if 'replacement_value' in correction:
                                st.write(f"‚Ä¢ Valeur de remplacement : {correction['replacement_value']:.2f}")
                            if 'threshold_used' in correction:
                                st.write(f"‚Ä¢ Seuil utilis√© : {correction['threshold_used']:.2f}")
                            if 'basis' in correction:
                                st.write(f"‚Ä¢ Base : {correction['basis']}")
            
            # M√©triques calcul√©es avec validation
            metrics = results['metrics']
            if metrics:
                st.markdown("#### üìà M√©triques Financi√®res Calcul√©es")
                
                tabs = st.tabs(["üí∞ Revenus", "üí∏ Co√ªts", "üìä Rentabilit√©", "üìà Tendances"])
                
                with tabs[0]:
                    if 'revenue' in metrics:
                        rev_metrics = metrics['revenue']
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Total P√©riode", f"{rev_metrics['total']:,.0f} DHS")
                        with col2:
                            st.metric("Moyenne Mensuelle", f"{rev_metrics['average']:,.0f} DHS")
                        with col3:
                            st.metric("Croissance", f"{rev_metrics.get('growth_rate', 0):+.1f}%")
                        with col4:
                            st.metric("Volatilit√©", f"{rev_metrics.get('volatility', 0):.1%}")
                        
                        # Tendance qualitative
                        trend = rev_metrics.get('trend', 'stable')
                        if trend == 'croissance':
                            st.success("üìà Tendance : Croissance")
                        elif trend == 'declin':
                            st.error("üìâ Tendance : D√©clin")
                        else:
                            st.info("üìä Tendance : Stable")
                
                with tabs[1]:
                    if 'costs' in metrics:
                        cost_metrics = metrics['costs']
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Total Co√ªts", f"{cost_metrics['total']:,.0f} DHS")
                        with col2:
                            st.metric("Co√ªts Moyens", f"{cost_metrics['average']:,.0f} DHS")
                        with col3:
                            st.metric("√âvolution", f"{cost_metrics.get('growth_rate', 0):+.1f}%")
                
                with tabs[2]:
                    if 'profit' in metrics:
                        profit_metrics = metrics['profit']
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Profit Total", f"{profit_metrics['total']:,.0f} DHS")
                        with col2:
                            st.metric("Marge Moyenne", f"{profit_metrics.get('margin_average', 0):.1f}%")
                        with col3:
                            profit_growth = profit_metrics.get('growth_rate', 0)
                            st.metric("Croissance Profit", f"{profit_growth:+.1f}%")
                        
                        # Sant√© financi√®re basique
                        margin = profit_metrics.get('margin_average', 0)
                        if margin > 15:
                            st.success("üí∞ Excellente rentabilit√©")
                        elif margin > 5:
                            st.info("üìà Rentabilit√© correcte")
                        elif margin > 0:
                            st.warning("üìä Faible rentabilit√©")
                        else:
                            st.error("üî¥ Entreprise d√©ficitaire")
                
                with tabs[3]:
                    # R√©sum√© des tendances
                    st.markdown("**Analyse des Tendances D√©tect√©es**")
                    
                    if 'revenue' in metrics:
                        rev_growth = metrics['revenue'].get('growth_rate', 0)
                        if rev_growth > 10:
                            st.success(f"üìà **Forte croissance CA** : {rev_growth:.1f}% sur la p√©riode")
                        elif rev_growth > 0:
                            st.info(f"üìä **Croissance mod√©r√©e** : {rev_growth:.1f}%")
                        else:
                            st.error(f"üìâ **D√©clin CA** : {abs(rev_growth):.1f}% de baisse")
                    
                    if 'profit' in metrics:
                        profit_trend = metrics['profit'].get('growth_rate', 0)
                        if profit_trend > rev_growth:
                            st.success("üìà **Am√©lioration de l'efficacit√©** : Profit cro√Æt plus vite que le CA")
                        elif profit_trend < rev_growth - 10:
                            st.warning("‚ö†Ô∏è **D√©t√©rioration marges** : Croissance co√ªts sup√©rieure")
            
            # Visualisations avec contexte de validation
            if 'figures' in results and results['figures']:
                st.markdown("#### üìä Visualisations avec Validation")
                
                figures = results['figures']
                
                for chart_name, fig in figures.items():
                    # Ajouter annotation de qualit√©
                    if quality_score < 80:
                        st.caption(f"‚ö†Ô∏è Graphique bas√© sur donn√©es qualit√© {quality_score:.0f}% - Interpr√©ter avec prudence")
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    if corrections_applied:
                        st.caption("‚ÑπÔ∏è Visualisation inclut les corrections automatiques appliqu√©es")
            
            # Insights IA avec validation
            insights_data = results.get('insights', {})
            if insights_data:
                st.markdown("#### ü§ñ Insights IA avec Validation Avanc√©e")
                
                insight_tabs = st.tabs(["‚úÖ Insights Valid√©s", "üí° Recommandations", "‚ö†Ô∏è Alertes", "üéØ Actions Prioritaires"])
                
                with insight_tabs[0]:
                    if insights_data.get('insights'):
                        for insight in insights_data['insights']:
                            st.success(f"‚úÖ {insight}")
                            
                            # Ajouter niveau de confiance bas√© sur qualit√© donn√©es
                            if quality_score >= 90:
                                st.caption("üîπ Confiance √©lev√©e (donn√©es haute qualit√©)")
                            elif quality_score >= 70:
                                st.caption("üî∏ Confiance mod√©r√©e")
                            else:
                                st.caption("üî∏ Confiance limit√©e - Validation externe recommand√©e")
                    else:
                        st.info("Aucun insight sp√©cifique g√©n√©r√©. Performance dans les normes.")
                
                with insight_tabs[1]:
                    if insights_data.get('recommendations'):
                        for rec in insights_data['recommendations']:
                            st.warning(f"üí° {rec}")
                    else:
                        st.success("‚úÖ Aucune recommandation imm√©diate identifi√©e")
                
                with insight_tabs[2]:
                    if insights_data.get('alerts'):
                        for alert in insights_data['alerts']:
                            st.error(f"‚ö†Ô∏è {alert}")
                    else:
                        st.success("‚úÖ Aucune alerte critique d√©tect√©e !")
                
                with insight_tabs[3]:
                    # G√©n√©rer actions prioritaires bas√©es sur r√©sultats validation
                    priority_actions = []
                    
                    if critical_issues > 0:
                        priority_actions.append("üî¥ **Priorit√© 1** : Corriger les incoh√©rences critiques d√©tect√©es")
                    
                    if quality_score < 70:
                        priority_actions.append("üü° **Priorit√© 2** : Am√©liorer la qualit√© globale des donn√©es")
                    
                    if len(results.get('correction_log', [])) > 3:
                        priority_actions.append("üîµ **Priorit√© 3** : R√©viser les processus de collecte des donn√©es")
                    
                    if not priority_actions:
                        priority_actions.append("‚úÖ **Aucune action prioritaire** : Donn√©es de qualit√© satisfaisante")
                    
                    for action in priority_actions:
                        if "Priorit√© 1" in action:
                            st.error(action)
                        elif "Priorit√© 2" in action:
                            st.warning(action)
                        elif "Priorit√© 3" in action:
                            st.info(action)
                        else:
                            st.success(action)
            
            # Options d'int√©gration am√©lior√©es
            st.subheader("üîÑ Options d'Int√©gration Avanc√©es")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if st.button("üíæ Sauvegarder Analyse", type="primary", use_container_width=True):
                    # Ajouter √† l'historique des analyses
                    analysis_record = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'filename': uploaded_file.name,
                        'quality_score': quality_score,
                        'total_issues': total_issues,
                        'critical_issues': critical_issues,
                        'corrections_applied': corrections_applied
                    }
                    
                    if 'analysis_history' not in st.session_state:
                        st.session_state.analysis_history = []
                    
                    st.session_state.analysis_history.append(analysis_record)
                    
                    st.success("‚úÖ Analyse sauvegard√©e avec succ√®s !")
                    
                    if quality_score >= 80:
                        st.balloons()
                    else:
                        st.info("üí° Am√©liorer la qualit√© des donn√©es pour de meilleurs r√©sultats")
            
            with col2:
                if st.button("üß† Analytics Avanc√©s", use_container_width=True):
                    st.success("üöÄ Naviguez vers Analytics Avanc√©s via la barre lat√©rale...")
                    st.info("üëà Utilisez le menu de navigation √† gauche pour acc√©der aux Analytics Avanc√©s")
            
            with col3:
                if st.button("üéØ Planification Sc√©narios", use_container_width=True):
                    st.success("üöÄ Naviguez vers Planification Sc√©narios via la barre lat√©rale...")
                    st.info("üëà Utilisez le menu de navigation √† gauche pour acc√©der √† la Planification de Sc√©narios")
            
            with col4:
                if st.button("ü§ñ Pr√©visions ML", use_container_width=True):
                    st.success("üöÄ Naviguez vers Pr√©visions ML via la barre lat√©rale...")
                    st.info("üëà Utilisez le menu de navigation √† gauche pour acc√©der aux Pr√©visions ML")
            
            # Historique des analyses si disponible
            if len(st.session_state.get('analysis_history', [])) > 0:
                with st.expander("üìã Historique des Analyses", expanded=False):
                    history_df = pd.DataFrame(st.session_state.analysis_history)
                    st.dataframe(history_df, use_container_width=True)
        
        except Exception as e:
            st.error(f"‚ùå **Erreur lors du traitement du fichier** : {str(e)}")
            st.info("""
            **Suggestions de r√©solution** :
            - V√©rifier que le fichier est au format CSV valide
            - S'assurer de l'encodage UTF-8
            - Contr√¥ler que les donn√©es num√©riques ne contiennent pas de caract√®res sp√©ciaux
            - Essayer de sauvegarder le fichier Excel en CSV depuis votre tableur
            """)

# ========== EXECUTIVE DASHBOARD (Enhanced) ==========
def show_executive_dashboard():
    """Dashboard ex√©cutif am√©lior√© avec insights validation"""
    st.header("üëî Executive Dashboard Avanc√©")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    
    if csv_data:
        # Afficher le statut de qualit√© des donn√©es en premier
        quality_info = ""
        if 'validation_results' in st.session_state:
            quality_score = st.session_state.validation_results.get('quality_score', 100)
            if quality_score >= 80:
                quality_info = f" (Qualit√©: {quality_score:.0f}/100 ‚úÖ)"
            elif quality_score >= 60:
                quality_info = f" (Qualit√©: {quality_score:.0f}/100 ‚ö†Ô∏è)"
            else:
                quality_info = f" (Qualit√©: {quality_score:.0f}/100 üî¥)"
        
        st.success(f"üìä **Dashboard aliment√© par vos donn√©es CSV{quality_info}**")
        
        # KPI M√©triques principales avec contexte validation
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            monthly_revenue = csv_data.get('monthly_revenue', 0)
            st.metric("CA Mensuel Moyen", f"{monthly_revenue:,.0f} DHS")
            
            growth = csv_data.get('revenue_growth', 0)
            if growth > 0:
                st.success(f"üìà Croissance {growth:.1f}%")
            else:
                st.error(f"üìâ D√©clin {abs(growth):.1f}%")
        
        with col2:
            monthly_costs = csv_data.get('monthly_costs', 0)
            st.metric("Co√ªts Mensuels Moyens", f"{monthly_costs:,.0f} DHS")
            
            cost_growth = csv_data.get('costs_growth', 0)
            if cost_growth < 5:
                st.success("‚úÖ Ma√Ætrise Co√ªts")
            else:
                st.warning(f"‚ö†Ô∏è Hausse {cost_growth:.1f}%")
        
        with col3:
            monthly_profit = csv_data.get('monthly_profit', 0)
            st.metric("Profit Mensuel Moyen", f"{monthly_profit:,.0f} DHS")
            
            if monthly_profit > 0:
                st.success("üí∞ Rentable")
            else:
                st.error("üî¥ D√©ficitaire")
        
        with col4:
            profit_margin = csv_data.get('profit_margin', 0)
            st.metric("Marge B√©n√©ficiaire", f"{profit_margin:.1f}%")
            
            if profit_margin > 20:
                st.success("üéØ Excellente")
            elif profit_margin > 10:
                st.info("üìà Bonne")
            elif profit_margin > 0:
                st.warning("‚ö†Ô∏è Faible")
            else:
                st.error("üî¥ N√©gative")
        
        # Indicateur de qualit√© donn√©es am√©lior√©
        if 'validation_results' in st.session_state:
            validation_results = st.session_state.validation_results
            quality_score = validation_results.get('quality_score', 100)
            
            if quality_score < 70:
                st.warning(f"‚ö†Ô∏è **Attention Qualit√© Donn√©es** : Score {quality_score:.0f}/100 - Interpr√©ter les m√©triques avec prudence")
                
                with st.expander("Voir d√©tails qualit√© donn√©es", expanded=False):
                    critical_issues = validation_results.get('critical_issues', 0)
                    total_issues = validation_results.get('total_issues', 0)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Probl√®mes Critiques", critical_issues)
                    with col2:
                        st.metric("Total Probl√®mes", total_issues)
        
        # Analyse de performance financi√®re am√©lior√©e
        st.subheader("üìà Analyse de Performance Financi√®re")
        
        # Afficher visualisations CSV avec contexte validation
        csv_figures = CSVDataManager.get_csv_visualizations()
        if csv_figures and 'financial_trend' in csv_figures:
            st.plotly_chart(csv_figures['financial_trend'], use_container_width=True)
            
            # Ajouter contexte qualit√© donn√©es
            if 'validation_results' in st.session_state:
                quality_score = st.session_state.validation_results.get('quality_score', 100)
                if quality_score < 70:
                    st.caption("‚ö†Ô∏è Graphique bas√© sur des donn√©es avec corrections automatiques appliqu√©es")
        
        # Insights am√©lior√©s avec validation
        csv_insights = CSVDataManager.get_csv_insights()
        if csv_insights:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ü§ñ Insights IA de Vos Donn√©es")
                for insight in csv_insights['insights']:
                    st.success(f"‚úÖ {insight}")
                
                # Ajouter insights bas√©s sur validation
                if 'validation_results' in st.session_state:
                    validation_results = st.session_state.validation_results
                    if validation_results.get('quality_score', 100) >= 90:
                        st.success("‚úÖ Donn√©es de tr√®s haute qualit√© - Analyses hautement fiables")
            
            with col2:
                st.markdown("#### üí° Recommandations")
                for rec in csv_insights['recommendations']:
                    st.info(f"üí° {rec}")
                
                # Ajouter recommandations qualit√© donn√©es
                if 'validation_results' in st.session_state:
                    validation_results = st.session_state.validation_results
                    quality_score = validation_results.get('quality_score', 100)
                    
                    if quality_score < 80:
                        st.warning("üîß Am√©liorer la qualit√© des donn√©es pour des analyses plus pr√©cises")
                    
                    if validation_results.get('critical_issues', 0) > 0:
                        st.error("üö® Corriger les incoh√©rences critiques en priorit√©")
            
            if csv_insights['alerts']:
                st.markdown("#### ‚ö†Ô∏è Alertes Risques")
                for alert in csv_insights['alerts']:
                    st.error(f"‚ö†Ô∏è {alert}")
        
        # R√©sum√© de performance am√©lior√© avec validation
        st.subheader("üìä R√©sum√© de Performance")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            annual_revenue = csv_data.get('revenue', 0)
            st.metric("CA Annuel", f"{annual_revenue:,.0f} DHS")
            
            volatility = csv_data.get('revenue_volatility', 0)
            if volatility < 0.1:
                st.success("üü¢ Stable")
            elif volatility < 0.3:
                st.warning("üü° Mod√©r√©")
            else:
                st.error("üî¥ Volatil")
        
        with col2:
            annual_profit = csv_data.get('net_profit', 0)
            st.metric("Profit Annuel", f"{annual_profit:,.0f} DHS")
            
            if annual_profit > 0:
                roi = (annual_profit / (annual_revenue * 0.6)) * 100
                st.metric("ROI", f"{roi:.1f}%")
        
        with col3:
            cash_flow = csv_data.get('cash_flow', 0)
            st.metric("Cash Flow Mensuel", f"{cash_flow:,.0f} DHS")
            
            if cash_flow > 0:
                st.success("üí∞ Positif")
            else:
                st.error("üî¥ N√©gatif")
        
        # R√©sum√© validation am√©lior√© pour dirigeants
        if 'validation_results' in st.session_state:
            validation_results = st.session_state.validation_results
            
            with st.expander("üìã R√©sum√© Qualit√© Donn√©es pour Direction", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    quality_score = validation_results.get('quality_score', 100)
                    st.metric("Score Qualit√© Global", f"{quality_score:.0f}/100")
                    
                    if quality_score >= 90:
                        st.success("üü¢ Excellente fiabilit√©")
                    elif quality_score >= 70:
                        st.info("üîµ Fiabilit√© acceptable")
                    else:
                        st.warning("üü° Fiabilit√© limit√©e")
                
                with col2:
                    corrections_applied = len(st.session_state.get('correction_log', []))
                    st.metric("Corrections Appliqu√©es", corrections_applied)
                    
                    if corrections_applied == 0:
                        st.success("‚úÖ Donn√©es brutes correctes")
                    else:
                        st.info("üîß Am√©liorations automatiques")
                
                with col3:
                    critical_issues = validation_results.get('critical_issues', 0)
                    st.metric("Probl√®mes Critiques", critical_issues)
                    
                    if critical_issues == 0:
                        st.success("‚úÖ Aucun probl√®me critique")
                    else:
                        st.error("üö® Attention requise")
    
    else:
        # Message am√©lior√© sans donn√©es
        st.warning("üì§ **Aucune Donn√©e CSV Import√©e**")
        st.info("Importez vos donn√©es financi√®res via Smart CSV Import pour voir une analyse compl√®te du dashboard avec validation avanc√©e !")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì§ Importer Donn√©es CSV", type="primary", use_container_width=True):
                st.session_state['current_page'] = 'csv_import'
                st.rerun()
        
        with col2:
            st.markdown("""
            **Ce que vous verrez avec les donn√©es CSV :**
            - Tendances r√©elles revenus et profits
            - Insights IA avec validation qualit√©
            - Analyse de croissance valid√©e
            - Alertes risques avec niveau confiance
            - Benchmarks performance sectoriels
            - Score qualit√© donn√©es en temps r√©el
            """)

# ========== ENHANCED ADVANCED ANALYTICS ==========
def show_advanced_analytics():
    """Analytics avanc√©s avec validation am√©lior√©e et capacit√©s ML"""
    st.header("üß† Advanced Analytics & Insights IA Am√©lior√©s")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    
    if not csv_data:
        st.warning("üì§ **Aucune Donn√©e CSV Disponible**")
        st.info("Advanced Analytics n√©cessite vos donn√©es CSV upload√©es pour fournir une analyse significative avec validation avanc√©e.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì§ Importer Donn√©es CSV Maintenant", type="primary", use_container_width=True):
                st.session_state['current_page'] = 'csv_import'
                st.rerun()
        
        with col2:
            st.markdown("""
            **Advanced Analytics fournira :**
            - Ratios financiers complets avec validation
            - Score sant√© IA avec corrections automatiques
            - Benchmarking sectoriel avanc√©
            - Insights pr√©dictifs avec niveau confiance
            - √âvaluations risques calibr√©es
            - Diagnostics incoh√©rences en temps r√©el
            """)
        return
    
    # Afficher contexte qualit√© donn√©es de mani√®re prominente
    if 'validation_results' in st.session_state:
        validation_results = st.session_state.validation_results
        quality_score = validation_results.get('quality_score', 100)
        
        if quality_score >= 80:
            st.success(f"üìä **Analytics aliment√©s par vos donn√©es CSV valid√©es (Qualit√©: {quality_score:.0f}/100) ‚úÖ**")
        elif quality_score >= 60:
            st.info(f"üìä **Analytics aliment√©s par vos donn√©es CSV (Qualit√©: {quality_score:.0f}/100) ‚ö†Ô∏è**")
        else:
            st.warning(f"üìä **Analytics avec donn√©es qualit√© limit√©e (Score: {quality_score:.0f}/100) - Interpr√©ter avec prudence üî¥**")
    else:
        st.success("üìä **Analytics aliment√©s par vos donn√©es CSV upload√©es**")
    
    # Initialiser moteur analytics avanc√©
    analytics = AdvancedAnalytics()
    
    # Calculer ratios complets avec validation
    ratios = analytics.calculate_comprehensive_ratios(csv_data)
    
    # Calculer score sant√© avec contexte validation
    validation_context = st.session_state.get('validation_results')
    health_score, score_breakdown = analytics.calculate_financial_health_score(ratios, 'technology', validation_context)
    
    # Aper√ßu sant√© financi√®re am√©lior√©
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Sant√© Financi√®re", f"{health_score:.0f}/100")
        
        if health_score >= 80:
            st.success("üü¢ Excellente")
        elif health_score >= 60:
            st.info("üîµ Bonne")
        elif health_score >= 40:
            st.warning("üü° Moyenne")
        else:
            st.error("üî¥ Faible")
        
        # Ajouter indicateur impact validation
        if validation_context and validation_context.get('quality_score', 100) < 80:
            st.caption("‚ö†Ô∏è Score ajust√© selon qualit√© donn√©es")
    
    with col2:
        current_ratio = csv_data.get('current_ratio', 0)
        st.metric("Ratio Liquidit√©", f"{current_ratio:.2f}")
        
        if current_ratio > 1.5:
            st.success("üü¢ Saine")
        elif current_ratio > 1.2:
            st.info("üîµ Mod√©r√©e")
        else:
            st.warning("üü° Faible")
    
    with col3:
        net_margin = csv_data.get('net_margin', 0)
        st.metric("Marge Nette", f"{net_margin*100:.1f}%")
        
        if net_margin > 0.15:
            st.success("üü¢ Forte")
        elif net_margin > 0.08:
            st.info("üîµ Moyenne")
        else:
            st.warning("üü° Faible")
    
    with col4:
        debt_to_equity = csv_data.get('debt_to_equity', 0)
        st.metric("Dette/Capitaux", f"{debt_to_equity:.2f}")
        
        if debt_to_equity < 0.5:
            st.success("üü¢ Conservateur")
        elif debt_to_equity < 1.0:
            st.info("üîµ Mod√©r√©")
        else:
            st.warning("üü° √âlev√©")
    
    with col5:
        revenue_volatility = csv_data.get('revenue_volatility', 0)
        stability_score = (1-revenue_volatility)*100
        st.metric("Stabilit√© CA", f"{stability_score:.0f}%")
        
        if revenue_volatility < 0.1:
            st.success("üü¢ Tr√®s Stable")
        elif revenue_volatility < 0.2:
            st.info("üîµ Stable")
        else:
            st.warning("üü° Volatile")
    
    # Analyse par onglets am√©lior√©e avec contexte validation
    tab1, tab2, tab3, tab4 = st.tabs(["üìà Analyse Performance", "ü§ñ Insights IA Avanc√©s", "üìä Ratios Financiers", "‚öïÔ∏è Diagnostic Donn√©es"])
    
    with tab1:
        st.subheader("Analyse Performance de Vos Donn√©es")
        
        # Afficher visualisation CSV originale avec am√©liorations
        csv_figures = CSVDataManager.get_csv_visualizations()
        if csv_figures and 'financial_trend' in csv_figures:
            st.plotly_chart(csv_figures['financial_trend'], use_container_width=True)
            
            # Ajouter annotations validation
            if validation_context:
                quality_score = validation_context.get('quality_score', 100)
                corrections_applied = len(st.session_state.get('correction_log', []))
                
                if corrections_applied > 0:
                    st.info(f"üìù Note : {corrections_applied} corrections automatiques appliqu√©es pour am√©liorer la pr√©cision")
                
                if quality_score < 80:
                    st.warning("‚ö†Ô∏è Donn√©es avec qualit√© mod√©r√©e - Tendances √† valider avec sources externes")
        
        # M√©triques performance am√©lior√©es
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìä Indicateurs Cl√©s de Performance")
            
            revenue_data = csv_data.get('revenue_data', [])
            if revenue_data:
                avg_revenue = np.mean(revenue_data)
                revenue_trend = "Croissance" if revenue_data[-1] > revenue_data[0] else "D√©clin"
                
                st.metric("CA Moyen", f"{avg_revenue:,.0f} DHS")
                st.metric("Tendance CA", revenue_trend)
                
                if len(revenue_data) > 1:
                    growth_rate = ((revenue_data[-1] / revenue_data[0]) - 1) * 100
                    st.metric("Croissance Totale", f"{growth_rate:+.1f}%")
                    
                    # Ajouter contexte validation pour croissance
                    if validation_context:
                        extreme_variations = any(abs(r2/r1 - 1) > 1.0 for r1, r2 in zip(revenue_data[:-1], revenue_data[1:]) if r1 != 0)
                        if extreme_variations:
                            st.caption("‚ö†Ô∏è Variations extr√™mes d√©tect√©es - Croissance peut inclure des corrections")
        
        with col2:
            st.markdown("#### üí∞ Analyse Rentabilit√©")
            
            profit_data = csv_data.get('profit_data', [])
            if profit_data:
                avg_profit = np.mean(profit_data)
                profit_trend = "Am√©lioration" if profit_data[-1] > profit_data[0] else "D√©t√©rioration"
                
                st.metric("Profit Moyen", f"{avg_profit:,.0f} DHS")
                st.metric("Tendance Profit", profit_trend)
                
                profit_margin = csv_data.get('profit_margin', 0)
                st.metric("Marge B√©n√©ficiaire", f"{profit_margin:.1f}%")
                
                # Ajouter insights validation pour rentabilit√©
                if validation_context:
                    profit_issues = [i for i in validation_context.get('issues', []) if 'Profit' in i.get('type', '')]
                    if profit_issues:
                        st.caption("‚ÑπÔ∏è Calculs profit valid√©s et corrig√©s automatiquement")
    
    with tab2:
        st.subheader("ü§ñ Insights IA Avanc√©s avec Validation")
        
        # Insights IA am√©lior√©s avec contexte validation
        csv_insights = CSVDataManager.get_csv_insights()
        if csv_insights:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ‚úÖ Insights Valid√©s")
                if csv_insights['insights']:
                    for insight in csv_insights['insights']:
                        st.success(f"‚úÖ {insight}")
                        
                        # Ajouter niveau confiance bas√© sur qualit√© donn√©es
                        if validation_context:
                            quality_score = validation_context.get('quality_score', 100)
                            if quality_score >= 90:
                                st.caption("üîπ Confiance √©lev√©e")
                            elif quality_score >= 70:
                                st.caption("üî∏ Confiance mod√©r√©e")
                            else:
                                st.caption("üî∏ Confiance limit√©e - Validation externe recommand√©e")
                else:
                    st.info("Aucun insight sp√©cifique g√©n√©r√© √† partir des donn√©es actuelles.")
                
                st.markdown("#### ‚ö†Ô∏è Alertes Valid√©es")
                if csv_insights['alerts']:
                    for alert in csv_insights['alerts']:
                        st.error(f"‚ö†Ô∏è {alert}")
                        
                        # Ajouter contexte qualit√© donn√©es aux alertes
                        if validation_context and validation_context.get('quality_score', 100) < 70:
                            st.caption("‚ö†Ô∏è Alerte bas√©e sur donn√©es qualit√© mod√©r√©e")
                else:
                    st.success("‚úÖ Aucune alerte critique d√©tect√©e !")
            
            with col2:
                st.markdown("#### üí° Recommandations IA Avanc√©es")
                
                # G√©n√©rer recommandations am√©lior√©es avec contexte validation
                try:
                    enhanced_recommendations = analytics.generate_ai_recommendations(
                        csv_data, ratios, health_score, validation_context
                    )
                    
                    if enhanced_recommendations:
                        for i, rec in enumerate(enhanced_recommendations):
                            priority_color = "üî¥" if rec['priority'] == 'Critique' else "üü†" if rec['priority'] == '√âlev√©e' else "üü°"
                            
                            with st.expander(f"{priority_color} {rec['category']} - Priorit√© {rec['priority']}", expanded=i < 2):
                                st.write(f"**Recommandation** : {rec['recommendation']}")
                                
                                col_a, col_b, col_c = st.columns(3)
                                with col_a:
                                    st.metric("Impact", rec['impact'])
                                with col_b:
                                    st.metric("D√©lai", rec['timeframe'])
                                with col_c:
                                    if isinstance(rec.get('estimated_benefit'), (int, float)):
                                        st.metric("B√©n√©fice Est.", f"{rec['estimated_benefit']:,.0f} DHS")
                                    else:
                                        st.metric("B√©n√©fice", rec.get('estimated_benefit', 'Qualitatif'))
                    else:
                        for rec in csv_insights['recommendations']:
                            st.warning(f"üí° {rec}")
                except Exception as e:
                    st.warning(f"Erreur g√©n√©ration recommandations avanc√©es: {str(e)}")
                    # Fallback aux recommandations de base
                    for rec in csv_insights.get('recommendations', []):
                        st.warning(f"üí° {rec}")
                
                # Ajouter recommandations sp√©cifiques qualit√© donn√©es
                if validation_context:
                    quality_score = validation_context.get('quality_score', 100)
                    critical_issues = validation_context.get('critical_issues', 0)
                    
                    st.markdown("#### üîß Recommandations Qualit√© Donn√©es")
                    
                    if quality_score < 50:
                        st.error("üö® **Urgent** : Refonte compl√®te du processus de collecte des donn√©es")
                    elif quality_score < 70:
                        st.warning("‚ö†Ô∏è **Important** : Am√©liorer les contr√¥les qualit√© lors de la saisie")
                    elif quality_score < 90:
                        st.info("‚ÑπÔ∏è **Suggestion** : Automatiser davantage la validation des donn√©es")
                    else:
                        st.success("‚úÖ **Excellent** : Maintenir les processus qualit√© actuels")
                    
                    if critical_issues > 0:
                        st.error(f"üî¥ **Action Imm√©diate** : Corriger {critical_issues} incoh√©rence(s) critique(s)")
        else:
            st.info("Uploadez des donn√©es CSV pour voir les insights IA avanc√©s sp√©cifiques √† votre entreprise")
    
    with tab3:
        st.subheader("üìä Analyse Ratios Financiers Avanc√©e")
        
        # Analyse ratios am√©lior√©e avec validation
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üîç Ratios de Liquidit√©")
            
            current_ratio = csv_data.get('current_ratio', 0)
            quick_ratio = (csv_data.get('current_assets', 0) - csv_data.get('inventory', 0)) / csv_data.get('current_liabilities', 1)
            cash_ratio = csv_data.get('cash', 0) / csv_data.get('current_liabilities', 1)
            
            ratios_data = {
                'Ratio': ['Ratio Liquidit√© G√©n√©rale', 'Ratio Liquidit√© R√©duite', 'Ratio Liquidit√© Imm√©diate'],
                'Valeur': [current_ratio, quick_ratio, cash_ratio],
                'Benchmark': [1.5, 1.0, 0.2],
                'Statut': []
            }
            
            for value, benchmark in zip(ratios_data['Valeur'], ratios_data['Benchmark']):
                if value >= benchmark * 1.2:
                    ratios_data['Statut'].append('Excellent')
                elif value >= benchmark:
                    ratios_data['Statut'].append('Bon')
                elif value >= benchmark * 0.8:
                    ratios_data['Statut'].append('Ad√©quat')
                else:
                    ratios_data['Statut'].append('Faible')
            
            df_ratios = pd.DataFrame(ratios_data)
            df_ratios['Valeur'] = df_ratios['Valeur'].round(2)
            
            st.dataframe(df_ratios, use_container_width=True)
            
            # Ajouter contexte validation pour ratios
            if validation_context and validation_context.get('quality_score', 100) < 80:
                st.caption("‚ö†Ô∏è Ratios calcul√©s avec donn√©es corrig√©es automatiquement")
        
        with col2:
            st.markdown("#### üí∞ Ratios de Rentabilit√©")
            
            gross_margin = (csv_data.get('gross_profit', 0) / csv_data.get('revenue', 1)) * 100
            net_margin = csv_data.get('net_margin', 0) * 100
            roa = (csv_data.get('net_profit', 0) / csv_data.get('total_assets', 1)) * 100
            
            profit_data = {
                'M√©trique': ['Marge Brute %', 'Marge Nette %', 'ROA %'],
                'Valeur': [gross_margin, net_margin, roa],
                'Moyenne Industrie': [40, 12, 8]
            }
            
            df_profit = pd.DataFrame(profit_data)
            df_profit['Valeur'] = df_profit['Valeur'].round(1)
            
            st.dataframe(df_profit, use_container_width=True)
            
            # Graphique rentabilit√© am√©lior√© avec contexte validation
            fig = go.Figure(data=[
                go.Bar(name='Votre Entreprise', x=profit_data['M√©trique'], y=profit_data['Valeur']),
                go.Bar(name='Moyenne Industrie', x=profit_data['M√©trique'], y=profit_data['Moyenne Industrie'])
            ])
            
            fig.update_layout(
                barmode='group',
                title='Rentabilit√© vs Moyenne Industrie',
                yaxis_title='Pourcentage (%)'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Ajouter indicateur confiance
            if validation_context:
                quality_score = validation_context.get('quality_score', 100)
                st.caption(f"Confiance analyse : {quality_score:.0f}%")
    
    with tab4:
        st.subheader("‚öïÔ∏è Diagnostic Avanc√© des Donn√©es")
        
        if validation_context:
            # Dashboard qualit√© donn√©es complet
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                quality_score = validation_context.get('quality_score', 100)
                st.metric("Score Qualit√© Global", f"{quality_score:.0f}/100")
                
                if quality_score >= 90:
                    st.success("üü¢ Excellente")
                elif quality_score >= 70:
                    st.info("üîµ Bonne")
                elif quality_score >= 50:
                    st.warning("üü° Mod√©r√©e")
                else:
                    st.error("üî¥ Faible")
            
            with col2:
                total_issues = validation_context.get('total_issues', 0)
                st.metric("Anomalies Totales", total_issues)
                
                if total_issues == 0:
                    st.success("‚úÖ Aucune")
                elif total_issues <= 2:
                    st.info("üîµ Limit√©es")
                else:
                    st.warning("üü° Attention")
            
            with col3:
                critical_issues = validation_context.get('critical_issues', 0)
                st.metric("Anomalies Critiques", critical_issues)
                
                if critical_issues == 0:
                    st.success("‚úÖ Aucune")
                else:
                    st.error(f"üî¥ {critical_issues}")
            
            with col4:
                corrections_count = len(st.session_state.get('correction_log', []))
                st.metric("Corrections Auto", corrections_count)
                
                if corrections_count == 0:
                    st.success("‚úÖ Aucune")
                else:
                    st.info(f"üîß {corrections_count}")
            
            # R√©partition validation d√©taill√©e
            st.markdown("#### üîç D√©tails Validation par Cat√©gorie")
            
            validation_categories = {}
            for issue in validation_context.get('issues', []):
                category = issue.get('type', 'Autre')
                severity = issue.get('severity', 'Inconnu')
                
                if category not in validation_categories:
                    validation_categories[category] = {'OK': 0, 'Moyenne': 0, '√âlev√©e': 0}
                
                validation_categories[category][severity] += 1
            
            if validation_categories:
                validation_df = pd.DataFrame(validation_categories).T.fillna(0)
                validation_df['Total'] = validation_df.sum(axis=1)
                
                st.dataframe(validation_df, use_container_width=True)
                
                # Visualisation r√©sultats validation
                fig = go.Figure()
                
                for severity in ['OK', 'Moyenne', '√âlev√©e']:
                    if severity in validation_df.columns:
                        color = 'green' if severity == 'OK' else 'orange' if severity == 'Moyenne' else 'red'
                        fig.add_trace(go.Bar(
                            name=severity,
                            x=validation_df.index,
                            y=validation_df[severity],
                            marker_color=color
                        ))
                
                fig.update_layout(
                    title="R√©partition des Validations par Cat√©gorie",
                    xaxis_title="Cat√©gorie de Validation",
                    yaxis_title="Nombre d'Occurrences",
                    barmode='stack'
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # D√©tails journal corrections
            correction_log = st.session_state.get('correction_log', [])
            if correction_log:
                st.markdown("#### üîß Journal D√©taill√© des Corrections")
                
                for i, correction in enumerate(correction_log):
                    with st.expander(f"Correction {i+1}: {correction.get('method', 'Correction Automatique')}", expanded=False):
                        col_a, col_b = st.columns(2)
                        
                        with col_a:
                            st.write(f"**M√©thode** : {correction.get('method', 'N/A')}")
                            
                            if 'outliers_found' in correction:
                                st.write(f"**Outliers d√©tect√©s** : {correction['outliers_found']}")
                            if 'missing_values_filled' in correction:
                                st.write(f"**Valeurs manquantes combl√©es** : {correction['missing_values_filled']}")
                            if 'values_corrected' in correction:
                                st.write(f"**Valeurs corrig√©es** : {correction['values_corrected']}")
                            if 'extreme_variations_smoothed' in correction:
                                st.write(f"**Variations extr√™mes liss√©es** : {correction['extreme_variations_smoothed']}")
                        
                        with col_b:
                            if 'replacement_value' in correction:
                                st.write(f"**Valeur de remplacement** : {correction['replacement_value']:.2f}")
                            if 'interpolation_method' in correction:
                                st.write(f"**M√©thode interpolation** : {correction['interpolation_method']}")
                            if 'threshold_used' in correction:
                                st.write(f"**Seuil utilis√©** : {correction['threshold_used']:.2f}")
                            if 'basis' in correction:
                                st.write(f"**Base de correction** : {correction['basis']}")
            
            # Recommandations qualit√© donn√©es
            st.markdown("#### üí° Recommandations Qualit√© Donn√©es")
            
            quality_score = validation_context.get('quality_score', 100)
            critical_issues = validation_context.get('critical_issues', 0)
            
            if critical_issues > 0:
                st.error("üö® **Action Imm√©diate Requise** : Corriger les incoh√©rences critiques d√©tect√©es")
            
            if quality_score < 60:
                st.error("üî¥ **Refonte Processus** : Score qualit√© tr√®s faible - Revoir compl√®tement la collecte des donn√©es")
            elif quality_score < 80:
                st.warning("üü° **Am√©lioration Processus** : Renforcer les contr√¥les qualit√© lors de la saisie")
            elif quality_score < 95:
                st.info("üîµ **Optimisation** : Automatiser davantage les validations pour atteindre l'excellence")
            else:
                st.success("‚úÖ **Excellence** : Maintenir les standards de qualit√© actuels")
        else:
            st.info("Donn√©es de validation non disponibles. R√©importez vos donn√©es CSV pour acc√©der au diagnostic avanc√©.")

# ========== ENHANCED SCENARIO PLANNING ==========
def show_scenario_planning():
    """Planification de sc√©narios avanc√©e avec auto-calibrage et validation - VERSION CORRIG√âE"""
    st.header("üéØ Planification de Sc√©narios Avanc√©e avec Auto-Calibrage")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    
    if not csv_data:
        st.warning("üì§ **Aucune Donn√©e CSV Disponible**")
        st.info("La Planification de Sc√©narios avanc√©e n√©cessite vos donn√©es CSV upload√©es pour un auto-calibrage pr√©cis bas√© sur votre historique.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì§ Importer Donn√©es CSV Maintenant", type="primary", use_container_width=True):
                st.session_state['current_page'] = 'csv_import'
                st.rerun()
        
        with col2:
            st.markdown("""
            **Avec vos donn√©es CSV, vous b√©n√©ficiez de :**
            - Auto-calibrage sc√©narios bas√© sur votre volatilit√© historique
            - D√©tection automatique de saisonnalit√©
            - Contraintes business personnalis√©es
            - Simulation Monte Carlo avec votre profil de risque
            - Validation qualit√© donn√©es pour fiabilit√© sc√©narios
            """)
        return
    
    # Afficher contexte qualit√© donn√©es pour sc√©narios
    quality_context = ""
    scenario_confidence = "√âlev√©e"
    
    if 'validation_results' in st.session_state:
        validation_results = st.session_state.validation_results
        quality_score = validation_results.get('quality_score', 100)
        
        if quality_score >= 80:
            quality_context = f" (Donn√©es valid√©es - Score: {quality_score:.0f}/100 ‚úÖ)"
            scenario_confidence = "Tr√®s √âlev√©e"
        elif quality_score >= 60:
            quality_context = f" (Qualit√© mod√©r√©e - Score: {quality_score:.0f}/100 ‚ö†Ô∏è)"
            scenario_confidence = "Mod√©r√©e"
        else:
            quality_context = f" (Qualit√© limit√©e - Score: {quality_score:.0f}/100 üî¥)"
            scenario_confidence = "Limit√©e"
            
        critical_issues = validation_results.get('critical_issues', 0)
        if critical_issues > 0:
            quality_context += f" - {critical_issues} incoh√©rence(s) critique(s)"
    
    st.success(f"üìä **Sc√©narios auto-calibr√©s sur vos donn√©es CSV{quality_context}**")
    
    # Donn√©es de base avec validation
    base_monthly_revenue = float(csv_data.get('monthly_revenue', 15000))
    base_monthly_costs = float(csv_data.get('monthly_costs', 12000))
    historical_volatility = float(csv_data.get('revenue_volatility', 0.2))
    current_growth_rate = float(csv_data.get('revenue_growth', 0)) / 100
    
    # Auto-calibrage avanc√© avec d√©tection industrie
    industry_manager = IndustryTemplateManager()
    detected_industry = industry_manager.detect_industry_from_csv(csv_data)
    
    # Calibrateur de sc√©narios am√©lior√©
    scenario_calibrator = EnhancedScenarioCalibrator()
    
    # Analyser patterns historiques pour calibrage
    revenue_data = csv_data.get('revenue_data', [])
    historical_analysis = scenario_calibrator.analyze_historical_volatility(revenue_data)
    
    # Aper√ßu des donn√©es de base avec contexte auto-calibrage
    st.subheader(f"üìä Donn√©es de Base Auto-Calibr√©es ({detected_industry.title()})")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("CA Mensuel Base", f"{base_monthly_revenue:,.0f} DHS")
        st.caption(f"Moyenne de {len(revenue_data)} points" if revenue_data else "Estimation")
    
    with col2:
        st.metric("Co√ªts Mensuels Base", f"{base_monthly_costs:,.0f} DHS")
        profit_base = base_monthly_revenue - base_monthly_costs
        st.caption(f"Profit base: {profit_base:,.0f} DHS")
    
    with col3:
        st.metric("Volatilit√© Historique", f"{historical_volatility:.1%}")
        volatility_level = "Faible" if historical_volatility < 0.1 else "Mod√©r√©e" if historical_volatility < 0.3 else "√âlev√©e"
        st.caption(f"Niveau: {volatility_level}")
    
    with col4:
        st.metric("Tendance Actuelle", f"{current_growth_rate*100:+.1f}%")
        trend_desc = "Croissance" if current_growth_rate > 0 else "D√©clin" if current_growth_rate < -0.05 else "Stable"
        st.caption(f"Direction: {trend_desc}")
    
    # Afficher r√©sultats auto-calibrage
    if historical_analysis:
        with st.expander("üîç D√©tails Auto-Calibrage Bas√© sur Votre Historique", expanded=False):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Points de Donn√©es", historical_analysis.get('data_points', 0))
                st.metric("Tendance D√©tect√©e", f"{historical_analysis.get('trend', 0)*100:+.2f}%")
            
            with col2:
                st.metric("Coefficient Variation", f"{historical_analysis.get('coefficient_variation', 0):.1%}")
                seasonality = "Oui" if historical_analysis.get('seasonality', False) else "Non"
                st.metric("Saisonnalit√©", seasonality)
            
            with col3:
                st.metric("Valeur Moyenne", f"{historical_analysis.get('mean_value', 0):,.0f} DHS")
                reliability = "Haute" if historical_analysis.get('data_points', 0) >= 12 else "Mod√©r√©e"
                st.metric("Fiabilit√© Calibrage", reliability)
    
    # Configuration sc√©narios avec auto-calibrage
    st.subheader("‚öôÔ∏è Configuration Sc√©narios Auto-Calibr√©s")
    
    # G√©n√©rer param√®tres auto-calibr√©s
    calibrated_scenarios = scenario_calibrator.calibrate_scenario_parameters(historical_analysis, detected_industry)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üò∞ Sc√©nario Pessimiste")
        st.caption("Auto-calibr√© selon votre volatilit√© historique")
        
        pess_revenue_auto = calibrated_scenarios['pessimistic']['revenue_change'] * 100
        pess_cost_auto = calibrated_scenarios['pessimistic']['cost_change'] * 100
        pess_prob_auto = calibrated_scenarios['pessimistic']['probability'] * 100
        
        pess_revenue = st.slider("√âvolution CA (%)", -50, 10, int(pess_revenue_auto), key="pess_rev", 
                                help=f"Valeur auto-calibr√©e: {pess_revenue_auto:.1f}%")
        pess_cost = st.slider("√âvolution Co√ªts (%)", -10, 40, int(pess_cost_auto), key="pess_cost",
                            help=f"Valeur auto-calibr√©e: {pess_cost_auto:.1f}%")
        pess_prob = st.slider("Probabilit√© (%)", 5, 40, int(pess_prob_auto), key="pess_prob",
                            help=f"Valeur auto-calibr√©e: {pess_prob_auto:.1f}%")
        
        if abs(pess_revenue - pess_revenue_auto) < 2:
            st.success("‚úÖ Align√© avec historique")
        else:
            st.info("üîß Valeur ajust√©e manuellement")
    
    with col2:
        st.markdown("### üòê Sc√©nario R√©aliste")
        st.caption("Bas√© sur votre tendance historique")
        
        real_revenue_auto = calibrated_scenarios['realistic']['revenue_change'] * 100
        real_cost_auto = calibrated_scenarios['realistic']['cost_change'] * 100
        real_prob_auto = calibrated_scenarios['realistic']['probability'] * 100
        
        real_revenue = st.slider("√âvolution CA (%)", -10, 40, int(real_revenue_auto), key="real_rev",
                                help=f"Valeur auto-calibr√©e: {real_revenue_auto:.1f}%")
        real_cost = st.slider("√âvolution Co√ªts (%)", 0, 25, int(real_cost_auto), key="real_cost",
                            help=f"Valeur auto-calibr√©e: {real_cost_auto:.1f}%")
        real_prob = st.slider("Probabilit√© (%)", 40, 80, int(real_prob_auto), key="real_prob",
                            help=f"Valeur auto-calibr√©e: {real_prob_auto:.1f}%")
        
        if abs(real_revenue - real_revenue_auto) < 2:
            st.success("‚úÖ Align√© avec historique")
        else:
            st.info("üîß Valeur ajust√©e manuellement")
    
    with col3:
        st.markdown("### üòÑ Sc√©nario Optimiste")
        st.caption("Calibr√© selon votre potentiel de croissance")
        
        opt_revenue_auto = calibrated_scenarios['optimistic']['revenue_change'] * 100
        opt_cost_auto = calibrated_scenarios['optimistic']['cost_change'] * 100
        opt_prob_auto = calibrated_scenarios['optimistic']['probability'] * 100
        
        opt_revenue = st.slider("√âvolution CA (%)", 10, 60, int(opt_revenue_auto), key="opt_rev",
                               help=f"Valeur auto-calibr√©e: {opt_revenue_auto:.1f}%")
        opt_cost = st.slider("√âvolution Co√ªts (%)", -5, 15, int(opt_cost_auto), key="opt_cost",
                           help=f"Valeur auto-calibr√©e: {opt_cost_auto:.1f}%")
        opt_prob = st.slider("Probabilit√© (%)", 5, 40, int(opt_prob_auto), key="opt_prob",
                           help=f"Valeur auto-calibr√©e: {opt_prob_auto:.1f}%")
        
        if abs(opt_revenue - opt_revenue_auto) < 2:
            st.success("‚úÖ Align√© avec historique")
        else:
            st.info("üîß Valeur ajust√©e manuellement")
    
    # Param√®tres avanc√©s avec contraintes business
    col1, col2 = st.columns(2)
    
    with col1:
        analysis_period = st.selectbox("P√©riode d'Analyse", [6, 12, 18, 24, 36], index=1,
                                     help="Plus longue p√©riode = plus d'incertitude")
        
        st.markdown("#### üè¢ Contraintes Business")
        apply_constraints = st.checkbox("Appliquer Contraintes Op√©rationnelles", value=True,
                                      help="Limiter les variations √† des niveaux r√©alistes")
        
        if apply_constraints:
            max_monthly_growth = st.slider("Croissance Max Mensuelle (%)", 5, 50, 20,
                                         help="Limite la croissance mensuelle maximale")
            max_monthly_decline = st.slider("D√©clin Max Mensuel (%)", 5, 30, 15,
                                          help="Limite le d√©clin mensuel maximal")
    
    with col2:
        st.markdown("#### üéØ Options Avanc√©es")
        include_seasonality = st.checkbox("Inclure Saisonnalit√©", 
                                        value=historical_analysis.get('seasonality', False),
                                        help="Appliquer patterns saisonniers d√©tect√©s")
        
        monte_carlo_sims = st.slider("Simulations Monte Carlo", 500, 2000, 1000,
                                   help="Plus de simulations = plus de pr√©cision")
        
        confidence_level = st.slider("Niveau de Confiance (%)", 80, 99, 95,
                                    help="Niveau de confiance pour intervalles")
        
        # Afficher confiance sc√©narios bas√©e sur qualit√© donn√©es
        st.metric("Confiance Sc√©narios", scenario_confidence)
        if scenario_confidence != "Tr√®s √âlev√©e":
            st.caption("‚ö†Ô∏è Bas√© sur qualit√© des donn√©es source")
    
    # Lancer analyse sc√©narios avec gestion d'erreurs am√©lior√©e
    if st.button("üöÄ Lancer Analyse Sc√©narios Avanc√©e", type="primary"):
        try:
            with st.spinner("Ex√©cution analyse sc√©narios avec auto-calibrage et Monte Carlo..."):
                
                # Normaliser probabilities pour qu'elles totalisent 100%
                total_prob = pess_prob + real_prob + opt_prob
                if total_prob != 100:
                    pess_prob = pess_prob * 100 / total_prob
                    real_prob = real_prob * 100 / total_prob
                    opt_prob = opt_prob * 100 / total_prob
                
                scenarios = {
                    'pessimistic': {
                        'revenue_change': float(pess_revenue) / 100,
                        'cost_change': float(pess_cost) / 100,
                        'probability': float(pess_prob) / 100
                    },
                    'realistic': {
                        'revenue_change': float(real_revenue) / 100,
                        'cost_change': float(real_cost) / 100,
                        'probability': float(real_prob) / 100
                    },
                    'optimistic': {
                        'revenue_change': float(opt_revenue) / 100,
                        'cost_change': float(opt_cost) / 100,
                        'probability': float(opt_prob) / 100
                    }
                }
                
                # Appliquer contraintes business si activ√©es
                if apply_constraints:
                    constraints = {
                        'max_revenue_decline': -max_monthly_decline / 100,
                        'max_cost_increase': max_monthly_growth / 100,
                        'min_margin': -0.2
                    }
                    scenarios = scenario_calibrator.apply_operational_constraints(scenarios, constraints)
                
                # Calculer r√©sultats pour chaque sc√©nario avec gestion d'erreurs
                scenario_results = {}
                
                for scenario_name, params in scenarios.items():
                    try:
                        monthly_results = []
                        
                        # Facteur saisonnier si activ√©
                        seasonal_factors = [1.0] * 12  # Default: pas de saisonnalit√©
                        if include_seasonality and historical_analysis.get('seasonality', False):
                            # Utiliser patterns saisonniers du template industrie
                            template = industry_manager.get_template(detected_industry)
                            seasonal_factors = template.get('seasonal_factors', [1.0] * 12)
                        
                        for month in range(analysis_period):
                            # Appliquer facteur saisonnier
                            seasonal_factor = seasonal_factors[month % 12] if include_seasonality else 1.0
                            
                            # Calculer revenus et co√ªts avec volatilit√© et saisonnalit√©
                            base_revenue_adjusted = base_monthly_revenue * seasonal_factor
                            monthly_revenue = base_revenue_adjusted * (1 + params['revenue_change'])
                            monthly_cost = base_monthly_costs * (1 + params['cost_change'])
                            
                            # Appliquer contraintes mensuelles si activ√©es
                            if apply_constraints:
                                if month > 0:
                                    prev_revenue = monthly_results[-1]['revenue']
                                    max_change = prev_revenue * (max_monthly_growth / 100)
                                    min_change = prev_revenue * (-max_monthly_decline / 100)
                                    
                                    revenue_change = monthly_revenue - prev_revenue
                                    revenue_change = max(min_change, min(max_change, revenue_change))
                                    monthly_revenue = prev_revenue + revenue_change
                            
                            monthly_profit = monthly_revenue - monthly_cost
                            
                            monthly_results.append({
                                'month': month + 1,
                                'revenue': float(max(0, monthly_revenue)),
                                'cost': float(max(0, monthly_cost)),
                                'profit': float(monthly_profit),
                                'seasonal_factor': float(seasonal_factor)
                            })
                        
                        # FIX: Calculer m√©triques finales avec gestion s√©curis√©e
                        total_profit = sum(float(m['profit']) for m in monthly_results)
                        total_revenue = sum(float(m['revenue']) for m in monthly_results) 
                        avg_monthly_profit = total_profit / analysis_period if analysis_period > 0 else 0.0
                        profit_margin = (total_profit / total_revenue * 100) if total_revenue > 0 else 0.0
                        
                        scenario_results[scenario_name] = {
                            'monthly_data': monthly_results,
                            'total_profit': float(total_profit),
                            'total_revenue': float(total_revenue),
                            'avg_monthly_profit': float(avg_monthly_profit),
                            'profit_margin': float(profit_margin),
                            'probability': float(params['probability'])
                        }
                        
                    except Exception as e:
                        st.error(f"Erreur calcul sc√©nario {scenario_name}: {str(e)}")
                        # FIX: Fournir valeurs par d√©faut s√©curis√©es
                        scenario_results[scenario_name] = {
                            'monthly_data': [],
                            'total_profit': 0.0,
                            'total_revenue': 0.0,
                            'avg_monthly_profit': 0.0,
                            'profit_margin': 0.0,
                            'probability': float(params['probability'])
                        }
                
                # G√©n√©rer simulations Monte Carlo avec donn√©es r√©elles
                mc_simulations = scenario_calibrator.generate_monte_carlo_scenarios(
                    revenue_data, monte_carlo_sims, analysis_period
                )
                
                # Sauvegarder r√©sultats avec m√©tadonn√©es am√©lior√©es
                st.session_state.scenario_results = {
                    'scenarios': scenario_results,
                    'monte_carlo': mc_simulations,
                    'metadata': {
                        'analysis_period': analysis_period,
                        'confidence_level': confidence_level,
                        'industry': detected_industry,
                        'seasonality_applied': include_seasonality,
                        'constraints_applied': apply_constraints,
                        'auto_calibrated': True,
                        'data_quality_score': validation_results.get('quality_score', 100) if 'validation_results' in st.session_state else 100,
                        'historical_volatility': historical_volatility,
                        'calibration_confidence': scenario_confidence
                    }
                }
                
                st.success("‚úÖ Analyse sc√©narios compl√©t√©e avec succ√®s !")
                
        except Exception as e:
            st.error(f"Erreur lors de l'analyse des sc√©narios: {str(e)}")
            st.info("V√©rification des param√®tres d'entr√©e et nouvelle tentative recommand√©e.")
    
    # Afficher r√©sultats avec gestion d'erreurs am√©lior√©e
    if 'scenario_results' in st.session_state and st.session_state.scenario_results:
        try:
            scenario_data = st.session_state.scenario_results
            scenario_results = scenario_data['scenarios']
            metadata = scenario_data.get('metadata', {})
            
            st.subheader("üìä R√©sultats Analyse Sc√©narios Avanc√©e")
            
            # M√©triques principales avec contexte validation
            # FIX: Calcul s√©curis√© de expected_value
            scenario_profits = {}
            for name, data in scenario_results.items():
                if isinstance(data, dict) and all(k in data for k in ['total_profit', 'probability']):
                    scenario_profits[name] = {
                        'total_profit': float(data.get('total_profit', 0)),
                        'probability': float(data.get('probability', 0))
                    }
            
            if scenario_profits:
                # FIX: Calcul expected_value s√©curis√©
                expected_value = sum(
                    float(data['total_profit']) * float(data['probability']) 
                    for data in scenario_profits.values()
                    if isinstance(data.get('total_profit'), (int, float)) and isinstance(data.get('probability'), (int, float))
                )
                
                profit_values = [float(data['total_profit']) for data in scenario_profits.values() 
                               if isinstance(data.get('total_profit'), (int, float))]
                
                best_case = max(profit_values) if profit_values else 0.0
                worst_case = min(profit_values) if profit_values else 0.0
                profit_range = best_case - worst_case
                
                # Calculer upside potential et risk ratio
                upside_potential = max(0, best_case - expected_value)
                downside_risk = max(0, expected_value - worst_case)
                risk_ratio = upside_potential / downside_risk if downside_risk > 0 else float('inf')
                
                # Affichage m√©triques principales
                col1, col2, col3, col4, col5 = st.columns(5)
                
                with col1:
                    st.metric("Valeur Esp√©r√©e", f"{expected_value:,.0f} DHS")
                    if expected_value > 0:
                        st.success("üü¢ Positif")
                    else:
                        st.error("üî¥ N√©gatif")
                
                with col2:
                    st.metric("Meilleur Cas", f"{best_case:,.0f} DHS")
                    st.caption(f"Potentiel upside")
                
                with col3:
                    st.metric("Pire Cas", f"{worst_case:,.0f} DHS")
                    st.caption(f"Risque downside")
                
                with col4:
                    st.metric("Fourchette", f"{profit_range:,.0f} DHS")
                    st.caption("Amplitude totale")
                
                with col5:
                    st.metric("Confiance Analyse", metadata.get('calibration_confidence', 'Mod√©r√©e'))
                    quality_score = metadata.get('data_quality_score', 100)
                    if quality_score >= 80:
                        st.success("üü¢ Fiable")
                    else:
                        st.warning("üü° Attention")
                
                # Afficher contexte auto-calibrage
                if metadata.get('auto_calibrated', False):
                    st.info(f"ü§ñ **Sc√©narios auto-calibr√©s** pour industrie {metadata.get('industry', 'g√©n√©rale').title()} "
                           f"avec {metadata.get('analysis_period', 12)} mois d'analyse")
                
                # Visualisation avanc√©e avec Monte Carlo
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    # Graphique principal des sc√©narios avec saisonnalit√©
                    fig = go.Figure()
                    
                    colors = {'pessimistic': '#FF6B6B', 'realistic': '#4ECDC4', 'optimistic': '#45B7D1'}
                    
                    for scenario, data in scenario_results.items():
                        if isinstance(data, dict) and 'monthly_data' in data:
                            monthly_data = data['monthly_data']
                            if monthly_data:
                                months = [m.get('month', i+1) for i, m in enumerate(monthly_data)]
                                profits = [float(m.get('profit', 0)) for m in monthly_data]
                                cumulative_profit = np.cumsum(profits)
                                
                                # Ligne principale
                                fig.add_trace(go.Scatter(
                                    x=months,
                                    y=cumulative_profit,
                                    mode='lines+markers',
                                    name=f"{scenario.title()} (P: {data.get('probability', 0):.0%})",
                                    line=dict(color=colors.get(scenario, 'gray'), width=3),
                                    hovertemplate=f"<b>{scenario.title()}</b><br>" +
                                                f"Mois: %{{x}}<br>" +
                                                f"Profit Cumul√©: %{{y:,.0f}} DHS<extra></extra>"
                                ))
                                
                                # Ajouter pattern saisonnier si appliqu√©
                                if metadata.get('seasonality_applied', False):
                                    seasonal_factors = [m.get('seasonal_factor', 1.0) for m in monthly_data]
                                    if any(f != 1.0 for f in seasonal_factors):
                                        fig.add_trace(go.Scatter(
                                            x=months,
                                            y=[f * 1000 for f in seasonal_factors],  # Scale pour visibilit√©
                                            mode='lines',
                                            name=f"Saisonnalit√© {scenario}",
                                            line=dict(color=colors.get(scenario, 'gray'), width=1, dash='dot'),
                                            opacity=0.3,
                                            yaxis='y2',
                                            showlegend=False
                                        ))
                    
                    # Ligne de r√©f√©rence rentabilit√©
                    fig.add_hline(y=0, line_dash="dash", line_color="gray", 
                                 annotation_text="Seuil de rentabilit√©")
                    
                    fig.update_layout(
                        title="√âvolution Profit Cumul√© par Sc√©nario",
                        xaxis_title="Mois",
                        yaxis_title="Profit Cumul√© (DHS)",
                        height=500,
                        hovermode='x unified'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Analyse de risque
                    st.markdown("#### üéØ Analyse de Risque")
                    
                    st.metric("Potentiel Haussier", f"{upside_potential:,.0f} DHS")
                    st.metric("Ratio Risque/Rendement", f"{risk_ratio:.2f}" if risk_ratio != float('inf') else "‚àû")
                    
                    # Risk assessment
                    if risk_ratio > 2:
                        st.success("üü¢ Profil risque favorable")
                    elif risk_ratio > 1:
                        st.info("üîµ Profil risque √©quilibr√©")
                    else:
                        st.warning("üü° Profil risque √©lev√©")
                    
                    # Recommandations strat√©giques
                    st.markdown("#### üéØ Recommandations")
                    
                    if worst_case > 0:
                        st.success("‚úÖ **Tous sc√©narios rentables**")
                        st.info("üí° Focus croissance et optimisation")
                    elif expected_value > 0:
                        st.warning("‚ö†Ô∏è **Risque pire cas**")
                        st.info("üí° Pr√©parer plans contingence")
                    else:
                        st.error("üî¥ **Rentabilit√© incertaine**")
                        st.error("üí° Actions correctives urgentes")
                
                # Tableau comparatif d√©taill√©
                st.markdown("#### üìã Comparatif D√©taill√© des Sc√©narios")
                
                comparison_data = []
                for scenario, data in scenario_results.items():
                    if isinstance(data, dict):
                        comparison_data.append({
                            'Sc√©nario': scenario.title(),
                            'Profit Total': f"{float(data.get('total_profit', 0)):,.0f} DHS",
                            'Revenus Totaux': f"{float(data.get('total_revenue', 0)):,.0f} DHS",
                            'Marge Moyenne': f"{float(data.get('profit_margin', 0)):.1f}%",
                            'Profit Mensuel Moyen': f"{float(data.get('avg_monthly_profit', 0)):,.0f} DHS",
                            'Probabilit√©': f"{float(data.get('probability', 0)):.0%}"
                        })
                
                if comparison_data:
                    df_comparison = pd.DataFrame(comparison_data)
                    st.dataframe(df_comparison, use_container_width=True, hide_index=True)
                
                # Monte Carlo si disponible
                mc_simulations = scenario_data.get('monte_carlo', [])
                if mc_simulations and len(mc_simulations) > 10:
                    st.markdown("#### üé≤ R√©sultats Simulation Monte Carlo")
                    
                    mc_values = [sim.get('total_value', 0) for sim in mc_simulations if isinstance(sim.get('total_value'), (int, float))]
                    
                    if mc_values:
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            mc_mean = np.mean(mc_values)
                            st.metric("Moyenne MC", f"{mc_mean:,.0f} DHS")
                        
                        with col2:
                            var_5 = np.percentile(mc_values, 5)
                            st.metric("VaR 5%", f"{var_5:,.0f} DHS")
                        
                        with col3:
                            prob_positive = (np.array(mc_values) > 0).mean() * 100
                            st.metric("Prob. Profit", f"{prob_positive:.1f}%")
                        
                        with col4:
                            mc_volatility = np.std(mc_values)
                            st.metric("Volatilit√© MC", f"{mc_volatility:,.0f} DHS")
                        
                        # Distribution Monte Carlo
                        fig_mc = go.Figure(data=[go.Histogram(
                            x=mc_values,
                            nbinsx=50,
                            name='Distribution Monte Carlo',
                            opacity=0.7
                        )])
                        
                        fig_mc.add_vline(x=var_5, line_dash="dash", line_color="red", 
                                       annotation_text="VaR 5%")
                        fig_mc.add_vline(x=0, line_dash="solid", line_color="black", 
                                       annotation_text="Seuil Rentabilit√©")
                        fig_mc.add_vline(x=mc_mean, line_dash="dot", line_color="green", 
                                       annotation_text="Moyenne")
                        
                        fig_mc.update_layout(
                            title=f"Distribution Monte Carlo ({len(mc_simulations)} simulations)",
                            xaxis_title="Profit Total (DHS)",
                            yaxis_title="Fr√©quence",
                            height=400
                        )
                        
                        st.plotly_chart(fig_mc, use_container_width=True)
                
                # Impact qualit√© donn√©es sur sc√©narios
                if 'validation_results' in st.session_state:
                    quality_score = st.session_state.validation_results.get('quality_score', 100)
                    
                    with st.expander("üìä Impact Qualit√© Donn√©es sur Sc√©narios", expanded=False):
                        if quality_score >= 90:
                            st.success("üü¢ **Haute Confiance** : Sc√©narios bas√©s sur donn√©es haute qualit√©")
                        elif quality_score >= 70:
                            st.info("üîµ **Confiance Mod√©r√©e** : Sc√©narios fiables avec corrections appliqu√©es")
                            st.caption("Recommandation : Valider r√©sultats avec sources externes")
                        else:
                            st.warning("üü° **Confiance Limit√©e** : Sc√©narios bas√©s sur donn√©es qualit√© mod√©r√©e")
                            st.caption("Recommandation : Am√©liorer qualit√© donn√©es avant d√©cisions strat√©giques")
                        
                        corrections_count = len(st.session_state.get('correction_log', []))
                        if corrections_count > 0:
                            st.info(f"‚ÑπÔ∏è {corrections_count} corrections automatiques appliqu√©es aux donn√©es source")
            
            else:
                st.warning("Aucun r√©sultat de sc√©nario valide disponible. V√©rifiez la configuration des param√®tres.")
                
        except Exception as e:
            st.error(f"Erreur affichage r√©sultats sc√©narios: {str(e)}")
            st.info("Tentez de relancer l'analyse avec des param√®tres diff√©rents.")

# ========== ENHANCED ML FORECASTING ==========
def show_ml_forecasting():
    """Pr√©visions ML avanc√©es avec ensemble methods et validation - VERSION CORRIG√âE"""
    st.header("ü§ñ Pr√©visions ML Financi√®res Avanc√©es")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    
    if not csv_data:
        st.warning("üì§ **Aucune Donn√©e CSV Disponible**")
        st.info("Les Pr√©visions ML n√©cessitent vos donn√©es CSV upload√©es pour entra√Æner des mod√®les pr√©cis avec validation crois√©e.")
        
        if st.button("üì§ Importer Donn√©es CSV Maintenant", type="primary"):
            st.session_state['current_page'] = 'csv_import'
            st.rerun()
        return
    
    # Display enhanced data quality context for ML
    quality_context = ""
    model_confidence = "√âlev√©e"
    
    if 'validation_results' in st.session_state:
        quality_score = st.session_state.validation_results.get('quality_score', 100)
        if quality_score >= 90:
            quality_context = f" (Donn√©es haute qualit√© - Score: {quality_score:.0f}/100 ‚úÖ)"
            model_confidence = "Tr√®s √âlev√©e"
        elif quality_score >= 70:
            quality_context = f" (Donn√©es qualit√© mod√©r√©e - Score: {quality_score:.0f}/100 ‚ö†Ô∏è)"
            model_confidence = "Mod√©r√©e"
        else:
            quality_context = f" (Donn√©es qualit√© limit√©e - Score: {quality_score:.0f}/100 üî¥)"
            model_confidence = "Limit√©e"
    
    st.success(f"üìä **Mod√®les ML entra√Æn√©s sur vos donn√©es CSV{quality_context}**")
    
    # Enhanced ML engine
    ml_engine = EnhancedMLForecastingEngine()
    
    # Get available data for forecasting with validation
    available_metrics = get_available_forecast_metrics(csv_data)
    
    # Enhanced data overview
    st.subheader("üìä Aper√ßu Donn√©es d'Entra√Ænement")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_data_points = len(csv_data.get('revenue_data', []))
        st.metric("Points de Donn√©es", total_data_points)
        
        if total_data_points >= 24:
            data_quality = "Excellente"
            st.success("üü¢ Excellente")
        elif total_data_points >= 12:
            data_quality = "Bonne"
            st.info("üîµ Bonne")
        elif total_data_points >= 6:
            data_quality = "Suffisante"
            st.warning("üü° Suffisante")
        else:
            data_quality = "Limit√©e"
            st.error("üî¥ Limit√©e")
    
    with col2:
        st.metric("Variables Disponibles", len(available_metrics))
        st.metric("Algorithmes ML", "Ensemble + Validation")
    
    with col3:
        if csv_data.get('revenue_data'):
            revenue_data = csv_data['revenue_data']
            revenue_trend = "Croissance" if revenue_data[-1] > revenue_data[0] else "D√©clin"
            st.metric("Tendance CA", revenue_trend)
            
            volatility = np.std(revenue_data) / np.mean(revenue_data) if np.mean(revenue_data) > 0 else 0
            st.metric("Volatilit√© Donn√©es", f"{volatility:.1%}")
    
    with col4:
        st.metric("Confiance Mod√®le", model_confidence)
        
        # ML readiness assessment
        ml_readiness = 100
        if total_data_points < 12:
            ml_readiness -= 30
        if csv_data.get('revenue_volatility', 0) > 0.5:
            ml_readiness -= 20
        if 'validation_results' in st.session_state:
            quality_score = st.session_state.validation_results.get('quality_score', 100)
            ml_readiness = ml_readiness * (quality_score / 100)
        
        st.metric("Readiness ML", f"{ml_readiness:.0f}%")
    
    # Enhanced Forecasting Configuration
    st.subheader("üîÆ Configuration Pr√©visions ML Avanc√©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Enhanced forecast target selection
        forecast_target = st.selectbox(
            "Cible de Pr√©vision",
            available_metrics,
            help="Choisir la variable √† pr√©voir bas√©e sur vos donn√©es upload√©es"
        )
        
        forecast_periods = st.slider("P√©riodes de Pr√©vision (mois)", 3, 36, 12)
        
        # Advanced ML options
        st.markdown("#### üîß Options ML Avanc√©es")
        include_trend = st.checkbox("Analyse Tendance", value=True, help="Inclure l'analyse de tendance temporelle")
        include_seasonality = st.checkbox("Analyse Saisonnalit√©", value=True, help="D√©tecter et mod√©liser la saisonnalit√©")
        use_ensemble = st.checkbox("M√©thodes Ensemble", value=True, help="Utiliser plusieurs algorithmes pour plus de robustesse")
        
        # Enhanced model selection
        if use_ensemble:
            model_type = st.selectbox(
                "Type Mod√®le",
                ["Auto Ensemble (Recommand√©)", "Random Forest + Linear", "Ensemble Complet"],
                help="Choisir l'approche d'ensemble pour les pr√©visions"
            )
        else:
            model_type = st.selectbox(
                "Algorithme ML",
                ["Random Forest", "R√©gression Lin√©aire", "Moyenne Mobile Adaptative"],
                help="Choisir l'algorithme de pr√©vision"
            )
    
    with col2:
        confidence_level = st.slider("Niveau Confiance (%)", 80, 99, 95)
        
        # Enhanced forecast scenarios
        st.markdown("#### üìà Sc√©narios de Pr√©vision")
        include_scenarios = st.checkbox("G√©n√©rer Sc√©narios Multiples", value=True, help="Cr√©er des sc√©narios optimiste/pessimiste")
        
        if include_scenarios:
            optimistic_factor = st.slider("Sc√©nario Optimiste (+%)", 5, 50, 20)
            pessimistic_factor = st.slider("Sc√©nario Pessimiste (-%)", 5, 50, 15)
        
        # Enhanced external factors
        st.markdown("#### üåç Facteurs Externes")
        market_growth = st.slider("Croissance March√© Attendue (%)", -20, 30, 5)
        economic_impact = st.selectbox("Perspectives √âconomiques", ["Positive", "Neutre", "N√©gative"])
        
        # Business constraints
        st.markdown("#### üè¢ Contraintes Business")
        apply_constraints = st.checkbox("Appliquer Contraintes", value=True, help="Limiter les pr√©visions aux plages r√©alistes")
        
        if apply_constraints:
            max_growth = st.slider("Croissance Max Mensuelle (%)", 5, 100, 25, help="Limite la croissance mensuelle maximale")
            min_decline = st.slider("D√©clin Max Mensuel (%)", 5, 50, 20, help="Limite le d√©clin mensuel maximal")
    
    # Historical data visualization for selected variable with enhancements
    if forecast_target in available_metrics:
        st.subheader(f"üìà Analyse Donn√©es Historiques : {forecast_target}")
        
        # Get data for selected target
        target_data = get_target_data(csv_data, forecast_target)
        
        if target_data and len(target_data) > 0:
            months = list(range(1, len(target_data) + 1))
            
            # Enhanced historical visualization
            fig = make_subplots(rows=2, cols=1, 
                              subplot_titles=[f'Donn√©es Historiques {forecast_target}', 'Analyse de Distribution'],
                              vertical_spacing=0.1)
            
            # Main time series
            fig.add_trace(go.Scatter(
                x=months,
                y=target_data,
                mode='lines+markers',
                name=f'Historique {forecast_target}',
                line=dict(color='blue', width=3),
                marker=dict(size=6)
            ), row=1, col=1)
            
            # Add trend line if requested
            if include_trend and len(target_data) > 3:
                x_trend = np.arange(len(target_data))
                slope, intercept = np.polyfit(x_trend, target_data, 1)
                trend_line = slope * x_trend + intercept
                
                fig.add_trace(go.Scatter(
                    x=months,
                    y=trend_line,
                    mode='lines',
                    name='Ligne de Tendance',
                    line=dict(color='red', width=2, dash='dash')
                ), row=1, col=1)
                
                # Display trend statistics
                trend_slope_monthly = slope
                trend_annual = trend_slope_monthly * 12
                st.caption(f"üìà Tendance d√©tect√©e : {trend_annual:+.1f} unit√©s/an ({trend_slope_monthly:+.2f}/mois)")
            
            # Distribution analysis
            fig.add_trace(go.Histogram(
                x=target_data,
                name='Distribution',
                nbinsx=min(20, len(target_data)//2),
                marker=dict(color='lightblue', opacity=0.7)
            ), row=2, col=1)
            
            fig.update_layout(
                title=f"Analyse Compl√®te {forecast_target}",
                height=600,
                showlegend=True
            )
            
            fig.update_xaxes(title_text="Mois", row=1, col=1)
            fig.update_yaxes(title_text=f"{forecast_target}", row=1, col=1)
            fig.update_xaxes(title_text=f"Valeurs {forecast_target}", row=2, col=1)
            fig.update_yaxes(title_text="Fr√©quence", row=2, col=1)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Enhanced statistical summary
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Moyenne", f"{np.mean(target_data):,.2f}")
                st.metric("M√©diane", f"{np.median(target_data):,.2f}")
            
            with col2:
                st.metric("√âcart-Type", f"{np.std(target_data):,.2f}")
                st.metric("Coefficient Variation", f"{np.std(target_data)/np.mean(target_data):.1%}")
            
            with col3:
                st.metric("Minimum", f"{np.min(target_data):,.2f}")
                st.metric("Maximum", f"{np.max(target_data):,.2f}")
            
            with col4:
                if len(target_data) > 1:
                    growth_rate = ((target_data[-1] / target_data[0]) - 1) * 100
                    st.metric("Croissance Totale", f"{growth_rate:+.1f}%")
                    
                    monthly_growth = (target_data[-1] / target_data[0]) ** (1/len(target_data)) - 1
                    st.metric("Croissance Mensuelle", f"{monthly_growth*100:+.2f}%")
            
            # Data quality impact on forecasting
            if 'validation_results' in st.session_state:
                validation_results = st.session_state.validation_results
                quality_score = validation_results.get('quality_score', 100)
                
                if quality_score < 80:
                    st.warning(f"‚ö†Ô∏è **Impact Qualit√©** : Score {quality_score:.0f}/100 peut affecter la pr√©cision des pr√©visions ML")
                    
                    corrections_applied = len(st.session_state.get('correction_log', []))
                    if corrections_applied > 0:
                        st.info(f"‚ÑπÔ∏è {corrections_applied} corrections automatiques appliqu√©es pour am√©liorer la fiabilit√©")
    
    # Generate enhanced ML forecast
    if st.button("üöÄ G√©n√©rer Pr√©visions ML Avanc√©es", type="primary"):
        with st.spinner("Entra√Ænement mod√®les ML avanc√©s et g√©n√©ration pr√©visions..."):
            
            target_data = get_target_data(csv_data, forecast_target)
            
            if not target_data or len(target_data) < 3:
                st.error("‚ùå Donn√©es insuffisantes pour pr√©visions ML. Besoin d'au moins 3 points de donn√©es.")
                return
            
            # Prepare external factors and constraints
            external_factors = {
                'market_growth': market_growth / 100,
                'economic_impact': {'Positive': 1.1, 'Neutre': 1.0, 'N√©gative': 0.95}[economic_impact]
            }
            
            business_constraints = None
            if apply_constraints:
                business_constraints = {
                    'max_growth': max_growth / 100,
                    'min_growth': -min_decline / 100,
                    'smooth_factor': 0.3
                }
            
            # Generate enhanced forecasts using the improved ML engine
            forecast_results = ml_engine.enhanced_forecast(
                target_data,
                forecast_periods,
                confidence_level,
                external_factors,
                business_constraints
            )
            
            # FIX: V√©rifier que forecast_results contient 'forecasts'
            if forecast_results is None or 'forecasts' not in forecast_results:
                st.error("‚ùå Erreur lors de la g√©n√©ration des pr√©visions ML.")
                return
            
            # Add scenarios if requested
            if include_scenarios:
                base_forecasts = forecast_results['forecasts']
                forecast_results['scenarios'] = generate_forecast_scenarios(
                    base_forecasts,
                    optimistic_factor / 100,
                    pessimistic_factor / 100
                )
            
            # Add data quality metrics to results
            if 'validation_results' in st.session_state:
                forecast_results['data_quality'] = {
                    'quality_score': st.session_state.validation_results.get('quality_score', 100),
                    'confidence_adjustment': model_confidence,
                    'corrections_applied': len(st.session_state.get('correction_log', []))
                }
            
            forecast_results['target'] = forecast_target
            forecast_results['external_factors'] = external_factors
            forecast_results['business_constraints'] = business_constraints
            
            st.session_state.enhanced_ml_results = forecast_results
    
    # Display enhanced forecast results with error handling
    if 'enhanced_ml_results' in st.session_state:
        try:
            display_enhanced_forecast_results(st.session_state.enhanced_ml_results, csv_data)
        except Exception as e:
            st.error(f"Erreur affichage r√©sultats pr√©visions: {str(e)}")

def get_available_forecast_metrics(csv_data):
    """Get list of available metrics for forecasting based on CSV data"""
    available = []
    
    # Core financial metrics
    if csv_data.get('revenue_data'):
        available.append("Revenus")
    if csv_data.get('costs_data'):
        available.append("Co√ªts")
    if csv_data.get('profit_data'):
        available.append("Profit")
    
    # Check for other metrics in the CSV processor's detected mappings
    if 'csv_data' in st.session_state and 'mappings' in st.session_state.csv_data:
        mappings = st.session_state.csv_data['mappings']
        
        metric_mapping = {
            'cash_flow': "Cash Flow",
            'assets': "Total Actifs", 
            'current_assets': "Actifs Courants", 
            'fixed_assets': "Actifs Fixes",
            'liabilities': "Total Passifs",
            'current_liabilities': "Passifs Courants",
            'equity': "Capitaux Propres",
            'inventory': "Stocks",
            'accounts_receivable': "Cr√©ances Clients",
            'accounts_payable': "Dettes Fournisseurs",
            'customer_metrics': "Nombre Clients",
            'unit_metrics': "Unit√©s Vendues",
            'pricing_metrics': "Prix Moyen",
            'saas_metrics': "M√©triques SaaS"
        }
        
        for key, display_name in metric_mapping.items():
            if key in mappings and display_name not in available:
                available.append(display_name)
    
    # Financial ratios (calculated)
    if len(available) >= 2:
        available.extend([
            "Marge B√©n√©ficiaire %",
            "Ratio Liquidit√©",
            "Taux Croissance CA"
        ])
    
    return available if available else ["Revenus", "Profit"]  # Fallback

def get_target_data(csv_data, target):
    """Get data array for the selected forecast target"""
    target_mapping = {
        "Revenus": csv_data.get('revenue_data', []),
        "Co√ªts": csv_data.get('costs_data', []),
        "Profit": csv_data.get('profit_data', []),
        "Cash Flow": csv_data.get('cash_flow_data', []),
        # Add more mappings based on available data
    }
    
    # For calculated metrics
    if target == "Marge B√©n√©ficiaire %":
        revenue_data = csv_data.get('revenue_data', [])
        profit_data = csv_data.get('profit_data', [])
        if revenue_data and profit_data:
            return [(p/r)*100 for p, r in zip(profit_data, revenue_data) if r != 0]
    
    if target == "Taux Croissance CA":
        revenue_data = csv_data.get('revenue_data', [])
        if len(revenue_data) > 1:
            return [((revenue_data[i] - revenue_data[i-1]) / revenue_data[i-1]) * 100 
                   for i in range(1, len(revenue_data)) if revenue_data[i-1] != 0]
    
    return target_mapping.get(target, csv_data.get('revenue_data', []))

def generate_forecast_scenarios(base_forecasts, optimistic_factor, pessimistic_factor):
    """Generate optimistic and pessimistic scenarios"""
    return {
        'optimistic': [f * (1 + optimistic_factor) for f in base_forecasts],
        'pessimistic': [f * (1 - pessimistic_factor) for f in base_forecasts],
        'base': base_forecasts
    }

def display_enhanced_forecast_results(results, csv_data):
    """Display enhanced forecast results with comprehensive analysis - VERSION CORRIG√âE"""
    
    # FIX: V√©rifier que 'forecasts' existe dans results
    if not results or 'forecasts' not in results:
        st.warning("‚ùå Aucun r√©sultat de pr√©vision disponible ou donn√©es incompl√®tes.")
        return
    
    st.subheader("üìà R√©sultats Pr√©visions ML Avanc√©es")
    
    # Enhanced summary metrics with data quality context
    col1, col2, col3, col4, col5 = st.columns(5)
    
    forecasts = results['forecasts']
    target = results.get('target', 'Variable')
    
    with col1:
        avg_forecast = np.mean(forecasts)
        st.metric("Pr√©vision Moyenne", f"{avg_forecast:,.0f}")
    
    with col2:
        total_forecast = sum(forecasts)
        periods = results.get('periods', len(forecasts))
        st.metric(f"Total {periods}-Mois", f"{total_forecast:,.0f}")
    
    with col3:
        # Calculate growth from last historical value
        if target in ["Revenus", "Co√ªts", "Profit"]:
            historical_data = get_target_data(csv_data, target)
            if historical_data:
                last_actual = historical_data[-1]
                growth = (forecasts[-1] / last_actual - 1) * 100
                st.metric("Croissance Projet√©e", f"{growth:+.1f}%")
    
    with col4:
        volatility = np.std(forecasts) / np.mean(forecasts) * 100 if np.mean(forecasts) != 0 else 0
        st.metric("Volatilit√© Pr√©vision", f"{volatility:.1f}%")
    
    with col5:
        model_performance = results.get('model_performance', {})
        if 'r2_score' in model_performance:
            accuracy = model_performance['r2_score'] * 100
            st.metric("Pr√©cision Mod√®le", f"{accuracy:.1f}%")
        else:
            st.metric("Mod√®le Utilis√©", results.get('best_model', 'ML'))
    
    # Data quality impact indicator
    if 'data_quality' in results:
        data_quality = results['data_quality']
        quality_score = data_quality.get('quality_score', 100)
        
        if quality_score < 80:
            st.warning(f"‚ö†Ô∏è **Impact Qualit√© Donn√©es** : Score {quality_score:.0f}/100 - Confiance {data_quality.get('confidence_adjustment', 'Mod√©r√©e')}")
            
            corrections = data_quality.get('corrections_applied', 0)
            if corrections > 0:
                st.info(f"‚ÑπÔ∏è {corrections} corrections automatiques appliqu√©es aux donn√©es d'entra√Ænement")
    
    # Enhanced forecast visualization with multiple scenarios
    historical_data = get_target_data(csv_data, target)
    if historical_data:
        historical_months = list(range(1, len(historical_data) + 1))
        forecast_months = list(range(len(historical_months) + 1, len(historical_months) + results.get('periods', len(forecasts)) + 1))
        
        # Create comprehensive visualization
        fig = make_subplots(rows=2, cols=1,
                           subplot_titles=[f'Pr√©visions {target} avec Sc√©narios', 'Intervalles de Confiance'],
                           vertical_spacing=0.1)
        
        # Historical data
        fig.add_trace(go.Scatter(
            x=historical_months,
            y=historical_data,
            mode='lines+markers',
            name='Donn√©es Historiques',
            line=dict(color='blue', width=3),
            marker=dict(size=6)
        ), row=1, col=1)
        
        # Base forecast
        fig.add_trace(go.Scatter(
            x=forecast_months,
            y=forecasts,
            mode='lines+markers',
            name='Pr√©vision ML',
            line=dict(color='red', width=3, dash='dash'),
            marker=dict(size=8)
        ), row=1, col=1)
        
        # Scenarios if available
        if 'scenarios' in results:
            scenarios = results['scenarios']
            
            fig.add_trace(go.Scatter(
                x=forecast_months,
                y=scenarios['optimistic'],
                mode='lines',
                name='Sc√©nario Optimiste',
                line=dict(color='green', width=2, dash='dot'),
                opacity=0.7
            ), row=1, col=1)
            
            fig.add_trace(go.Scatter(
                x=forecast_months,
                y=scenarios['pessimistic'],
                mode='lines',
                name='Sc√©nario Pessimiste',
                line=dict(color='orange', width=2, dash='dot'),
                opacity=0.7
            ), row=1, col=1)
        
        # Confidence intervals - main chart
        if 'upper_bounds' in results and 'lower_bounds' in results:
            fig.add_trace(go.Scatter(
                x=forecast_months + forecast_months[::-1],
                y=results['upper_bounds'] + results['lower_bounds'][::-1],
                fill='toself',
                fillcolor='rgba(255,0,0,0.2)',
                line=dict(color='rgba(255,255,255,0)'),
                name=f'IC {results.get("confidence_level", 95)}%',
                showlegend=True
            ), row=1, col=1)
            
            # Detailed confidence interval view
            fig.add_trace(go.Scatter(
                x=forecast_months,
                y=results['upper_bounds'],
                mode='lines',
                name='Borne Sup√©rieure',
                line=dict(color='red', width=1, dash='dash'),
                opacity=0.8
            ), row=2, col=1)
            
            fig.add_trace(go.Scatter(
                x=forecast_months,
                y=forecasts,
                mode='lines+markers',
                name='Pr√©vision Centrale',
                line=dict(color='red', width=2),
                marker=dict(size=6)
            ), row=2, col=1)
            
            fig.add_trace(go.Scatter(
                x=forecast_months,
                y=results['lower_bounds'],
                mode='lines',
                name='Borne Inf√©rieure',
                line=dict(color='red', width=1, dash='dash'),
                opacity=0.8
            ), row=2, col=1)
        
        fig.update_layout(
            title=f"Pr√©visions ML Avanc√©es : {target}",
            height=800,
            hovermode='x unified'
        )
        
        fig.update_xaxes(title_text="Mois", row=1, col=1)
        fig.update_yaxes(title_text=f"{target}", row=1, col=1)
        fig.update_xaxes(title_text="Mois", row=2, col=1)
        fig.update_yaxes(title_text=f"{target}", row=2, col=1)
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Enhanced insights and recommendations with business context
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Performance du Mod√®le ML")
        performance = results.get('model_performance', {})
        
        if performance:
            col_a, col_b = st.columns(2)
            
            with col_a:
                rmse = performance.get('rmse', 0)
                st.metric("RMSE", f"{rmse:.2f}")
                
                mae = performance.get('mae', 0)
                st.metric("MAE", f"{mae:.2f}")
            
            with col_b:
                r2_score = performance.get('r2_score', 0)
                st.metric("R¬≤ Score", f"{r2_score:.3f}")
                
                cv_score = performance.get('cv_score', 0)
                st.metric("CV Score", f"{cv_score:.3f}")
            
            # Model quality assessment
            if r2_score > 0.8:
                st.success("üü¢ **Mod√®le Tr√®s Performant** : Pr√©visions hautement fiables")
            elif r2_score > 0.6:
                st.info("üîµ **Mod√®le Performant** : Pr√©visions fiables")
            elif r2_score > 0.4:
                st.warning("üü° **Mod√®le Moyen** : Pr√©visions √† valider")
            else:
                st.error("üî¥ **Mod√®le Faible** : Pr√©visions peu fiables")
        
        # Feature importance if available
        if 'feature_importance' in results and results['feature_importance']:
            st.markdown("#### üéØ Importance des Variables")
            
            importance_data = results['feature_importance']
            features = list(importance_data.keys())
            importance_values = list(importance_data.values())
            
            fig_importance = go.Figure(data=[
                go.Bar(x=importance_values, y=features, orientation='h',
                      marker_color='lightblue')
            ])
            
            fig_importance.update_layout(
                title="Importance des Features ML",
                xaxis_title="Importance",
                height=300
            )
            
            st.plotly_chart(fig_importance, use_container_width=True)
        
        # Model information
        best_model = results.get('best_model', 'Ensemble ML')
        st.markdown(f"**Mod√®le S√©lectionn√©** : {best_model}")
        
        if 'model_scores' in results:
            model_scores = results['model_scores']
            if model_scores:
                st.markdown("**Comparaison Mod√®les** :")
                for model_name, scores in model_scores.items():
                    if isinstance(scores, dict) and 'mean_score' in scores:
                        st.write(f"‚Ä¢ {model_name}: {scores['mean_score']:.3f}")
    
    with col2:
        st.markdown("#### üí° Insights et Recommandations ML")
        
        # Generate insights based on forecast patterns
        insights = generate_forecast_insights(forecasts, historical_data, target)
        
        for insight in insights:
            if insight['type'] == 'positive':
                st.success(f"‚úÖ {insight['message']}")
            elif insight['type'] == 'warning':
                st.warning(f"‚ö†Ô∏è {insight['message']}")
            else:
                st.info(f"‚ÑπÔ∏è {insight['message']}")
        
        # Recommendations based on forecast results
        st.markdown("#### üéØ Recommandations Strat√©giques")
        
        if historical_data and len(forecasts) > 0:
            last_actual = historical_data[-1]
            first_forecast = forecasts[0]
            
            if first_forecast > last_actual * 1.1:
                st.success("üìà **Opportunit√© Croissance** : Pr√©parer scaling op√©rationnel")
            elif first_forecast < last_actual * 0.9:
                st.warning("üìâ **Alerte D√©clin** : Actions correctives recommand√©es")
            else:
                st.info("üìä **Stabilit√© Projet√©e** : Maintenir strat√©gie actuelle")
        
        # Business constraints feedback
        if results.get('business_constraints'):
            st.caption("üè¢ Pr√©visions ajust√©es selon contraintes business")
        
        if results.get('external_factors'):
            st.caption("üåç Facteurs externes pris en compte")
    
    # Detailed forecast table with scenarios
    st.markdown("#### üìã Tableau D√©taill√© des Pr√©visions")
    
    forecast_table_data = []
    
    for i, forecast in enumerate(forecasts):
        month = i + 1
        row_data = {
            'Mois': f"M+{month}",
            'Pr√©vision Base': f"{forecast:,.0f}",
        }
        
        # Add confidence intervals
        if 'upper_bounds' in results and 'lower_bounds' in results:
            row_data['Borne Inf.'] = f"{results['lower_bounds'][i]:,.0f}"
            row_data['Borne Sup.'] = f"{results['upper_bounds'][i]:,.0f}"
        
        # Add scenarios if available
        if 'scenarios' in results:
            scenarios = results['scenarios']
            row_data['Optimiste'] = f"{scenarios['optimistic'][i]:,.0f}"
            row_data['Pessimiste'] = f"{scenarios['pessimistic'][i]:,.0f}"
        
        forecast_table_data.append(row_data)
    
    # Display only first 12 months in main table, rest in expander
    main_table_data = forecast_table_data[:12]
    extended_table_data = forecast_table_data[12:] if len(forecast_table_data) > 12 else []
    
    df_forecast = pd.DataFrame(main_table_data)
    st.dataframe(df_forecast, use_container_width=True, hide_index=True)
    
    if extended_table_data:
        with st.expander(f"üìÖ Voir Pr√©visions √âtendues (Mois 13-{len(forecast_table_data)})", expanded=False):
            df_extended = pd.DataFrame(extended_table_data)
            st.dataframe(df_extended, use_container_width=True, hide_index=True)
    
    # Risk analysis section
    if 'scenarios' in results:
        st.markdown("#### ‚ö†Ô∏è Analyse de Risque des Pr√©visions")
        
        scenarios = results['scenarios']
        base_total = sum(scenarios['base'])
        optimistic_total = sum(scenarios['optimistic'])
        pessimistic_total = sum(scenarios['pessimistic'])
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            upside_potential = optimistic_total - base_total
            st.metric("Potentiel Haussier", f"{upside_potential:,.0f}")
            upside_pct = (upside_potential / base_total) * 100 if base_total > 0 else 0
            st.caption(f"{upside_pct:+.1f}%")
        
        with col2:
            downside_risk = base_total - pessimistic_total
            st.metric("Risque Baissier", f"{downside_risk:,.0f}")
            downside_pct = (downside_risk / base_total) * 100 if base_total > 0 else 0
            st.caption(f"{downside_pct:.1f}%")
        
        with col3:
            risk_ratio = upside_potential / downside_risk if downside_risk > 0 else float('inf')
            st.metric("Ratio Risque/Rendement", f"{risk_ratio:.2f}")
            
            if risk_ratio > 2:
                st.success("üü¢ Favorable")
            elif risk_ratio > 1:
                st.info("üîµ √âquilibr√©")
            else:
                st.warning("üü° Risqu√©")
    
    # Validation and confidence summary
    st.markdown("#### üîç Validation et Confiance")
    
    validation_summary = []
    
    # Data quality validation
    if 'data_quality' in results:
        data_quality = results['data_quality']
        quality_score = data_quality.get('quality_score', 100)
        
        validation_summary.append({
            'Crit√®re': 'Qualit√© Donn√©es Source',
            'Score': f"{quality_score:.0f}/100",
            'Statut': 'üü¢ Excellent' if quality_score >= 90 else 'üîµ Bon' if quality_score >= 70 else 'üü° Mod√©r√©'
        })
    
    # Model performance validation
    if performance:
        r2_score = performance.get('r2_score', 0)
        validation_summary.append({
            'Crit√®re': 'Performance Mod√®le (R¬≤)',
            'Score': f"{r2_score:.3f}",
            'Statut': 'üü¢ Excellent' if r2_score >= 0.8 else 'üîµ Bon' if r2_score >= 0.6 else 'üü° Mod√©r√©'
        })
    
    # Data volume validation
    if historical_data:
        data_points = len(historical_data)
        validation_summary.append({
            'Crit√®re': 'Volume Donn√©es',
            'Score': f"{data_points} points",
            'Statut': 'üü¢ Suffisant' if data_points >= 12 else 'üîµ Acceptable' if data_points >= 6 else 'üü° Limit√©'
        })
    
    if validation_summary:
        df_validation = pd.DataFrame(validation_summary)
        st.dataframe(df_validation, use_container_width=True, hide_index=True)
    
    # Export options
    st.markdown("#### üì• Options d'Export")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìä Exporter Donn√©es CSV", use_container_width=True):
            csv_export = df_forecast.to_csv(index=False)
            st.download_button(
                label="üíæ T√©l√©charger CSV",
                data=csv_export,
                file_name=f"predictions_{target}_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    with col2:
        if st.button("üìà G√©n√©rer Rapport", use_container_width=True):
            st.info("üîÑ Fonction g√©n√©ration rapport en d√©veloppement")
    
    with col3:
        if st.button("üîÑ Nouvelle Pr√©vision", use_container_width=True):
            if 'enhanced_ml_results' in st.session_state:
                del st.session_state.enhanced_ml_results
            st.rerun()

def generate_forecast_insights(forecasts, historical_data, target):
    """Generate insights based on forecast patterns"""
    insights = []
    
    try:
        if not forecasts or len(forecasts) == 0:
            return insights
        
        # Trend analysis
        if len(forecasts) > 1:
            trend_slope = (forecasts[-1] - forecasts[0]) / len(forecasts)
            
            if trend_slope > np.mean(forecasts) * 0.05:
                insights.append({
                    'type': 'positive',
                    'message': f"Tendance haussi√®re forte d√©tect√©e pour {target}"
                })
            elif trend_slope < -np.mean(forecasts) * 0.05:
                insights.append({
                    'type': 'warning',
                    'message': f"Tendance baissi√®re d√©tect√©e pour {target}"
                })
            else:
                insights.append({
                    'type': 'info',
                    'message': f"Tendance stable projet√©e pour {target}"
                })
        
        # Volatility analysis
        if len(forecasts) > 2:
            forecast_volatility = np.std(forecasts) / np.mean(forecasts)
            
            if forecast_volatility < 0.1:
                insights.append({
                    'type': 'positive',
                    'message': "Pr√©visions tr√®s stables - Faible volatilit√© projet√©e"
                })
            elif forecast_volatility > 0.3:
                insights.append({
                    'type': 'warning',
                    'message': "Forte volatilit√© projet√©e - Surveillance renforc√©e recommand√©e"
                })
        
        # Comparison with historical data
        if historical_data and len(historical_data) > 0:
            historical_avg = np.mean(historical_data)
            forecast_avg = np.mean(forecasts)
            
            change_pct = ((forecast_avg - historical_avg) / historical_avg) * 100
            
            if change_pct > 20:
                insights.append({
                    'type': 'positive',
                    'message': f"Am√©lioration significative projet√©e (+{change_pct:.1f}% vs historique)"
                })
            elif change_pct < -20:
                insights.append({
                    'type': 'warning',
                    'message': f"D√©t√©rioration significative projet√©e ({change_pct:.1f}% vs historique)"
                })
    
    except Exception as e:
        insights.append({
            'type': 'info',
            'message': f"Analyse insights limit√©e: {str(e)}"
        })
    
    return insights

# ========== ENHANCED RISK MANAGEMENT ==========
def show_risk_management():
    """Gestion des risques avanc√©e avec simulation Monte Carlo et insights sectoriels - VERSION CORRIG√âE"""
    st.header("‚ö†Ô∏è Gestion des Risques Financiers Avanc√©e")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    
    if not csv_data:
        st.warning("üì§ **Aucune Donn√©e CSV Disponible**")
        st.info("La Gestion des Risques avanc√©e n√©cessite vos donn√©es CSV upload√©es pour une √©valuation pr√©cise avec validation.")
        
        if st.button("üì§ Importer Donn√©es CSV Maintenant", type="primary"):
            st.session_state['current_page'] = 'csv_import'
            st.rerun()
        return
    
    # Enhanced risk context with data quality
    quality_context = ""
    risk_confidence = "√âlev√©e"
    
    if 'validation_results' in st.session_state:
        validation_results = st.session_state.validation_results
        quality_score = validation_results.get('quality_score', 100)
        
        if quality_score >= 80:
            quality_context = f" (Analyse fiable - Score: {quality_score:.0f}/100 ‚úÖ)"
            risk_confidence = "Tr√®s √âlev√©e"
        elif quality_score >= 60:
            quality_context = f" (Fiabilit√© mod√©r√©e - Score: {quality_score:.0f}/100 ‚ö†Ô∏è)"
            risk_confidence = "Mod√©r√©e"
        else:
            quality_context = f" (Fiabilit√© limit√©e - Score: {quality_score:.0f}/100 üî¥)"
            risk_confidence = "Limit√©e"
            
        critical_issues = validation_results.get('critical_issues', 0)
        if critical_issues > 0:
            quality_context += f" - {critical_issues} incoh√©rence(s) critique(s)"
    
    st.success(f"üìä **Analyse des risques bas√©e sur vos donn√©es CSV{quality_context}**")
    
    # Initialize enhanced analytics
    analytics = AdvancedAnalytics()
    
    # Calculate enhanced risk metrics with validation
    revenue_volatility = float(csv_data.get('revenue_volatility', 0))
    profit_margin = float(csv_data.get('profit_margin', 0))
    revenue_growth = float(csv_data.get('revenue_growth', 0))
    current_ratio = float(csv_data.get('current_ratio', 1.5))
    debt_to_equity = float(csv_data.get('debt_to_equity', 0.4))
    
    # Enhanced risk score calculation with validation context
    risk_components = {}
    
    # Revenue risk (0-30 points)
    revenue_risk = 0
    if revenue_volatility > 0.4:
        revenue_risk = 30
    elif revenue_volatility > 0.3:
        revenue_risk = 25
    elif revenue_volatility > 0.2:
        revenue_risk = 15
    elif revenue_volatility > 0.1:
        revenue_risk = 8
    
    risk_components['Revenue Volatility'] = revenue_risk
    
    # Profitability risk (0-25 points)
    profitability_risk = 0
    if profit_margin < -10:
        profitability_risk = 25
    elif profit_margin < 0:
        profitability_risk = 20
    elif profit_margin < 5:
        profitability_risk = 15
    elif profit_margin < 10:
        profitability_risk = 8
    
    risk_components['Profitability'] = profitability_risk
    
    # Growth risk (0-20 points)
    growth_risk = 0
    if revenue_growth < -20:
        growth_risk = 20
    elif revenue_growth < -10:
        growth_risk = 15
    elif revenue_growth < 0:
        growth_risk = 10
    elif revenue_growth < 5:
        growth_risk = 5
    
    risk_components['Growth Trend'] = growth_risk
    
    # Liquidity risk (0-15 points)
    liquidity_risk = 0
    if current_ratio < 0.8:
        liquidity_risk = 15
    elif current_ratio < 1.0:
        liquidity_risk = 12
    elif current_ratio < 1.2:
        liquidity_risk = 8
    elif current_ratio < 1.5:
        liquidity_risk = 4
    
    risk_components['Liquidity'] = liquidity_risk
    
    # Leverage risk (0-10 points)
    leverage_risk = 0
    if debt_to_equity > 3:
        leverage_risk = 10
    elif debt_to_equity > 2:
        leverage_risk = 8
    elif debt_to_equity > 1:
        leverage_risk = 5
    elif debt_to_equity > 0.5:
        leverage_risk = 2
    
    risk_components['Leverage'] = leverage_risk
    
    # Data quality risk adjustment
    data_quality_penalty = 0
    if 'validation_results' in st.session_state:
        quality_score = st.session_state.validation_results.get('quality_score', 100)
        if quality_score < 70:
            data_quality_penalty = (100 - quality_score) * 0.1
    
    risk_components['Data Quality'] = data_quality_penalty
    
    # Calculate total risk score
    total_risk_score = sum(risk_components.values())
    total_risk_score = min(100, max(0, total_risk_score))
    
    # Enhanced risk dashboard
    st.subheader("üéØ Dashboard Risques Multidimensionnel")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # Enhanced risk gauge with validation context
        fig_gauge = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=total_risk_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': f"Score Risque Global<br><span style='font-size:0.8em;color:gray'>Confiance: {risk_confidence}</span>"},
            delta={'reference': 50, 'position': "bottom"},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkred"},
                'steps': [
                    {'range': [0, 25], 'color': "lightgreen"},
                    {'range': [25, 50], 'color': "yellow"},
                    {'range': [50, 75], 'color': "orange"},
                    {'range': [75, 100], 'color': "red"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 75
                }
            }
        ))
        
        fig_gauge.update_layout(height=350)
        st.plotly_chart(fig_gauge, use_container_width=True)
        
        # Risk level interpretation with validation
        if total_risk_score < 25:
            st.success("üü¢ **Risque Faible**")
            st.write("Position financi√®re solide")
        elif total_risk_score < 50:
            st.info("üîµ **Risque Mod√©r√©**")
            st.write("Surveillance r√©guli√®re recommand√©e")
        elif total_risk_score < 75:
            st.warning("üü° **Risque √âlev√©**")
            st.write("Actions pr√©ventives n√©cessaires")
        else:
            st.error("üî¥ **Risque Critique**")
            st.write("Intervention imm√©diate requise")
        
        # Add data quality context
        if data_quality_penalty > 0:
            st.caption(f"‚ö†Ô∏è Score ajust√© (+{data_quality_penalty:.1f}) pour qualit√© donn√©es")
    
    with col2:
        # Enhanced risk components breakdown
        st.markdown("#### üìä D√©composition des Risques")
        
        # Risk components chart
        fig_components = go.Figure(data=[
            go.Bar(
                x=list(risk_components.keys()),
                y=list(risk_components.values()),
                marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']
            )
        ])
        
        fig_components.update_layout(
            title="Contribution par Composante de Risque",
            xaxis_title="Composantes",
            yaxis_title="Points de Risque",
            height=300
        )
        
        st.plotly_chart(fig_components, use_container_width=True)
        
        # Risk factors table with enhanced details
        risk_factors_data = []
        
        for component, score in risk_components.items():
            if score > 0:
                if component == 'Revenue Volatility':
                    level = "Critique" if score >= 25 else "√âlev√©" if score >= 15 else "Mod√©r√©"
                    description = f"Volatilit√© CA: {revenue_volatility:.1%}"
                elif component == 'Profitability':
                    level = "Critique" if score >= 20 else "√âlev√©" if score >= 15 else "Mod√©r√©"
                    description = f"Marge: {profit_margin:.1f}%"
                elif component == 'Growth Trend':
                    level = "Critique" if score >= 15 else "√âlev√©" if score >= 10 else "Mod√©r√©"
                    description = f"Croissance: {revenue_growth:.1f}%"
                elif component == 'Liquidity':
                    level = "Critique" if score >= 12 else "√âlev√©" if score >= 8 else "Mod√©r√©"
                    description = f"Ratio liquidit√©: {current_ratio:.2f}"
                elif component == 'Leverage':
                    level = "Critique" if score >= 8 else "√âlev√©" if score >= 5 else "Mod√©r√©"
                    description = f"Dette/Capitaux: {debt_to_equity:.2f}"
                elif component == 'Data Quality':
                    level = "Attention"
                    description = f"Score qualit√©: {100-data_quality_penalty*10:.0f}/100"
                else:
                    level = "Moyen"
                    description = "Facteur de risque d√©tect√©"
                
                risk_factors_data.append({
                    'Facteur': component,
                    'Score': f"{score:.1f}",
                    'Niveau': level,
                    'D√©tail': description
                })
        
        if risk_factors_data:
            df_risk_factors = pd.DataFrame(risk_factors_data)
            st.dataframe(df_risk_factors, use_container_width=True, hide_index=True)
        else:
            st.success("‚úÖ Aucun facteur de risque significatif d√©tect√©")
    
    # Enhanced tabs with validation context
    tab1, tab2, tab3, tab4 = st.tabs(["üéØ Analyse Facteurs", "üé≤ Simulation Monte Carlo", "üí° Recommandations IA", "‚öïÔ∏è Risques Donn√©es"])
    
    with tab1:
        st.subheader("üîç Analyse D√©taill√©e des Facteurs de Risque")
        
        # Industry-specific risk analysis
        industry_manager = IndustryTemplateManager()
        detected_industry = industry_manager.detect_industry_from_csv(csv_data)
        
        st.info(f"üè≠ **Analyse sp√©cialis√©e pour industrie** : {industry_manager.templates[detected_industry]['name']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìà Risques Op√©rationnels")
            
            # Revenue analysis with industry context
            st.metric("Volatilit√© CA", f"{revenue_volatility:.1%}")
            if revenue_volatility > 0.3:
                st.error("üî¥ Volatilit√© excessive")
                if detected_industry == 'retail':
                    st.caption("üí° Normal pour retail saisonnier")
                else:
                    st.caption("‚ö†Ô∏è Instabilit√© pr√©occupante")
            elif revenue_volatility > 0.2:
                st.warning("üü° Volatilit√© mod√©r√©e")
            else:
                st.success("üü¢ CA stable")
            
            st.metric("Croissance CA", f"{revenue_growth:+.1f}%")
            if revenue_growth < -10:
                st.error("üî¥ D√©clin s√©v√®re")
            elif revenue_growth < 0:
                st.warning("üü° D√©clin")
            elif revenue_growth > 20:
                st.success("üü¢ Forte croissance")
                if detected_industry == 'saas':
                    st.caption("üí° Excellent pour SaaS")
            else:
                st.info("üîµ Croissance mod√©r√©e")
            
            # Profitability analysis
            st.metric("Marge B√©n√©ficiaire", f"{profit_margin:.1f}%")
            
            # Industry-specific margin analysis
            template = industry_manager.get_template(detected_industry)
            benchmark_margin = template['benchmarks'].get('profit_margin', 0.1) * 100
            
            if profit_margin < 0:
                st.error("üî¥ Entreprise d√©ficitaire")
            elif profit_margin < benchmark_margin * 0.5:
                st.error("üî¥ Marges tr√®s faibles")
            elif profit_margin < benchmark_margin:
                st.warning("üü° Marges sous benchmark")
            elif profit_margin > benchmark_margin * 1.5:
                st.success("üü¢ Marges excellentes")
            else:
                st.success("üü¢ Marges satisfaisantes")
            
            st.caption(f"Benchmark {detected_industry}: {benchmark_margin:.1f}%")
        
        with col2:
            st.markdown("#### üí∞ Risques Financiers")
            
            st.metric("Ratio de Liquidit√©", f"{current_ratio:.2f}")
            if current_ratio < 1.0:
                st.error("üî¥ Liquidit√© critique")
                st.write("‚Ä¢ Risque de d√©faut de paiement")
                st.write("‚Ä¢ Actions imm√©diates requises")
            elif current_ratio < 1.2:
                st.warning("üü° Liquidit√© tendue")
                st.write("‚Ä¢ Surveillance renforc√©e")
                st.write("‚Ä¢ Optimiser le BFR")
            else:
                st.success("üü¢ Liquidit√© saine")
            
            st.metric("Ratio d'Endettement", f"{debt_to_equity:.2f}")
            if debt_to_equity > 2:
                st.error("üî¥ Endettement excessif")
            elif debt_to_equity > 1:
                st.warning("üü° Endettement √©lev√©")
            else:
                st.success("üü¢ Endettement ma√Ætris√©")
            
            # Cash flow risk if available
            cash_flow = csv_data.get('cash_flow', 0)
            st.metric("Cash Flow Mensuel", f"{cash_flow:,.0f} DHS")
            
            if cash_flow < 0:
                st.error("üî¥ Cash flow n√©gatif")
                st.write("‚Ä¢ Risque de tr√©sorerie")
                st.write("‚Ä¢ Besoin financement urgent")
            elif cash_flow < csv_data.get('monthly_costs', 1) * 0.1:
                st.warning("üü° Cash flow faible")
            else:
                st.success("üü¢ Cash flow positif")
        
        # Sector-specific risks
        st.markdown(f"#### üè≠ Risques Sp√©cifiques {industry_manager.templates[detected_industry]['name']}")
        
        if detected_industry == 'saas':
            st.info("‚òÅÔ∏è **Risques SaaS Sp√©cifiques :**")
            st.write("‚Ä¢ **Churn Rate** : Risque de perte abonn√©s")
            st.write("‚Ä¢ **Acquisition Costs** : Co√ªt client vs LTV")
            st.write("‚Ä¢ **Scalabilit√©** : Capacit√© infrastructure")
            st.write("‚Ä¢ **Concurrence** : March√© tr√®s comp√©titif")
        
        elif detected_industry == 'retail':
            st.info("üõçÔ∏è **Risques Retail Sp√©cifiques :**")
            st.write("‚Ä¢ **Saisonnalit√©** : Variations importantes")
            st.write("‚Ä¢ **Stocks** : Risque obsolescence")
            st.write("‚Ä¢ **Concurrence** : Pression sur marges")
            st.write("‚Ä¢ **Supply Chain** : D√©pendance fournisseurs")
        
        elif detected_industry == 'technology':
            st.info("üíª **Risques Tech Sp√©cifiques :**")
            st.write("‚Ä¢ **Obsolescence** : √âvolution technologique")
            st.write("‚Ä¢ **Talent** : P√©nurie comp√©tences")
            st.write("‚Ä¢ **Cycles produits** : Investissement R&D")
            st.write("‚Ä¢ **R√©glementation** : √âvolutions juridiques")
        
        elif detected_industry == 'manufacturing':
            st.info("üè≠ **Risques Manufacturing Sp√©cifiques :**")
            st.write("‚Ä¢ **Capacit√©** : Sous-utilisation √©quipements")
            st.write("‚Ä¢ **Qualit√©** : D√©fauts et rappels")
            st.write("‚Ä¢ **Supply Chain** : Ruptures approvisionnement")
            st.write("‚Ä¢ **R√©glementation** : Normes environnementales")
    
    with tab2:
        st.subheader("üé≤ Simulation Monte Carlo des Risques")
        
        if st.button("üöÄ Lancer Simulation Risques", type="secondary"):
            with st.spinner("Ex√©cution simulation Monte Carlo des risques financiers..."):
                
                # Enhanced Monte Carlo simulation with validation context
                base_monthly_revenue = csv_data.get('monthly_revenue', 15000)
                base_monthly_costs = csv_data.get('monthly_costs', 12000)
                
                # Adjust volatility based on data quality
                simulation_volatility = revenue_volatility
                if 'validation_results' in st.session_state:
                    quality_score = st.session_state.validation_results.get('quality_score', 100)
                    if quality_score < 70:
                        simulation_volatility *= 1.3  # Increase uncertainty for poor data quality
                    elif quality_score > 90:
                        simulation_volatility *= 0.9  # Reduce uncertainty for high quality data
                
                mc_results = analytics.monte_carlo_simulation(
                    base_monthly_revenue, 
                    base_monthly_costs, 
                    volatility=simulation_volatility,
                    simulations=1000, 
                    periods=12
                )
                
                # Enhanced risk metrics from Monte Carlo
                profits = mc_results['net_profit']
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    var_5 = np.percentile(profits, 5)
                    st.metric("VaR 5%", f"{var_5:,.0f} DHS")
                    if var_5 < 0:
                        st.error("üî¥ Risque perte significatif")
                    else:
                        st.success("üü¢ Pire cas reste positif")
                
                with col2:
                    prob_loss = (profits < 0).mean() * 100
                    st.metric("Probabilit√© Perte", f"{prob_loss:.1f}%")
                    if prob_loss > 20:
                        st.error("üî¥ Risque √©lev√©")
                    elif prob_loss > 10:
                        st.warning("üü° Risque mod√©r√©")
                    else:
                        st.success("üü¢ Risque faible")
                
                with col3:
                    expected_profit = profits.mean()
                    st.metric("Profit Esp√©r√©", f"{expected_profit:,.0f} DHS")
                    if expected_profit > 0:
                        st.success("üü¢ Rentabilit√© attendue")
                    else:
                        st.error("üî¥ Perte attendue")
                
                with col4:
                    profit_volatility = profits.std()
                    st.metric("Volatilit√© Profit", f"{profit_volatility:,.0f} DHS")
                    cv = profit_volatility / abs(expected_profit) if expected_profit != 0 else float('inf')
                    if cv < 0.5:
                        st.success("üü¢ Pr√©visible")
                    elif cv < 1.0:
                        st.warning("üü° Variable")
                    else:
                        st.error("üî¥ Tr√®s volatile")
                
                # Enhanced risk distribution visualization
                fig = go.Figure()
                
                fig.add_trace(go.Histogram(
                    x=profits,
                    nbinsx=50,
                    name='Distribution Profits',
                    opacity=0.7,
                    marker_color='lightblue'
                ))
                
                # Add enhanced risk markers
                fig.add_vline(x=var_5, line_dash="dash", line_color="red", 
                             annotation_text="VaR 5%")
                fig.add_vline(x=0, line_dash="solid", line_color="black", 
                             annotation_text="Seuil Rentabilit√©")
                fig.add_vline(x=expected_profit, line_dash="dot", line_color="green", 
                             annotation_text="Profit Esp√©r√©")
                
                # Add percentile lines
                var_1 = np.percentile(profits, 1)
                percentile_95 = np.percentile(profits, 95)
                fig.add_vline(x=var_1, line_dash="dash", line_color="darkred", 
                             annotation_text="VaR 1%")
                fig.add_vline(x=percentile_95, line_dash="dash", line_color="darkgreen", 
                             annotation_text="95e Percentile")
                
                fig.update_layout(
                    title="Distribution des Profits Simul√©s (1000 sc√©narios)",
                    xaxis_title="Profit Annuel (DHS)",
                    yaxis_title="Fr√©quence",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Enhanced risk interpretation with industry context
                st.markdown("#### üéØ Interpr√©tation des Risques")
                
                if prob_loss > 30:
                    st.error("üî¥ **Risque Tr√®s √âlev√©** : Plus de 30% de chance de perte")
                    st.write("‚Ä¢ R√©vision strat√©gique urgente n√©cessaire")
                    st.write("‚Ä¢ Mise en place de mesures de protection")
                    st.write("‚Ä¢ Recherche de diversification")
                elif prob_loss > 15:
                    st.warning("üü° **Risque √âlev√©** : Probabilit√© significative de perte")
                    st.write("‚Ä¢ Surveillance √©troite recommand√©e")
                    st.write("‚Ä¢ Plans de contingence √† pr√©parer")
                    st.write("‚Ä¢ Am√©lioration de la r√©silience")
                elif prob_loss > 5:
                    st.info("üîµ **Risque Mod√©r√©** : Faible probabilit√© de perte")
                    st.write("‚Ä¢ Monitoring r√©gulier suffisant")
                    st.write("‚Ä¢ Maintenir les strat√©gies actuelles")
                else:
                    st.success("üü¢ **Risque Faible** : Tr√®s faible probabilit√© de perte")
                    st.write("‚Ä¢ Position financi√®re solide")
                    st.write("‚Ä¢ Opportunit√©s de croissance possibles")
                
                # Data quality impact on simulation
                if 'validation_results' in st.session_state:
                    quality_score = st.session_state.validation_results.get('quality_score', 100)
                    if quality_score < 80:
                        st.warning(f"‚ö†Ô∏è **Note** : Simulation bas√©e sur donn√©es qualit√© {quality_score:.0f}% - R√©sultats √† interpr√©ter avec prudence")
                        
                        if quality_score < 60:
                            st.error("üî¥ Recommandation : Am√©liorer la qualit√© des donn√©es avant prise de d√©cisions critiques")
    
    with tab3:
        st.subheader("üí° Recommandations IA pour Mitigation des Risques")
        
        # Generate enhanced recommendations with validation insights - FIX
        try:
            ratios = analytics.calculate_comprehensive_ratios(csv_data)
            validation_context = st.session_state.get('validation_results')
            
            enhanced_recommendations = analytics.generate_ai_recommendations(
                csv_data, ratios, 100 - total_risk_score, validation_context
            )
            
            if enhanced_recommendations:
                for i, rec in enumerate(enhanced_recommendations):
                    priority_color = "üî¥" if rec['priority'] == 'Critique' else "üü†" if rec['priority'] == '√âlev√©e' else "üü°"
                    
                    with st.expander(f"{priority_color} {rec['category']} - Priorit√© {rec['priority']}", expanded=i < 3):
                        col_a, col_b = st.columns([3, 1])
                        
                        with col_a:
                            st.markdown(f"**Recommandation :** {rec['recommendation']}")
                            
                            # Add enhanced implementation steps
                            st.markdown("**√âtapes d'Impl√©mentation :**")
                            if rec['category'] == 'Gestion de tr√©sorerie':
                                st.write("1. Audit complet des flux de tr√©sorerie")
                                st.write("2. Mise en place d'un tableau de bord quotidien")
                                st.write("3. N√©gociation avec clients et fournisseurs")
                                st.write("4. Recherche de solutions de financement")
                            elif rec['category'] == 'Am√©lioration de la liquidit√©':
                                st.write("1. Analyse d√©taill√©e du besoin en fonds de roulement")
                                st.write("2. Optimisation des stocks")
                                st.write("3. R√©vision des conditions de paiement")
                                st.write("4. Mise en place de lignes de cr√©dit")
                            elif rec['category'] == 'Am√©lioration de la rentabilit√©':
                                st.write("1. Analyse ABC des produits/services")
                                st.write("2. √âtude de march√© et pricing")
                                st.write("3. Plan d'optimisation des co√ªts")
                                st.write("4. Indicateurs de suivi mensuel")
                            else:
                                st.write("1. √âvaluation d√©taill√©e du probl√®me")
                                st.write("2. D√©veloppement d'un plan d'action")
                                st.write("3. Mise en ≈ìuvre progressive")
                                st.write("4. Suivi et ajustements")
                        
                        with col_b:
                            st.metric("Impact", rec['impact'])
                            st.metric("D√©lai", rec['timeframe'])
                            
                            if isinstance(rec.get('estimated_benefit'), (int, float)):
                                st.metric("B√©n√©fice Est.", f"{rec['estimated_benefit']:,.0f} DHS")
                            else:
                                st.metric("B√©n√©fice", rec.get('estimated_benefit', 'Qualitatif'))
                            
                            # Risk reduction potential
                            if rec['priority'] == 'Critique':
                                st.metric("R√©duction Risque", "15-25%")
                            elif rec['priority'] == '√âlev√©e':
                                st.metric("R√©duction Risque", "8-15%")
                            else:
                                st.metric("R√©duction Risque", "3-8%")
            
        except Exception as e:
            st.warning(f"Erreur g√©n√©ration recommandations avanc√©es: {str(e)}")
            
            # Fallback recommendations
            st.markdown("#### üí° Recommandations G√©n√©rales")
            
            if total_risk_score > 75:
                st.error("üö® **Actions Critiques Imm√©diates**")
                st.write("‚Ä¢ R√©vision compl√®te de la strat√©gie financi√®re")
                st.write("‚Ä¢ Mise en place d'un plan de redressement")
                st.write("‚Ä¢ Recherche de financements d'urgence")
                st.write("‚Ä¢ Audit externe des processus")
            elif total_risk_score > 50:
                st.warning("‚ö†Ô∏è **Actions Pr√©ventives Urgentes**")
                st.write("‚Ä¢ Am√©lioration du monitoring financier")
                st.write("‚Ä¢ Diversification des sources de revenus")
                st.write("‚Ä¢ Optimisation de la structure de co√ªts")
                st.write("‚Ä¢ Renforcement de la position de tr√©sorerie")
            elif total_risk_score > 25:
                st.info("üîµ **Optimisation Continue**")
                st.write("‚Ä¢ Maintenir la surveillance des indicateurs")
                st.write("‚Ä¢ Am√©liorer l'efficacit√© op√©rationnelle")
                st.write("‚Ä¢ Pr√©parer des plans de contingence")
            else:
                st.success("‚úÖ **Position Saine - Croissance Possible**")
                st.write("‚Ä¢ Maintenir les bonnes pratiques actuelles")
                st.write("‚Ä¢ Explorer des opportunit√©s de croissance")
                st.write("‚Ä¢ Renforcer les avantages concurrentiels")
        
        # Industry-specific risk mitigation
        st.markdown(f"### üè≠ Mitigation Sp√©cifique {industry_manager.templates[detected_industry]['name']}")
        
        template = industry_manager.get_template(detected_industry)
        
        if detected_industry == 'saas':
            st.info("‚òÅÔ∏è **Strat√©gies SaaS Sp√©cifiques :**")
            st.write("‚Ä¢ **Churn Rate** : D√©velopper des programmes de fid√©lisation")
            st.write("‚Ä¢ **Acquisition Costs** : Optimiser les canaux marketing")
            st.write("‚Ä¢ **Scalabilit√©** : Pr√©parer l'infrastructure pour la croissance")
            st.write("‚Ä¢ **R√©currence** : Diversifier les sources de revenus r√©currents")
            
        elif detected_industry == 'retail':
            st.info("üõçÔ∏è **Strat√©gies Retail Sp√©cifiques :**")
            st.write("‚Ä¢ **Saisonnalit√©** : D√©velopper des strat√©gies anti-cycliques")
            st.write("‚Ä¢ **Stocks** : Optimiser la rotation et r√©duire l'obsolescence")
            st.write("‚Ä¢ **Concurrence** : Diff√©renciation et fid√©lisation client")
            st.write("‚Ä¢ **Supply Chain** : Diversifier les fournisseurs")
            
        elif detected_industry == 'technology':
            st.info("üíª **Strat√©gies Tech Sp√©cifiques :**")
            st.write("‚Ä¢ **Obsolescence** : Investissement continu en R&D")
            st.write("‚Ä¢ **Talent** : Strat√©gies de r√©tention des comp√©tences cl√©s")
            st.write("‚Ä¢ **Cycles produits** : Diversification du portefeuille")
            st.write("‚Ä¢ **Cybers√©curit√©** : Renforcement de la s√©curit√© informatique")
            
        elif detected_industry == 'manufacturing':
            st.info("üè≠ **Strat√©gies Manufacturing Sp√©cifiques :**")
            st.write("‚Ä¢ **Capacit√©** : Optimisation de l'utilisation des √©quipements")
            st.write("‚Ä¢ **Qualit√©** : Syst√®mes de contr√¥le qualit√© renforc√©s")
            st.write("‚Ä¢ **Supply Chain** : S√©curisation des approvisionnements")
            st.write("‚Ä¢ **R√©glementation** : Veille r√©glementaire continue")
    
    with tab4:
        st.subheader("‚öïÔ∏è Risques Li√©s √† la Qualit√© des Donn√©es")
        
        if 'validation_results' in st.session_state:
            validation_results = st.session_state.validation_results
            
            # Comprehensive data quality risk assessment
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                quality_score = validation_results.get('quality_score', 100)
                st.metric("Score Qualit√©", f"{quality_score:.0f}/100")
                
                if quality_score >= 90:
                    st.success("üü¢ Risque donn√©es minimal")
                elif quality_score >= 70:
                    st.info("üîµ Risque donn√©es mod√©r√©")
                elif quality_score >= 50:
                    st.warning("üü° Risque donn√©es √©lev√©")
                else:
                    st.error("üî¥ Risque donn√©es critique")
            
            with col2:
                total_issues = validation_results.get('total_issues', 0)
                st.metric("Anomalies Totales", total_issues)
                
                if total_issues == 0:
                    st.success("‚úÖ Aucune")
                elif total_issues <= 3:
                    st.info("üîµ Limit√©es")
                else:
                    st.warning("üü° Nombreuses")
            
            with col3:
                critical_issues = validation_results.get('critical_issues', 0)
                st.metric("Anomalies Critiques", critical_issues)
                
                if critical_issues == 0:
                    st.success("‚úÖ Aucune")
                else:
                    st.error(f"üî¥ {critical_issues}")
            
            with col4:
                corrections_count = len(st.session_state.get('correction_log', []))
                st.metric("Corrections Auto", corrections_count)
                
                if corrections_count == 0:
                    st.success("‚úÖ Aucune")
                else:
                    st.info(f"üîß {corrections_count}")
            
            # Detailed data risk analysis
            st.markdown("#### üîç Impact des Risques Donn√©es sur l'Analyse Financi√®re")
            
            data_risk_level = "Faible"
            if quality_score < 50:
                data_risk_level = "Critique"
            elif quality_score < 70:
                data_risk_level = "√âlev√©"
            elif quality_score < 90:
                data_risk_level = "Mod√©r√©"
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**Niveau de Risque Donn√©es : {data_risk_level}**")
                
                if data_risk_level == "Critique":
                    st.error("üî¥ **Impact Majeur** : Fiabilit√© des analyses compromise")
                    st.markdown("**Cons√©quences :**")
                    st.write("‚Ä¢ D√©cisions bas√©es sur des donn√©es erron√©es")
                    st.write("‚Ä¢ Sous-estimation ou surestimation des risques")
                    st.write("‚Ä¢ Pr√©visions potentiellement fausses")
                    st.write("‚Ä¢ Perte de confiance des parties prenantes")
                    
                elif data_risk_level == "√âlev√©":
                    st.warning("üü° **Impact Significatif** : Pr√©cision des analyses r√©duite")
                    st.markdown("**Cons√©quences :**")
                    st.write("‚Ä¢ Marge d'erreur importante dans les analyses")
                    st.write("‚Ä¢ Besoin de validation externe")
                    st.write("‚Ä¢ Recommandations √† prendre avec pr√©caution")
                    
                elif data_risk_level == "Mod√©r√©":
                    st.info("üîµ **Impact Limit√©** : Analyses globalement fiables")
                    st.markdown("**Cons√©quences :**")
                    st.write("‚Ä¢ L√©ger impact sur la pr√©cision")
                    st.write("‚Ä¢ Corrections automatiques appliqu√©es")
                    st.write("‚Ä¢ Monitoring continu recommand√©")
                    
                else:
                    st.success("üü¢ **Impact Minimal** : Haute fiabilit√© des analyses")
                    st.write("‚Ä¢ Donn√©es de haute qualit√©")
                    st.write("‚Ä¢ Analyses hautement fiables")
                    st.write("‚Ä¢ D√©cisions s√ªres possibles")
            
            with col2:
                st.markdown("#### üìã Plan d'Am√©lioration Qualit√© Donn√©es")
                
                if critical_issues > 0:
                    st.error("üö® **Action Imm√©diate Requise**")
                    st.markdown("**√âtapes Prioritaires :**")
                    st.write("1. **Audit complet** des processus de saisie")
                    st.write("2. **Correction manuelle** des incoh√©rences critiques")
                    st.write("3. **Formation √©quipe** sur les standards qualit√©")
                    st.write("4. **Mise en place contr√¥les** automatiques")
                
                if quality_score < 80:
                    st.warning("‚ö†Ô∏è **Am√©lioration N√©cessaire**")
                    st.markdown("**Actions Recommand√©es :**")
                    st.write("‚Ä¢ R√©vision des proc√©dures de collecte")
                    st.write("‚Ä¢ Validation crois√©e des donn√©es")
                    st.write("‚Ä¢ Formation sur les bonnes pratiques")
                    st.write("‚Ä¢ Automatisation des contr√¥les")
                
                if quality_score >= 80:
                    st.success("‚úÖ **Maintenir Excellence**")
                    st.markdown("**Actions de Maintien :**")
                    st.write("‚Ä¢ Monitoring continu de la qualit√©")
                    st.write("‚Ä¢ R√©visions p√©riodiques des processus")
                    st.write("‚Ä¢ Formation continue des √©quipes")
                    st.write("‚Ä¢ Am√©lioration continue des outils")
                
                # Specific data quality recommendations
                st.markdown("#### üéØ Recommandations Sp√©cifiques")
                
                issues = validation_results.get('issues', [])
                for issue in issues[:3]:  # Show top 3 issues
                    if issue.get('severity') in ['√âlev√©e', 'Critique']:
                        issue_type = issue.get('type', 'Anomalie')
                        st.write(f"‚Ä¢ **{issue_type}** : {issue.get('message', 'Correction n√©cessaire')}")
        else:
            st.info("Donn√©es de validation non disponibles. R√©importez vos donn√©es CSV pour une analyse compl√®te des risques li√©s aux donn√©es.")

# ========== ENHANCED INDUSTRY TEMPLATES ==========
def show_industry_templates():
    """Enhanced industry templates with comprehensive validation and benchmarking"""
    st.header("üè≠ Analyse Financi√®re Sp√©cialis√©e par Industrie")
    
    # Get CSV financial data
    csv_data = CSVDataManager.get_csv_financial_data()
    template_manager = IndustryTemplateManager()
    
    if csv_data:
        # Display data quality context
        quality_context = ""
        if 'validation_results' in st.session_state:
            quality_score = st.session_state.validation_results.get('quality_score', 100)
            if quality_score >= 80:
                quality_context = f" (Donn√©es valid√©es - Score: {quality_score:.0f}/100 ‚úÖ)"
            else:
                quality_context = f" (Qualit√© mod√©r√©e - Score: {quality_score:.0f}/100 ‚ö†Ô∏è)"
        
        st.success(f"üìä **Analyse sectorielle aliment√©e par vos donn√©es CSV{quality_context}**")
        
        # Enhanced auto-detection with validation
        detected_industry = template_manager.detect_industry_from_csv(csv_data)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            confidence_score = 85  # Base confidence
            
            # Adjust confidence based on data quality and quantity
            if 'validation_results' in st.session_state:
                quality_score = st.session_state.validation_results.get('quality_score', 100)
                confidence_score = confidence_score * (quality_score / 100)
            
            data_points = len(csv_data.get('revenue_data', []))
            if data_points < 12:
                confidence_score *= 0.8
            elif data_points >= 24:
                confidence_score *= 1.1
            
            confidence_score = min(100, confidence_score)
            
            st.info(f"ü§ñ **Industrie Auto-d√©tect√©e** : {template_manager.templates[detected_industry]['name']} "
                   f"(Confiance: {confidence_score:.0f}%) bas√©e sur vos patterns financiers")
        
        with col2:
            # Allow manual industry selection
            industry_options = list(template_manager.templates.keys())
            selected_industry = st.selectbox(
                "Modifier l'Industrie",
                industry_options,
                index=industry_options.index(detected_industry),
                format_func=lambda x: f"{template_manager.templates[x]['icon']} {template_manager.templates[x]['name']}"
            )
        
        # Industry-specific data validation
        validation_issues = template_manager.validate_industry_data(csv_data, selected_industry)
        if validation_issues:
            with st.expander("‚ö†Ô∏è Validation Sp√©cifique √† l'Industrie", expanded=False):
                for issue in validation_issues:
                    st.warning(f"‚ö†Ô∏è {issue}")
    else:
        st.warning("üì§ **Aucune Donn√©e CSV Disponible**")
        st.info("Les Templates Industrie fonctionnent mieux avec vos donn√©es financi√®res upload√©es pour un benchmarking pr√©cis.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì§ Importer Donn√©es CSV Maintenant", type="primary", use_container_width=True):
                st.session_state['current_page'] = 'csv_import'
                st.rerun()
        
        with col2:
            # Allow exploration without CSV data
            industry_options = list(template_manager.templates.keys())
            selected_industry = st.selectbox(
                "Explorer une Industrie",
                industry_options,
                index=2,  # Default to technology
                format_func=lambda x: f"{template_manager.templates[x]['icon']} {template_manager.templates[x]['name']}"
            )
    
    # Get selected template with enhanced data
    template = template_manager.get_template(selected_industry)
    
    # Enhanced industry overview tabs
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìä Profil Industrie", 
        "üìà Benchmarking Avanc√©", 
        "üéØ Votre Performance", 
        "üí° Insights Sectoriels",
        "üìã Plan d'Action",
        "üîç Analyse Comparative"
    ])
    
    with tab1:
        st.subheader(f"{template['icon']} Profil Complet {template['name']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üìà Mod√®le de Revenus")
            st.code(template['revenue_model'], language="text")
            
            st.markdown("### üéØ M√©triques Cl√©s de Performance")
            for i, metric in enumerate(template['key_metrics']):
                icon = "üìä" if i % 3 == 0 else "üìà" if i % 3 == 1 else "üí∞"
                st.write(f"{icon} **{metric}**")
            
            st.markdown("### üìä Ratios Financiers Typiques")
            ratios_df = pd.DataFrame([
                {"Ratio": k.replace('_', ' ').title(), "Valeur": f"{v:.1%}" if isinstance(v, float) and v < 1 else f"{v:.2f}"}
                for k, v in template['typical_ratios'].items()
            ])
            st.dataframe(ratios_df, use_container_width=True, hide_index=True)
        
        with col2:
            st.markdown("### üíº Structure de Co√ªts Typique")
            
            # Enhanced cost structure visualization
            cost_structure = template['cost_structure']
            
            fig = go.Figure(data=[go.Pie(
                labels=[k.replace('_', ' ').title() for k in cost_structure.keys()],
                values=list(cost_structure.values()),
                hole=0.4,
                marker=dict(
                    colors=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FF99CC', '#99CCFF'],
                    line=dict(color='#FFFFFF', width=2)
                ),
                textinfo='label+percent',
                textposition='outside'
            )])
            
            fig.update_layout(
                title=f"Structure Co√ªts {template['name']}",
                annotations=[dict(text=template['icon'], x=0.5, y=0.5, font_size=30, showarrow=False)],
                height=450,
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("### üîÑ Cycle de Conversion")
            wc_metrics = template['working_capital']
            
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("DSO*", f"{wc_metrics['days_sales_outstanding']:.0f}j", help="Days Sales Outstanding")
            with col_b:
                st.metric("DIO*", f"{wc_metrics['days_inventory_outstanding']:.0f}j", help="Days Inventory Outstanding")
            with col_c:
                st.metric("DPO*", f"{wc_metrics['days_payable_outstanding']:.0f}j", help="Days Payable Outstanding")
            
            cycle_conversion = (wc_metrics['days_sales_outstanding'] + 
                              wc_metrics['days_inventory_outstanding'] - 
                              wc_metrics['days_payable_outstanding'])
            
            st.metric("**Cycle de Conversion**", f"{cycle_conversion:.0f} jours")
            
            if cycle_conversion < 30:
                st.success("üü¢ Cycle tr√®s efficace")
            elif cycle_conversion < 60:
                st.info("üîµ Cycle efficace")
            elif cycle_conversion < 90:
                st.warning("üü° Cycle √† optimiser")
            else:
                st.error("üî¥ Cycle inefficace")
    
    with tab2:
        st.subheader("üìà Benchmarking Avanc√© vs Industrie")
        
        if csv_data:
            # Enhanced benchmarking with validation context
            comparison = template_manager.benchmark_against_industry(csv_data, selected_industry)
            
            # Create comprehensive comparison visualization
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=['Croissance CA', 'Marge B√©n√©ficiaire', 'Performance vs Benchmarks', 'Radar Comparatif'],
                specs=[[{"type": "bar"}, {"type": "bar"}], 
                       [{"type": "bar"}, {"type": "scatterpolar"}]]
            )
            
            # Revenue growth comparison
            if 'revenue_growth' in comparison:
                rg_data = comparison['revenue_growth']
                fig.add_trace(go.Bar(
                    name='Votre Entreprise',
                    x=['Croissance CA'],
                    y=[rg_data['company_value'] * 100],
                    marker_color='lightblue',
                    text=[f"{rg_data['company_value']*100:.1f}%"],
                    textposition='outside'
                ), row=1, col=1)
                
                fig.add_trace(go.Bar(
                    name='Benchmark Industrie',
                    x=['Croissance CA'],
                    y=[rg_data['industry_benchmark'] * 100],
                    marker_color='lightgreen',
                    text=[f"{rg_data['industry_benchmark']*100:.1f}%"],
                    textposition='outside',
                    showlegend=False
                ), row=1, col=1)
            
            # Profit margin comparison
            if 'profit_margin' in comparison:
                pm_data = comparison['profit_margin']
                fig.add_trace(go.Bar(
                    name='Votre Entreprise',
                    x=['Marge Profit'],
                    y=[pm_data['company_value'] * 100],
                    marker_color='lightblue',
                    text=[f"{pm_data['company_value']*100:.1f}%"],
                    textposition='outside',
                    showlegend=False
                ), row=1, col=2)
                
                fig.add_trace(go.Bar(
                    name='Benchmark Industrie',
                    x=['Marge Profit'],
                    y=[pm_data['industry_benchmark'] * 100],
                    marker_color='lightgreen',
                    text=[f"{pm_data['industry_benchmark']*100:.1f}%"],
                    textposition='outside',
                    showlegend=False
                ), row=1, col=2)
            
            # Performance summary
            performance_metrics = []
            company_values = []
            benchmark_values = []
            
            for metric_name, metric_data in comparison.items():
                if isinstance(metric_data, dict) and 'performance' in metric_data:
                    performance_metrics.append(metric_name.replace('_', ' ').title())
                    company_values.append(metric_data['company_value'])
                    benchmark_values.append(metric_data['industry_benchmark'])
            
            if performance_metrics:
                fig.add_trace(go.Bar(
                    name='Votre Performance',
                    x=performance_metrics,
                    y=company_values,
                    marker_color='lightblue'
                ), row=2, col=1)
                
                fig.add_trace(go.Bar(
                    name='Benchmark',
                    x=performance_metrics,
                    y=benchmark_values,
                    marker_color='lightgreen'
                ), row=2, col=1)
                
                # Radar chart for comprehensive view
                fig.add_trace(go.Scatterpolar(
                    r=company_values,
                    theta=performance_metrics,
                    fill='toself',
                    name='Votre Entreprise',
                    line_color='blue'
                ), row=2, col=2)
                
                fig.add_trace(go.Scatterpolar(
                    r=benchmark_values,
                    theta=performance_metrics,
                    fill='toself',
                    name='Benchmark Industrie',
                    line_color='green',
                    opacity=0.6
                ), row=2, col=2)
            
            fig.update_layout(
                height=800,
                title_text=f"Benchmarking Complet vs {template['name']}",
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Detailed comparison table
            st.markdown("#### üìã Tableau Comparatif D√©taill√©")
            
            comparison_table = []
            for metric_name, metric_data in comparison.items():
                if isinstance(metric_data, dict):
                    comparison_table.append({
                        'M√©trique': metric_name.replace('_', ' ').title(),
                        'Votre Valeur': f"{metric_data.get('company_value', 0):.2%}" if metric_data.get('company_value', 0) < 1 else f"{metric_data.get('company_value', 0):.2f}",
                        'Benchmark': f"{metric_data.get('industry_benchmark', 0):.2%}" if metric_data.get('industry_benchmark', 0) < 1 else f"{metric_data.get('industry_benchmark', 0):.2f}",
                        '√âcart': f"{metric_data.get('percentage_difference', 0):+.1f}%",
                        'Performance': metric_data.get('performance', 'N/A'),
                        'Statut Validation': metric_data.get('validation_status', 'Normal')
                    })
            
            if comparison_table:
                df_comparison = pd.DataFrame(comparison_table)
                st.dataframe(df_comparison, use_container_width=True, hide_index=True)
            
            # Add data quality note
            if 'validation_results' in st.session_state:
                quality_score = st.session_state.validation_results.get('quality_score', 100)
                if quality_score < 80:
                    st.caption(f"‚ö†Ô∏è Benchmarking bas√© sur donn√©es qualit√© {quality_score:.0f}% - Validation externe recommand√©e")
        
        else:
            st.info("üìä Uploadez vos donn√©es CSV pour voir le benchmarking personnalis√© vs votre industrie")
            
            # Show generic benchmarks
            st.markdown("#### üìä Benchmarks G√©n√©riques de l'Industrie")
            
            benchmark_data = []
            for metric, value in template['benchmarks'].items():
                benchmark_data.append({
                    'M√©trique': metric.replace('_', ' ').title(),
                    'Benchmark': f"{value:.1%}" if isinstance(value, float) and value < 1 else f"{value:.2f}",
                    'Description': get_metric_description(metric, selected_industry)
                })
            
            df_benchmarks = pd.DataFrame(benchmark_data)
            st.dataframe(df_benchmarks, use_container_width=True, hide_index=True)
    
    with tab3:
        st.subheader("üéØ Analyse de Votre Performance")
        
        if csv_data:
            # Enhanced performance analysis with industry context
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üìä M√©triques Financi√®res Actuelles")
                
                monthly_revenue = csv_data.get('monthly_revenue', 0)
                annual_revenue = monthly_revenue * 12
                st.metric("CA Annuel", f"{annual_revenue:,.0f} DHS")
                
                profit_margin = csv_data.get('profit_margin', 0)
                st.metric("Marge B√©n√©ficiaire", f"{profit_margin:.1f}%")
                
                revenue_growth = csv_data.get('revenue_growth', 0)
                st.metric("Croissance CA", f"{revenue_growth:+.1f}%")
                
                revenue_volatility = csv_data.get('revenue_volatility', 0)
                st.metric("Volatilit√© CA", f"{revenue_volatility:.1%}")
                
                # Calculate industry-specific KPIs
                st.markdown("#### üéØ KPIs Sp√©cifiques √† Votre Industrie")
                
                if selected_industry == 'saas':
                    # SaaS-specific metrics
                    mrr = monthly_revenue
                    arr = mrr * 12
                    st.metric("MRR", f"{mrr:,.0f} DHS")
                    st.metric("ARR", f"{arr:,.0f} DHS")
                    
                    # Estimated metrics
                    estimated_customers = max(100, int(mrr / 50))  # Assuming avg 50 DHS per customer
                    st.metric("Clients Estim√©s", f"{estimated_customers:,}")
                    
                    estimated_churn = min(0.15, max(0.03, revenue_volatility))
                    st.metric("Churn Estim√©", f"{estimated_churn:.1%}")
                
                elif selected_industry == 'retail':
                    # Retail-specific metrics
                    inventory_turnover = template['benchmarks'].get('inventory_turns', 6)
                    st.metric("Rotation Stocks", f"{inventory_turnover:.1f}x")
                    
                    # Seasonal factor analysis
                    if len(csv_data.get('revenue_data', [])) >= 12:
                        revenue_data = csv_data['revenue_data']
                        seasonal_cv = calculate_seasonality(revenue_data)
                        st.metric("Facteur Saisonnier", f"{seasonal_cv:.1%}")
                
                elif selected_industry == 'technology':
                    # Tech-specific metrics
                    estimated_rd_ratio = min(0.3, max(0.05, profit_margin * 0.02))
                    st.metric("R&D/CA Estim√©", f"{estimated_rd_ratio:.1%}")
                    
                    if annual_revenue > 0:
                        revenue_per_employee = annual_revenue / max(10, annual_revenue // 200000)  # Estimate employees
                        st.metric("CA/Employ√©", f"{revenue_per_employee:,.0f} DHS")
                
                elif selected_industry == 'manufacturing':
                    # Manufacturing-specific metrics
                    asset_turnover = template['typical_ratios'].get('asset_turnover', 1.2)
                    st.metric("Rotation Actifs", f"{asset_turnover:.2f}")
                    
                    estimated_capacity = max(0.6, min(0.95, (revenue_growth + 100) / 120))
                    st.metric("Utilisation Capacit√©", f"{estimated_capacity:.1%}")
            
            with col2:
                st.markdown("#### üìà Position Relative dans l'Industrie")
                
                # Industry position analysis
                position_score = 0
                position_factors = []
                
                # Revenue growth position
                benchmark_growth = template['benchmarks'].get('revenue_growth', 0.1) * 100
                if revenue_growth >= benchmark_growth * 1.2:
                    position_score += 25
                    position_factors.append("üü¢ Croissance excellente")
                elif revenue_growth >= benchmark_growth:
                    position_score += 15
                    position_factors.append("üîµ Croissance au-dessus benchmark")
                elif revenue_growth >= benchmark_growth * 0.8:
                    position_score += 10
                    position_factors.append("üü° Croissance correcte")
                else:
                    position_factors.append("üî¥ Croissance sous benchmark")
                
                # Profitability position
                benchmark_margin = template['benchmarks'].get('profit_margin', 0.1) * 100
                if profit_margin >= benchmark_margin * 1.2:
                    position_score += 25
                    position_factors.append("üü¢ Rentabilit√© excellente")
                elif profit_margin >= benchmark_margin:
                    position_score += 15
                    position_factors.append("üîµ Rentabilit√© au-dessus benchmark")
                elif profit_margin >= benchmark_margin * 0.8:
                    position_score += 10
                    position_factors.append("üü° Rentabilit√© correcte")
                else:
                    position_factors.append("üî¥ Rentabilit√© sous benchmark")
                
                # Stability position
                if revenue_volatility <= 0.1:
                    position_score += 20
                    position_factors.append("üü¢ Revenus tr√®s stables")
                elif revenue_volatility <= 0.2:
                    position_score += 15
                    position_factors.append("üîµ Revenus stables")
                elif revenue_volatility <= 0.3:
                    position_score += 10
                    position_factors.append("üü° Revenus mod√©r√©ment volatils")
                else:
                    position_factors.append("üî¥ Revenus tr√®s volatils")
                
                # Add data quality adjustment
                if 'validation_results' in st.session_state:
                    quality_score = st.session_state.validation_results.get('quality_score', 100)
                    position_score = position_score * (quality_score / 100)
                
                position_score = min(100, position_score)
                
                # Display position score
                st.metric("Score Position Industrie", f"{position_score:.0f}/100")
                
                if position_score >= 80:
                    st.success("üèÜ **Leader dans votre secteur**")
                elif position_score >= 60:
                    st.info("üìà **Performance au-dessus de la moyenne**")
                elif position_score >= 40:
                    st.warning("üìä **Performance moyenne**")
                else:
                    st.error("üìâ **Performance en dessous de la moyenne**")
                
                # Display position factors
                st.markdown("**Facteurs de Position :**")
                for factor in position_factors:
                    st.write(f"‚Ä¢ {factor}")
                
                # Industry ranking visualization
                fig_ranking = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=position_score,
                    domain={'x': [0, 1], 'y': [0, 1]},
                    title={'text': f"Position {template['name']}"},
                    gauge={
                        'axis': {'range': [None, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 25], 'color': "red"},
                            {'range': [25, 50], 'color': "orange"},
                            {'range': [50, 75], 'color': "yellow"},
                            {'range': [75, 100], 'color': "green"}
                        ]
                    }
                ))
                
                fig_ranking.update_layout(height=300)
                st.plotly_chart(fig_ranking, use_container_width=True)
        
        else:
            st.info("üìä Uploadez vos donn√©es CSV pour voir une analyse personnalis√©e de votre performance vs l'industrie")
    
    with tab4:
        st.subheader("üí° Insights Sectoriels Avanc√©s")
        
        if csv_data:
            # Generate industry-specific insights with validation
            insights, recommendations = template_manager.generate_industry_insights(csv_data, selected_industry)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ‚úÖ Insights Valid√©s")
                if insights:
                    for insight in insights:
                        st.success(f"‚úÖ {insight}")
                        
                        # Add confidence level based on data quality
                        if 'validation_results' in st.session_state:
                            quality_score = st.session_state.validation_results.get('quality_score', 100)
                            if quality_score >= 90:
                                st.caption("üîπ Confiance tr√®s √©lev√©e")
                            elif quality_score >= 70:
                                st.caption("üî∏ Confiance √©lev√©e")
                            else:
                                st.caption("üî∏ Confiance mod√©r√©e - Validation externe recommand√©e")
                else:
                    st.info("Performance dans les normes sectorielles. Maintenir la strat√©gie actuelle.")
            
            with col2:
                st.markdown("#### üéØ Recommandations Sectorielles")
                if recommendations:
                    for rec in recommendations:
                        if "‚ö†Ô∏è" in rec or "üî¥" in rec:
                            st.error(rec)
                        elif "üí°" in rec or "üéØ" in rec:
                            st.warning(rec)
                        else:
                            st.info(rec)
                else:
                    st.success("‚úÖ Aucune recommandation sp√©cifique identifi√©e")
            
            # Advanced sector-specific analysis
            st.markdown("#### üîç Analyse Sectorielle Avanc√©e")
            
            # Seasonal pattern analysis
            if len(csv_data.get('revenue_data', [])) >= 12:
                revenue_data = csv_data['revenue_data']
                seasonal_factors = template.get('seasonal_factors', [1.0] * 12)
                
                fig_seasonal = go.Figure()
                
                # Historical seasonality
                monthly_avg = []
                for month in range(12):
                    month_values = [revenue_data[i] for i in range(month, len(revenue_data), 12)]
                    if month_values:
                        monthly_avg.append(np.mean(month_values))
                    else:
                        monthly_avg.append(0)
                
                if len(monthly_avg) == 12:
                    months_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                                   'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
                    
                    # Normalize for comparison
                    if np.mean(monthly_avg) > 0:
                        normalized_actual = [m / np.mean(monthly_avg) for m in monthly_avg]
                    else:
                        normalized_actual = [1.0] * 12
                    
                    fig_seasonal.add_trace(go.Scatter(
                        x=months_names,
                        y=normalized_actual,
                        mode='lines+markers',
                        name='Votre Saisonnalit√©',
                        line=dict(color='blue', width=3)
                    ))
                    
                    fig_seasonal.add_trace(go.Scatter(
                        x=months_names,
                        y=seasonal_factors,
                        mode='lines+markers',
                        name=f'Saisonnalit√© Typique {template["name"]}',
                        line=dict(color='red', width=2, dash='dash')
                    ))
                    
                    fig_seasonal.update_layout(
                        title="Analyse Saisonnalit√© vs Benchmark Industrie",
                        yaxis_title="Facteur Saisonnier (Base 1.0)",
                        height=400
                    )
                    
                    st.plotly_chart(fig_seasonal, use_container_width=True)
                    
                    # Seasonality insights
                    actual_seasonality = np.std(normalized_actual)
                    expected_seasonality = np.std(seasonal_factors)
                    
                    if actual_seasonality > expected_seasonality * 1.5:
                        st.warning("‚ö†Ô∏è **Saisonnalit√© plus marqu√©e** que la moyenne du secteur")
                    elif actual_seasonality < expected_seasonality * 0.5:
                        st.success("‚úÖ **Revenus moins saisonniers** que la moyenne du secteur")
                    else:
                        st.info("üìä **Patterns saisonniers** align√©s avec le secteur")
        
        else:
            # Show generic industry insights
            st.markdown("#### üè≠ Insights G√©n√©riques du Secteur")
            
            if selected_industry == 'saas':
                st.info("‚òÅÔ∏è **Facteurs Cl√©s de Succ√®s SaaS :**")
                st.write("‚Ä¢ **R√©currence** : Focus sur les revenus pr√©visibles")
                st.write("‚Ä¢ **Churn Management** : R√©duction taux attrition")
                st.write("‚Ä¢ **Unit Economics** : LTV > 3x CAC")
                st.write("‚Ä¢ **Scalabilit√©** : Croissance sans augmentation proportionnelle des co√ªts")
                
            elif selected_industry == 'retail':
                st.info("üõçÔ∏è **Facteurs Cl√©s de Succ√®s Retail :**")
                st.write("‚Ä¢ **Rotation Stock** : Optimisation des niveaux d'inventaire")
                st.write("‚Ä¢ **Saisonnalit√©** : Planification selon les cycles")
                st.write("‚Ä¢ **Exp√©rience Client** : Diff√©renciation par le service")
                st.write("‚Ä¢ **Supply Chain** : Efficacit√© logistique")
                
            elif selected_industry == 'technology':
                st.info("üíª **Facteurs Cl√©s de Succ√®s Tech :**")
                st.write("‚Ä¢ **Innovation** : Investissement continu en R&D")
                st.write("‚Ä¢ **Time-to-Market** : Rapidit√© de d√©veloppement")
                st.write("‚Ä¢ **Talent** : Attraction et r√©tention des comp√©tences")
                st.write("‚Ä¢ **√âcosyst√®me** : Partenariats strat√©giques")
                
            elif selected_industry == 'manufacturing':
                st.info("üè≠ **Facteurs Cl√©s de Succ√®s Manufacturing :**")
                st.write("‚Ä¢ **Efficacit√© Op√©rationnelle** : Optimisation des processus")
                st.write("‚Ä¢ **Qualit√©** : Syst√®mes de contr√¥le rigoureux")
                st.write("‚Ä¢ **Capacit√©** : Utilisation optimale des √©quipements")
                st.write("‚Ä¢ **Supply Chain** : S√©curisation des approvisionnements")
    
    with tab5:
        st.subheader("üìã Plan d'Action Personnalis√©")
        
        if csv_data:
            # Generate comprehensive action plan
            st.markdown("#### üéØ Plan d'Action Bas√© sur Votre Performance")
            
            # Analyze current position
            revenue_growth = csv_data.get('revenue_growth', 0)
            profit_margin = csv_data.get('profit_margin', 0)
            revenue_volatility = csv_data.get('revenue_volatility', 0)
            
            benchmark_growth = template['benchmarks'].get('revenue_growth', 0.1) * 100
            benchmark_margin = template['benchmarks'].get('profit_margin', 0.1) * 100
            
            # Priority actions based on gaps
            priority_actions = []
            
            # Growth gap analysis
            growth_gap = revenue_growth - benchmark_growth
            if growth_gap < -10:
                priority_actions.append({
                    'priority': 'Critique',
                    'area': 'Croissance',
                    'action': 'Plan de relance croissance urgent',
                    'timeframe': '0-3 mois',
                    'description': 'Analyser causes du retard de croissance et impl√©menter actions correctives',
                    'kpis': ['Taux de croissance mensuel', 'Part de march√©', 'Acquisition clients']
                })
            elif growth_gap < -5:
                priority_actions.append({
                    'priority': '√âlev√©e',
                    'area': 'Croissance',
                    'action': 'Acc√©l√©ration strat√©gie croissance',
                    'timeframe': '3-6 mois',
                    'description': 'Identifier leviers croissance suppl√©mentaires',
                    'kpis': ['Pipeline commercial', 'Conversion leads', 'R√©tention clients']
                })
            
            # Profitability gap analysis
            margin_gap = profit_margin - benchmark_margin
            if margin_gap < -5:
                priority_actions.append({
                    'priority': 'Critique',
                    'area': 'Rentabilit√©',
                    'action': 'Optimisation urgente des marges',
                    'timeframe': '0-3 mois',
                    'description': 'R√©vision compl√®te structure co√ªts et pricing',
                    'kpis': ['Marge brute', 'Co√ªt par unit√©', 'Pricing power']
                })
            elif margin_gap < -2:
                priority_actions.append({
                    'priority': '√âlev√©e',
                    'area': 'Rentabilit√©',
                    'action': 'Am√©lioration continue rentabilit√©',
                    'timeframe': '3-6 mois',
                    'description': 'Optimisation op√©rationnelle et efficacit√©',
                    'kpis': ['Productivit√©', 'Automation ratio', 'Cost per acquisition']
                })
            
            # Volatility analysis
            if revenue_volatility > 0.3:
                priority_actions.append({
                    'priority': 'Moyenne',
                    'area': 'Stabilit√©',
                    'action': 'R√©duction volatilit√© revenus',
                    'timeframe': '6-12 mois',
                    'description': 'Diversification sources revenus et am√©lioration pr√©dictibilit√©',
                    'kpis': ['Coefficient variation CA', 'R√©currence revenus', 'Diversification clients']
                })
            
            # Industry-specific actions
            if selected_industry == 'saas':
                priority_actions.append({
                    'priority': 'Moyenne',
                    'area': 'SaaS Optimization',
                    'action': 'Optimisation m√©triques SaaS',
                    'timeframe': '3-9 mois',
                    'description': 'Focus sur MRR, r√©duction churn et am√©lioration LTV/CAC',
                    'kpis': ['MRR Growth', 'Churn Rate', 'LTV/CAC Ratio', 'Net Revenue Retention']
                })
            elif selected_industry == 'retail':
                priority_actions.append({
                    'priority': 'Moyenne',
                    'area': 'Retail Excellence',
                    'action': 'Optimisation op√©rations retail',
                    'timeframe': '3-9 mois',
                    'description': 'Am√©lioration rotation stocks et gestion saisonnalit√©',
                    'kpis': ['Inventory Turnover', 'Same-Store Sales', 'Gross Margin', 'Customer Traffic']
                })
            elif selected_industry == 'technology':
                priority_actions.append({
                    'priority': 'Moyenne',
                    'area': 'Tech Innovation',
                    'action': 'Renforcement capacit√©s innovation',
                    'timeframe': '6-12 mois',
                    'description': 'Investissement R&D et acc√©l√©ration time-to-market',
                    'kpis': ['R&D/Revenue Ratio', 'Time-to-Market', 'Innovation Pipeline', 'Patent Portfolio']
                })
            elif selected_industry == 'manufacturing':
                priority_actions.append({
                    'priority': 'Moyenne',
                    'area': 'Manufacturing Excellence',
                    'action': 'Optimisation efficacit√© op√©rationnelle',
                    'timeframe': '6-12 mois',
                    'description': 'Am√©lioration OEE et r√©duction waste',
                    'kpis': ['OEE', 'Capacity Utilization', 'Quality Rate', 'Lead Time']
                })
            
            # Sort by priority
            priority_order = {'Critique': 0, '√âlev√©e': 1, 'Moyenne': 2}
            priority_actions.sort(key=lambda x: priority_order.get(x['priority'], 3))
            
            # Display action plan
            for i, action in enumerate(priority_actions):
                priority_color = "üî¥" if action['priority'] == 'Critique' else "üü†" if action['priority'] == '√âlev√©e' else "üü°"
                
                with st.expander(f"{priority_color} Action {i+1}: {action['action']} - Priorit√© {action['priority']}", 
                               expanded=i < 2):
                    
                    col_a, col_b = st.columns([2, 1])
                    
                    with col_a:
                        st.markdown(f"**Domaine** : {action['area']}")
                        st.markdown(f"**Description** : {action['description']}")
                        
                        st.markdown("**√âtapes D√©taill√©es :**")
                        if action['area'] == 'Croissance':
                            st.write("1. Audit des canaux d'acquisition actuels")
                            st.write("2. Analyse de la concurrence et positionnement")
                            st.write("3. D√©veloppement de nouveaux segments/produits")
                            st.write("4. Mise en place de programmes de fid√©lisation")
                            st.write("5. Suivi quotidien des m√©triques de croissance")
                        elif action['area'] == 'Rentabilit√©':
                            st.write("1. Analyse d√©taill√©e de la structure de co√ªts")
                            st.write("2. Benchmark des prix vs concurrence")
                            st.write("3. Optimisation des processus op√©rationnels")
                            st.write("4. N√©gociation avec fournisseurs cl√©s")
                            st.write("5. Mise en place de contr√¥les de gestion renforc√©s")
                        elif action['area'] == 'Stabilit√©':
                            st.write("1. Diversification du portefeuille clients")
                            st.write("2. D√©veloppement de revenus r√©currents")
                            st.write("3. Am√©lioration de la pr√©dictibilit√© des ventes")
                            st.write("4. Mise en place de syst√®mes d'alerte pr√©coce")
                        else:
                            st.write("1. √âvaluation de la situation actuelle")
                            st.write("2. D√©finition d'objectifs sp√©cifiques")
                            st.write("3. Mise en place d'initiatives cibl√©es")
                            st.write("4. Monitoring et ajustements continus")
                    
                    with col_b:
                        st.metric("D√©lai", action['timeframe'])
                        st.metric("Priorit√©", action['priority'])
                        
                        st.markdown("**KPIs √† Suivre :**")
                        for kpi in action['kpis']:
                            st.write(f"‚Ä¢ {kpi}")
            
            # Add data quality improvement action if needed
            if 'validation_results' in st.session_state:
                quality_score = st.session_state.validation_results.get('quality_score', 100)
                if quality_score < 80:
                    with st.expander("üîß Action Transversale: Am√©lioration Qualit√© Donn√©es - Priorit√© √âlev√©e", expanded=False):
                        st.markdown("**Domaine** : Gouvernance des Donn√©es")
                        st.markdown(f"**Score Actuel** : {quality_score:.0f}/100")
                        
                        st.markdown("**Actions Imm√©diates :**")
                        st.write("1. Audit complet des processus de collecte des donn√©es")
                        st.write("2. Formation des √©quipes sur les standards qualit√©")
                        st.write("3. Mise en place de contr√¥les automatiques")
                        st.write("4. Validation crois√©e des donn√©es critiques")
                        st.write("5. Mise en place d'un monitoring continu")
                        
                        st.metric("Impact Attendu", "Am√©lioration fiabilit√© analyses +25%")
        
        else:
            st.info("üìä Uploadez vos donn√©es CSV pour g√©n√©rer un plan d'action personnalis√© bas√© sur votre performance actuelle")
            
            # Show generic best practices for the industry
            st.markdown(f"#### üè≠ Meilleures Pratiques {template['name']}")
            
            if selected_industry == 'saas':
                st.write("‚Ä¢ **Optimisation MRR** : Focus sur la croissance des revenus r√©currents")
                st.write("‚Ä¢ **R√©duction Churn** : Programmes de fid√©lisation et support client")
                st.write("‚Ä¢ **Scaling Efficient** : Am√©lioration des ratios de productivit√©")
                st.write("‚Ä¢ **Product-Market Fit** : Validation continue de l'ad√©quation produit-march√©")
                
            elif selected_industry == 'retail':
                st.write("‚Ä¢ **Inventory Management** : Optimisation rotation et r√©duction stocks morts")
                st.write("‚Ä¢ **Customer Experience** : Am√©lioration parcours client omnicanal")
                st.write("‚Ä¢ **Seasonal Planning** : Anticipation et pr√©paration des pics d'activit√©")
                st.write("‚Ä¢ **Supply Chain Efficiency** : Optimisation cha√Æne logistique")
                
            elif selected_industry == 'technology':
                st.write("‚Ä¢ **R&D Investment** : Maintenir l'avantage concurrentiel par l'innovation")
                st.write("‚Ä¢ **Talent Acquisition** : Attraction et r√©tention des meilleurs profils")
                st.write("‚Ä¢ **Agile Development** : Acc√©l√©ration time-to-market")
                st.write("‚Ä¢ **Partnership Ecosystem** : D√©veloppement d'√©cosyst√®mes partenaires")
                
            elif selected_industry == 'manufacturing':
                st.write("‚Ä¢ **Operational Excellence** : Optimisation continue des processus")
                st.write("‚Ä¢ **Quality Systems** : Mise en place de syst√®mes qualit√© robustes")
                st.write("‚Ä¢ **Capacity Optimization** : Maximisation utilisation des √©quipements")
                st.write("‚Ä¢ **Supply Chain Resilience** : S√©curisation des approvisionnements")
    
    with tab6:
        st.subheader("üîç Analyse Comparative Multi-Sectorielle")
        
        if csv_data:
            st.markdown("### üìä Comparaison Multi-Sectorielle")
            
            # Compare against all industry benchmarks
            all_comparisons = {}
            for industry_key in template_manager.templates.keys():
                comparison = template_manager.benchmark_against_industry(csv_data, industry_key)
                all_comparisons[industry_key] = comparison
            
            # Create comprehensive comparison visualization
            industries = list(all_comparisons.keys())
            revenue_growth_company = []
            revenue_growth_benchmarks = []
            profit_margin_company = []
            profit_margin_benchmarks = []
            
            for industry in industries:
                comp = all_comparisons[industry]
                if 'revenue_growth' in comp:
                    revenue_growth_company.append(comp['revenue_growth']['company_value'] * 100)
                    revenue_growth_benchmarks.append(comp['revenue_growth']['industry_benchmark'] * 100)
                else:
                    revenue_growth_company.append(0)
                    revenue_growth_benchmarks.append(0)
                
                if 'profit_margin' in comp:
                    profit_margin_company.append(comp['profit_margin']['company_value'] * 100)
                    profit_margin_benchmarks.append(comp['profit_margin']['industry_benchmark'] * 100)
                else:
                    profit_margin_company.append(0)
                    profit_margin_benchmarks.append(0)
            
            # Multi-industry comparison chart
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=['Croissance CA vs Industries', 'Marge B√©n√©ficiaire vs Industries'],
                specs=[[{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Revenue growth comparison
            fig.add_trace(
                go.Bar(name='Votre Entreprise', x=[template_manager.templates[ind]['name'] for ind in industries], 
                      y=revenue_growth_company, marker_color='lightblue'),
                row=1, col=1
            )
            fig.add_trace(
                go.Bar(name='Benchmark Industrie', x=[template_manager.templates[ind]['name'] for ind in industries], 
                      y=revenue_growth_benchmarks, marker_color='lightgreen'),
                row=1, col=1
            )
            
            # Profit margin comparison
            fig.add_trace(
                go.Bar(name='Votre Entreprise', x=[template_manager.templates[ind]['name'] for ind in industries], 
                      y=profit_margin_company, marker_color='lightblue', showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Bar(name='Benchmark Industrie', x=[template_manager.templates[ind]['name'] for ind in industries], 
                      y=profit_margin_benchmarks, marker_color='lightgreen', showlegend=False),
                row=1, col=2
            )
            
            fig.update_layout(
                height=500,
                title_text="Comparaison Performance Multi-Sectorielle",
                barmode='group'
            )
            fig.update_yaxes(title_text="Croissance CA (%)", row=1, col=1)
            fig.update_yaxes(title_text="Marge B√©n√©ficiaire (%)", row=1, col=2)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Best fit industry analysis
            st.markdown("### üéØ Analyse Meilleur Fit Sectoriel")
            
            fit_scores = {}
            for industry in industries:
                score = 0
                comp = all_comparisons[industry]
                
                # Score based on how close company performance is to industry benchmarks
                if 'revenue_growth' in comp:
                    growth_diff = abs(comp['revenue_growth']['percentage_difference'])
                    score += max(0, 100 - growth_diff)
                
                if 'profit_margin' in comp:
                    margin_diff = abs(comp['profit_margin']['percentage_difference'])
                    score += max(0, 100 - margin_diff)
                
                fit_scores[industry] = score / 2  # Average of the two metrics
            
            # Sort industries by fit score
            sorted_industries = sorted(fit_scores.items(), key=lambda x: x[1], reverse=True)
            
            st.markdown("#### üìà Classement Fit Sectoriel")
            
            for i, (industry, score) in enumerate(sorted_industries):
                template_info = template_manager.templates[industry]
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.write(f"**{i+1}. {template_info['icon']} {template_info['name']}**")
                
                with col2:
                    st.metric("Score Fit", f"{score:.0f}/100")
                
                with col3:
                    if i == 0:
                        st.success("ü•á Meilleur Fit")
                    elif i == 1:
                        st.info("ü•à Bon Fit")
                    elif i == 2:
                        st.warning("ü•â Fit Mod√©r√©")
                    else:
                        st.caption("Fit Limit√©")
                
                # Show why this industry fits (or doesn't)
                if score > 80:
                    st.success(f"‚úÖ Votre profil financier correspond tr√®s bien au secteur {template_info['name']}")
                elif score > 60:
                    st.info(f"‚ÑπÔ∏è Votre profil s'aligne bien avec le secteur {template_info['name']}")
                elif score > 40:
                    st.warning(f"‚ö†Ô∏è Alignement partiel avec le secteur {template_info['name']}")
                else:
                    st.error(f"‚ùå Profil peu compatible avec le secteur {template_info['name']}")
                
                st.markdown("---")
            
            # Strategic recommendations based on best fit
            best_fit_industry = sorted_industries[0][0]
            if best_fit_industry != selected_industry:
                st.markdown("### üí° Recommandations Strat√©giques")
                st.info(f"üéØ **Insight Sectoriel** : Vos m√©triques s'alignent mieux avec {template_manager.templates[best_fit_industry]['name']} "
                       f"que votre classification actuelle ({template_manager.templates[selected_industry]['name']})")
                
                st.markdown("**Options Strat√©giques :**")
                st.write(f"‚Ä¢ **Pivoter** vers le mod√®le {template_manager.templates[best_fit_industry]['name']}")
                st.write(f"‚Ä¢ **Hybrider** en adoptant les meilleures pratiques de {template_manager.templates[best_fit_industry]['name']}")
                st.write(f"‚Ä¢ **Optimiser** votre mod√®le actuel pour mieux s'aligner avec {template['name']}")
            
            # Competitive positioning analysis
            st.markdown("### üéØ Positionnement Concurrentiel")
            
            # Create positioning matrix
            fig = go.Figure()
            
            for industry in industries:
                comp = all_comparisons[industry]
                x_val = comp.get('revenue_growth', {}).get('company_value', 0) * 100
                y_val = comp.get('profit_margin', {}).get('company_value', 0) * 100
                
                template_info = template_manager.templates[industry]
                
                # Add industry benchmark point
                x_benchmark = comp.get('revenue_growth', {}).get('industry_benchmark', 0) * 100
                y_benchmark = comp.get('profit_margin', {}).get('industry_benchmark', 0) * 100
                
                fig.add_trace(go.Scatter(
                    x=[x_benchmark],
                    y=[y_benchmark],
                    mode='markers',
                    name=f"Benchmark {template_info['name']}",
                    marker=dict(size=15, symbol='diamond'),
                    text=[template_info['icon']],
                    textposition="middle center"
                ))
            
            # Add company position
            company_growth = csv_data.get('revenue_growth', 0)
            company_margin = csv_data.get('profit_margin', 0)
            
            fig.add_trace(go.Scatter(
                x=[company_growth],
                y=[company_margin],
                mode='markers',
                name='Votre Entreprise',
                marker=dict(size=20, color='red', symbol='star'),
                text=['VOUS'],
                textposition="middle center"
            ))
            
            fig.update_layout(
                title='Matrice Positionnement: Croissance vs Rentabilit√©',
                xaxis_title='Croissance CA (%)',
                yaxis_title='Marge B√©n√©ficiaire (%)',
                height=500
            )
            
            # Add quadrant lines
            fig.add_hline(y=company_margin, line_dash="dot", line_color="gray", opacity=0.5)
            fig.add_vline(x=company_growth, line_dash="dot", line_color="gray", opacity=0.5)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Quadrant analysis
            st.markdown("#### üéØ Analyse Positionnement")
            
            if company_growth > 10 and company_margin > 15:
                st.success("üåü **Position Excellente** : Forte croissance et haute rentabilit√© - Vous dominez votre march√©")
            elif company_growth > 10 and company_margin > 5:
                st.info("üìà **Croissance Forte** : Excellent momentum, optimiser la rentabilit√©")
            elif company_growth > 0 and company_margin > 15:
                st.info("üí∞ **Rentabilit√© Forte** : Excellentes marges, acc√©l√©rer la croissance")
            elif company_growth > 0 and company_margin > 5:
                st.warning("‚öñÔ∏è **Position √âquilibr√©e** : Performance correcte, identifier leviers d'am√©lioration")
            else:
                st.error("üîÑ **Repositionnement N√©cessaire** : Am√©lioration urgente requise sur croissance et/ou rentabilit√©")
            
        else:
            st.info("üìä L'analyse comparative multi-sectorielle sera disponible avec vos donn√©es CSV")
            
            # Show general comparison framework
            st.markdown("### üîç Framework Analyse Comparative")
            
            comparison_framework = {
                'Dimension': ['Croissance CA', 'Rentabilit√©', 'Efficacit√©', 'Stabilit√©', 'Innovation'],
                'SaaS': ['Tr√®s √âlev√©e', '√âlev√©e', 'Variable', '√âlev√©e', 'Critique'],
                'Retail': ['Mod√©r√©e', 'Faible', '√âlev√©e', 'Variable', 'Mod√©r√©e'],
                'Technology': ['√âlev√©e', '√âlev√©e', 'Mod√©r√©e', 'Mod√©r√©e', 'Tr√®s √âlev√©e'],
                'Manufacturing': ['Mod√©r√©e', 'Mod√©r√©e', 'Tr√®s √âlev√©e', '√âlev√©e', 'Faible']
            }
            
            comparison_df = pd.DataFrame(comparison_framework)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            st.markdown("**L√©gende :**")
            st.write("‚Ä¢ **Tr√®s √âlev√©e** : Performance sup√©rieure attendue")
            st.write("‚Ä¢ **√âlev√©e** : Performance au-dessus de la moyenne")
            st.write("‚Ä¢ **Mod√©r√©e** : Performance moyenne")
            st.write("‚Ä¢ **Faible** : Performance en dessous de la moyenne")
            st.write("‚Ä¢ **Variable** : D√©pend fortement du contexte")

# ========== HELPER FUNCTIONS ==========
def calculate_seasonality(data):
    """Calculate seasonality coefficient for retail analysis"""
    if len(data) < 12:
        return 0
    
    try:
        monthly_means = []
        for month in range(12):
            month_data = [data[i] for i in range(month, len(data), 12)]
            if month_data:
                monthly_means.append(np.mean(month_data))
        
        if len(monthly_means) == 12:
            return np.std(monthly_means) / np.mean(monthly_means)
        else:
            return 0
    except:
        return 0

def get_metric_description(metric, industry):
    """Get description for a metric based on industry context"""
    descriptions = {
        'revenue_growth': f"Taux de croissance annuel du chiffre d'affaires typique pour {industry}",
        'profit_margin': f"Marge b√©n√©ficiaire nette moyenne observ√©e dans {industry}",
        'inventory_turns': f"Nombre de rotations d'inventaire par an dans {industry}",
        'churn_rate': f"Taux d'attrition mensuel des clients dans {industry}",
        'ltv_cac_ratio': f"Ratio valeur vie client sur co√ªt d'acquisition dans {industry}",
        'gross_margin': f"Marge brute typique pour {industry}",
        'capacity_utilization': f"Taux d'utilisation des capacit√©s de production dans {industry}",
        'oee': f"Overall Equipment Effectiveness dans {industry}",
        'defect_rate': f"Taux de d√©fauts typique dans {industry}"
    }
    
    return descriptions.get(metric, f"M√©trique de r√©f√©rence pour {industry}")

# ========== MAIN APPLICATION ==========
def main():
    """Enhanced main function with comprehensive validation and industry analysis"""
    
    init_session_state()
    
    # Enhanced header with data quality status
    st.sidebar.markdown(f"""
    ### üè¢ Suite Analyse Financi√®re Avanc√©e
    **Bienvenue dans la Plateforme Analytics Professionnelle**
    
    *Validation Avanc√©e ‚Ä¢ Insights IA ‚Ä¢ Benchmarking Sectoriel*
    
    ---
    """)
    
    # Enhanced CSV import indicator with quality metrics
    if CSVDataManager.has_csv_data():
        st.sidebar.success("üìä Donn√©es CSV Charg√©es")
        
        # Show enhanced metrics with validation context
        csv_data = CSVDataManager.get_csv_financial_data()
        if csv_data:
            monthly_revenue = csv_data.get('monthly_revenue', 0)
            profit_margin = csv_data.get('profit_margin', 0)
            st.sidebar.metric("CA Mensuel", f"{monthly_revenue:,.0f} DHS")
            st.sidebar.metric("Marge B√©n√©ficiaire", f"{profit_margin:.1f}%")
            
            # Data quality indicator
            if 'validation_results' in st.session_state:
                quality_score = st.session_state.validation_results.get('quality_score', 100)
                if quality_score >= 90:
                    st.sidebar.success(f"üü¢ Qualit√©: {quality_score:.0f}/100")
                elif quality_score >= 70:
                    st.sidebar.info(f"üîµ Qualit√©: {quality_score:.0f}/100")
                else:
                    st.sidebar.warning(f"üü° Qualit√©: {quality_score:.0f}/100")
                
                critical_issues = st.session_state.validation_results.get('critical_issues', 0)
                if critical_issues > 0:
                    st.sidebar.error(f"üî¥ {critical_issues} probl√®me(s) critique(s)")
                
                corrections_applied = len(st.session_state.get('correction_log', []))
                if corrections_applied > 0:
                    st.sidebar.info(f"üîß {corrections_applied} correction(s) auto")
    else:
        st.sidebar.warning("üì§ Aucune Donn√©e CSV")
        st.sidebar.caption("Uploadez des donn√©es pour analyse compl√®te")
    
    # Enhanced navigation menu with new capabilities
    menu_items = {
        "üì§ Import CSV Intelligent": "csv_import",
        "üëî Dashboard Ex√©cutif": "executive_dashboard",
        "üß† Analytics IA Avanc√©s": "advanced_analytics", 
        "üéØ Planification Sc√©narios": "scenario_planning",
        "ü§ñ Pr√©visions ML Optimis√©es": "ml_forecasting",
        "‚ö†Ô∏è Gestion Risques Avanc√©e": "risk_management",
        "üè≠ Templates Sectoriels": "industry_templates"
    }
    
    # Handle enhanced page navigation
    if 'current_page' in st.session_state:
        page_key = st.session_state['current_page']
        choice = None
        for menu_text, menu_key in menu_items.items():
            if menu_key == page_key:
                choice = menu_text
                break
        if not choice:
            choice = list(menu_items.keys())[0]
        del st.session_state['current_page']
    else:
        choice = st.sidebar.selectbox(
            "üß≠ Navigation",
            list(menu_items.keys()),
            index=0
        )
    
    # Route to appropriate enhanced page
    page_key = menu_items[choice]
    
    if page_key == "csv_import":
        show_enhanced_csv_import()
    elif page_key == "executive_dashboard":
        show_executive_dashboard()
    elif page_key == "advanced_analytics":
        show_advanced_analytics()
    elif page_key == "scenario_planning":
        show_scenario_planning()
    elif page_key == "ml_forecasting":
        show_ml_forecasting()
    elif page_key == "risk_management":
        show_risk_management()
    elif page_key == "industry_templates":
        show_industry_templates()
    
    # Enhanced sidebar footer with comprehensive status
    with st.sidebar:
        st.markdown("---")
        
        # Enhanced system status
        st.markdown("### üîß Statut Syst√®me Avanc√©")
        st.success("üü¢ Processeur CSV: Op√©rationnel")
        st.success("üü¢ Moteur Analytics: Actif") 
        st.success("üü¢ Mod√®les ML: Disponibles")
        st.success("üü¢ Templates Sectoriels: Complets")
        st.success("üü¢ Validation Avanc√©e: Active")
        st.success("üü¢ Corrections Auto: Fonctionnelles")
        
        # Enhanced datetime and user info
        current_datetime = datetime.now()
        st.caption(f"Heure Actuelle: {current_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        st.caption("Utilisateur: SalianiBouchaib")
        
        # Performance metrics if data available
        if CSVDataManager.has_csv_data():
            st.markdown("---")
            st.markdown("### üìà M√©triques Session")
            
            # Calculate session metrics
            data_points = len(st.session_state.get('imported_metrics', {}).get('revenue', {}).get('data', []))
            st.caption(f"Points de donn√©es: {data_points}")
            
            # Validation summary
            if 'validation_results' in st.session_state:
                validation_results = st.session_state.validation_results
                total_issues = validation_results.get('total_issues', 0)
                st.caption(f"Validations effectu√©es: {total_issues} anomalies d√©tect√©es")
                
                corrections = len(st.session_state.get('correction_log', []))
                if corrections > 0:
                    st.caption(f"Corrections appliqu√©es: {corrections}")
        
        # Enhanced additional info
        st.markdown("---")
        st.markdown("### üìä Capacit√©s Avanc√©es")
        st.caption("‚úÖ Validation √âquation Comptable")
        st.caption("‚úÖ Contr√¥le Logique Profit")
        st.caption("‚úÖ D√©tection Variations Extr√™mes")
        st.caption("‚úÖ Identification Outliers (3œÉ)")
        st.caption("‚úÖ Corrections Automatis√©es")
        st.caption("‚úÖ Interpolation Intelligente")
        st.caption("‚úÖ Lissage Variations")
        st.caption("‚úÖ Validation Crois√©e")
        st.caption("‚úÖ Calibrage ML Am√©lior√©")
        st.caption("‚úÖ Ensemble Methods")
        st.caption("‚úÖ Contraintes Business")
        st.caption("‚úÖ Analyse Sectorielle")
        st.caption("‚úÖ Benchmarking Multi-Industries")

# ========== RUN ENHANCED APPLICATION ==========
if __name__ == "__main__":
    main()
